#' Add Module Scores for a List of Feature Sets
#'
#' This function takes a Seurat object and a list of feature (gene) sets.
#' For each feature set, it calculates a module score using Seurat's AddModuleScore.
#' The name of the resulting metadata column will be the name of the feature set if provided,
#' or a concatenation of gene names joined by "+" if the feature set is unnamed.
#'
#' @param seurat_object A Seurat object.
#' @param feature_sets A named or unnamed list of character vectors. Each character vector is a set of gene names.
#'                     If the list is named, the names will be used for the output module score columns.
#'                     If a list element is unnamed, its name will be generated by concatenating gene names with "+".
#' @param assay Name of the assay to use. Default is the current default assay.
#' @param layer layer to pull expression data from. Default is "data".
#' @param nbin Number of bins for AddModuleScore. Default is 24.
#' @param ctrl Number of control features for AddModuleScore. Default is 100.
#' @param seed Random seed for AddModuleScore. Default is 1.
#' @param search Passed to Seurat::`[.Assay`. Default is FALSE. Relevant if features are not present in the object.
#' @param ... Additional arguments passed to Seurat::AddModuleScore.
#'
#' @return A Seurat object with added module scores in the metadata.
#'
#' @examples
#' \dontrun{
#' # Assuming 'pbmc' is a Seurat object with an RNA assay
#' # Example feature sets
#' gene_sets <- list(
#'   Tcell_activation = c("CD69", "IFNG", "TNF"),
#'   Monocyte_markers = c("CD14", "LYZ"),
#'   c("CCR7", "SELL", "LEF1"), # Unnamed set
#'   Bcell_core = c("MS4A1", "CD19", "CD79A")
#' )
#'
#' pbmc <- AddMultipleModuleScores(seurat_object = pbmc, feature_sets = gene_sets)
#'
#' # Check the new metadata columns
#' head(pbmc@meta.data)
#'
#' # Visualize a score
#' FeaturePlot(pbmc, features = "Tcell_activation1") # Name is appended with a number
#' FeaturePlot(pbmc, features = "CCR7_SELL_LEF11")
#' }
AddMultipleModuleScores <- function(seurat_object,
                                    feature_sets,
                                    assay = NULL,
                                    layer = "data",
                                    nbin = 24,
                                    ctrl = 100,
                                    seed = 1,
                                    search = FALSE,
                                    ...) {
  
  if (!requireNamespace("Seurat", quietly = TRUE))
    stop("Package 'Seurat' is required but not installed.")
  if (!is.list(feature_sets))
    stop("'feature_sets' must be a list of character vectors.")
  
  if (is.null(assay))
    assay <- Seurat::DefaultAssay(seurat_object)
  
  all_genes <- rownames(Seurat::GetAssayData(seurat_object, assay = assay, layer = layer))
  added_cols <- character(0)              # <- 여기에 최종 컬럼명 모음
  
  for (i in seq_along(feature_sets)) {
    
    genes_raw <- feature_sets[[i]]
    genes_use <- intersect(genes_raw, all_genes)
    if (length(genes_use) == 0) {
      warning(sprintf("feature set %d: no genes found – skipped", i))
      next
    }
    
    set_name <- names(feature_sets)[i]
    if (is.null(set_name) || set_name == "")
      set_name <- paste(gsub("-", "_", genes_use), collapse = "+")
    
    #— 1) AddModuleScore 실행
    before_cols <- colnames(seurat_object[[]])
    seurat_object <- Seurat::AddModuleScore(
      object   = seurat_object,
      features = list(genes_use),
      name     = set_name,                # AddModuleScore가 set_name1 을 만듦
      assay    = assay,
      layer     = layer,
      nbin     = nbin,
      ctrl     = ctrl,
      seed     = seed,
      search   = search,
      ...
    )
    after_cols  <- colnames(seurat_object[[]])
    new_col     <- setdiff(after_cols, before_cols)  # 방금 생긴 컬럼
    
    #— 2) 뒤에 붙은 숫자 제거 & rename
    tidy_col    <- sub("1$", "", new_col)            # 끝의 1 지우기
    if (tidy_col != new_col) {
      colnames(seurat_object[[]])[match(new_col, after_cols)] <- tidy_col
      message(sprintf("renamed '%s' -> '%s'", new_col, tidy_col))
    }
    
    added_cols <- c(added_cols, tidy_col)
  }
  
  #— 3) FeaturePlot 에 바로 써먹을 수 있게 출력
  if (length(added_cols)) {
    msg1 <- "# Copy-&-paste for FeaturePlot:"
    msg2 <- sprintf("FeaturePlot(obj, features = c(%s))",
                    paste(sprintf("'%s'", added_cols), collapse=", "))
    message("\n", msg1, "\n", msg2, "\n")
    flush.console()
  } else {
    warning("No module scores were added.")
  }
  
  
  invisible(seurat_object)
}



#' Visualize Module Scores as Heatmap with Statistical Testing
#'
#' This function uses AddModuleScore results to create a heatmap visualization
#' with z-score normalization and statistical significance indicators
#'
#' @param sobj Seurat object
#' @param gene_sets Named list of gene sets
#' @param group Grouping variable (default: "seurat_clusters")
#' @param assay Assay to use (default: "SCT")
#' @param test_method Statistical test method ("wilcox" or "t")
#' @param p_adjust Method for p-value adjustment (default: "bonferroni")
#' @param show_pval Whether to show p-values on the heatmap
#' @param scale_method How to scale the data: "feature" (scale each feature across groups) or "group" (scale within each group)
#' @param color_limits Manual color scale limits (e.g., c(-2, 2)). If NULL, uses symmetric limits based on data
#' @param ... Additional arguments passed to AddModuleScore
#'
#' @return A list containing the heatmap plot and statistical results
#'
PlotModuleScoreHeatmap <- function(
    sobj,
    gene_sets,
    group = "seurat_clusters",
    assay = "SCT",
    test_method = "wilcox",
    p_adjust = "bonferroni",
    show_pval = TRUE,
    scale_method = "feature",
    color_limits = NULL,
    title = "Module Score Expression per Cluster",
    x_label = "Cluster",
    y_label = "Gene Set",
    ...
) {
  library(Seurat)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(patchwork)
  
  # Validate inputs
  if(is.null(gene_sets) || length(gene_sets) == 0) {
    stop("gene_sets must be provided")
  }
  
  # Ensure gene_sets is a named list
  if(!is.list(gene_sets)) {
    gene_sets <- list(GeneSet1 = gene_sets)
  }
  
  if(is.null(names(gene_sets)) || any(names(gene_sets) == "")) {
    for(i in seq_along(gene_sets)) {
      if(is.null(names(gene_sets)[i]) || names(gene_sets)[i] == "") {
        names(gene_sets)[i] <- paste0("GeneSet", i)
      }
    }
  }
  
  # Add module scores for each gene set
  module_names <- character()
  for(i in seq_along(gene_sets)) {
    set_name <- names(gene_sets)[i]
    
    # Check if genes exist in the dataset
    genes_present <- gene_sets[[i]][gene_sets[[i]] %in% rownames(sobj[[assay]])]
    if(length(genes_present) == 0) {
      warning(paste("No genes from", set_name, "found in the dataset."))
      next
    }
    
    # AddModuleScore adds a number suffix, we'll track it
    before_cols <- colnames(sobj@meta.data)
    sobj <- AddModuleScore(
      object = sobj,
      features = list(genes_present),
      name = set_name,
      assay = assay,
      ...
    )
    after_cols <- colnames(sobj@meta.data)
    new_col <- setdiff(after_cols, before_cols)
    
    # Remove the "1" suffix if desired
    if(length(new_col) > 0) {
      clean_name <- sub("1$", "", new_col[1])
      colnames(sobj@meta.data)[colnames(sobj@meta.data) == new_col[1]] <- clean_name
      module_names <- c(module_names, clean_name)
    }
  }
  
  if(length(module_names) == 0) {
    stop("No valid module scores could be calculated")
  }
  
  # Calculate average module scores per group
  Idents(sobj) <- group
  group_levels <- levels(Idents(sobj))
  if(is.null(group_levels)) {
    group_levels <- unique(Idents(sobj))
  }
  
  # Extract module score data
  module_data <- sobj@meta.data[, c(group, module_names), drop = FALSE]
  
  # Calculate mean scores per group
  mean_scores <- module_data %>%
    group_by(!!sym(group)) %>%
    summarise(across(all_of(module_names), mean, na.rm = TRUE)) %>%
    as.data.frame()
  
  # Z-score normalization based on scale_method
  z_scores <- mean_scores
  
  if(scale_method == "feature") {
    # Scale each module across all clusters (recommended)
    # 각 module에 대해 모든 cluster의 평균과 표준편차로 정규화
    for(module in module_names) {
      z_scores[[module]] <- scale(mean_scores[[module]])[, 1]
    }
  } else if(scale_method == "group") {
    # Scale all modules within each cluster (original behavior)
    # 각 cluster 내에서 모든 module을 정규화
    z_scores[, module_names] <- t(scale(t(mean_scores[, module_names])))
  } else {
    stop("scale_method must be either 'feature' or 'group'")
  }
  
  # Statistical testing between clusters
  p_values <- matrix(NA, nrow = length(module_names), ncol = length(group_levels),
                     dimnames = list(module_names, group_levels))
  
  for(module in module_names) {
    for(cluster in group_levels) {
      cluster_scores <- module_data[module_data[[group]] == cluster, module]
      other_scores <- module_data[module_data[[group]] != cluster, module]
      
      if(length(cluster_scores) > 2 && length(other_scores) > 2) {
        if(test_method == "wilcox") {
          test_result <- wilcox.test(cluster_scores, other_scores)
        } else if(test_method == "t") {
          test_result <- t.test(cluster_scores, other_scores)
        }
        p_values[module, as.character(cluster)] <- test_result$p.value
      }
    }
  }
  
  # Adjust p-values
  p_adj <- matrix(p.adjust(as.vector(p_values), method = p_adjust),
                  nrow = nrow(p_values), ncol = ncol(p_values),
                  dimnames = dimnames(p_values))
  
  # Prepare data for plotting
  plot_data <- z_scores %>%
    pivot_longer(cols = all_of(module_names),
                 names_to = "Module",
                 values_to = "ZScore")
  
  # Add significance indicators
  sig_data <- as.data.frame(p_adj) %>%
    mutate(Module = rownames(.)) %>%
    pivot_longer(cols = -Module,
                 names_to = group,
                 values_to = "p_adj")
  
  plot_data <- plot_data %>%
    left_join(sig_data, by = c("Module", group))
  
  # Add significance symbols
  plot_data <- plot_data %>%
    mutate(sig_symbol = case_when(
      p_adj < 0.001 ~ "***",
      p_adj < 0.01 ~ "**",
      p_adj < 0.05 ~ "*",
      TRUE ~ ""
    ))
  
  # Sort clusters numerically if possible
  numeric_test <- suppressWarnings(as.numeric(as.character(plot_data[[group]])))
  if(!all(is.na(numeric_test))) {
    plot_data[[group]] <- factor(plot_data[[group]],
                                 levels = as.character(sort(unique(numeric_test))))
  }
  
  # Create heatmap with adjusted color scale
  if(is.null(color_limits)) {
    # Use symmetric limits based on max absolute value
    max_abs <- max(abs(plot_data$ZScore), na.rm = TRUE)
    color_limits <- c(-max_abs, max_abs)
  }
  
  p <- ggplot(plot_data, aes_string(x = group, y = "Module", fill = "ZScore")) +
    geom_tile() +
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                         midpoint = 0, limits = color_limits, name = "Z-Score") +
    theme_minimal() +
    labs(title = title, x = x_label, y = y_label) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 14, face = "bold"),
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
    )
  
  # Add significance indicators if requested
  if(show_pval) {
    p <- p + geom_text(aes(label = sig_symbol), 
                       color = "black", size = 4, vjust = 0.5)
  }
  
  # Create a summary plot showing raw module scores
  summary_data <- module_data %>%
    pivot_longer(cols = all_of(module_names),
                 names_to = "Module",
                 values_to = "Score")
  
  p_violin <- ggplot(summary_data, aes_string(x = group, y = "Score", fill = group)) +
    geom_violin(trim = FALSE, alpha = 0.8) +
    geom_boxplot(width = 0.1, outlier.size = 0.5) +
    facet_wrap(~ Module, scales = "free_y", ncol = 2) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    ) +
    labs(title = "Raw Module Score Distribution",
         x = x_label, y = "Module Score")
  
  # Combine plots
  combined_plot <- p / p_violin + plot_layout(heights = c(1, 2))
  
  print(combined_plot)
  
  # Return results
  return(list(
    plot = combined_plot,
    z_scores = z_scores,
    p_values = p_adj,
    raw_means = mean_scores,
    module_names = module_names
  ))
}

#' Compare Module Scoring Methods
#'
#' This function compares the simple averaging method with AddModuleScore
#'
#' @export
CompareModuleScoringMethods <- function(
    sobj,
    gene_sets,
    group = "seurat_clusters",
    assay = "SCT"
) {
  library(ggplot2)
  library(patchwork)
  
  # Method 1: Simple averaging (original method)
  simple_results <- myhm_genesets4(sobj, group, "average", assay, gene_sets,
                                   title = "Simple Averaging Method")
  
  # Method 2: AddModuleScore-based
  module_results <- PlotModuleScoreHeatmap(sobj, gene_sets, group, assay,
                                           title = "AddModuleScore Method")
  
  # Create comparison plot
  comparison_data <- data.frame(
    Cluster = simple_results$Cluster,
    Method = "Simple"
  )
  
  for(gset in names(gene_sets)) {
    if(gset %in% colnames(simple_results)) {
      comparison_data[[gset]] <- simple_results[[gset]]
    }
  }
  
  module_z <- module_results$z_scores
  module_comparison <- data.frame(
    Cluster = module_z[[group]],
    Method = "AddModuleScore"
  )
  
  for(module in module_results$module_names) {
    if(module %in% colnames(module_z)) {
      module_comparison[[module]] <- module_z[[module]]
    }
  }
  
  # Combine data
  all_data <- bind_rows(comparison_data, module_comparison)
  
  # Create faceted comparison plot
  all_data_long <- all_data %>%
    pivot_longer(cols = -c(Cluster, Method),
                 names_to = "GeneSet",
                 values_to = "ZScore")
  
  p_compare <- ggplot(all_data_long, aes(x = Cluster, y = ZScore, fill = Method)) +
    geom_bar(stat = "identity", position = "dodge") +
    facet_wrap(~ GeneSet, scales = "free_y") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = "Comparison of Scoring Methods",
         x = "Cluster", y = "Z-Score")
  
  print(p_compare)
  
  return(list(
    simple = simple_results,
    module = module_results,
    comparison_plot = p_compare
  ))
}

# Example usage:
# gene_sets <- list(
#   Tcell = c("CD3D", "CD3E", "CD3G"),
#   Bcell = c("MS4A1", "CD79A", "CD79B"),
#   Monocyte = c("CD14", "LYZ", "S100A8", "S100A9")
# )
# 
# results <- PlotModuleScoreHeatmap(pbmc, gene_sets, show_pval = TRUE)
# comparison <- CompareModuleScoringMethods(pbmc, gene_sets)

#' @title Add Gene Signature Score using enrichIt (Improved Version)
#' @description Calculates a gene signature score using escape::enrichIt and adds it to the Seurat object's metadata.
#' This version flexibly accepts different gene ID types (e.g., ENSEMBL, SYMBOL, ENTREZID).
#'
#' @param seurat_obj A Seurat object.
#' @param gene_source A character string specifying the path to a file OR an R object (data.frame, vector) containing gene IDs.
#' @param signature_name A character string for the name of the new metadata column.
#' @param input_keytype The type of the input gene IDs. Must be a valid keytype for org.Hs.eg.db. 
#'                      Common values are "ENSEMBL", "SYMBOL", "ENTREZID". Defaults to "ENSEMBL".
#' @param gene_col If `gene_source` is a file path or a data.frame, specify the column index or name. Defaults to 1.
#' @param sheet_name If `gene_source` is an xlsx file, specify the sheet name or index. Defaults to 1.
#' @param assay The assay to use from the Seurat object. Defaults to "RNA".
#' @param layer The layer (slot) to use from the assay. Defaults to "data".
#' @param ... Additional arguments to be passed to `escape::enrichIt`.
#'
#' @return A Seurat object with the new signature score added to its metadata.
#' @export
add_signature_enrichit <- function(seurat_obj,
                                      gene_source,
                                      signature_name,
                                      input_keytype = "ENSEMBL", # <--- 이 파라미터 추가!
                                      gene_col = 1,
                                      sheet_name = 1,
                                      assay = "RNA",
                                      layer = "data",
                                      ...) {
  # ... (이전 버전과 동일한 유전자 목록 로드 부분) ...
  if (is.character(gene_source) && file.exists(gene_source)) {
    ext <- tools::file_ext(gene_source)
    gene_list_raw <- switch(ext,
                            xlsx = read_xlsx(gene_source, sheet = sheet_name)[[gene_col]],
                            csv = read.csv(gene_source, stringsAsFactors = FALSE)[[gene_col]],
                            txt = read.table(gene_source, stringsAsFactors = FALSE)[[gene_col]],
                            stop("Unsupported file type.")
    )
  } else if (is.data.frame(gene_source)) {
    gene_list_raw <- gene_source[[gene_col]]
  } else if (is.vector(gene_source)) {
    gene_list_raw <- gene_source
  } else {
    stop("`gene_source` must be a valid file path, data.frame, or vector.")
  }
  
  # 입력된 keytype을 사용하여 항상 SYMBOL로 변환
  # 자동 감지는 권하지 않는다. 왜냐면 오류의 원인이 되기 쉽다. 데이터 정제는 따로 수행하는 것이 좋다.
  
  message(paste("Input keytype is", input_keytype, ". Converting to Gene Symbols..."))
  gene_symbols <- mapIds(
    org.Hs.eg.db,
    keys = unique(na.omit(as.character(gene_list_raw))),
    keytype = input_keytype, # 사용자가 지정한 ID 타입을 사용
    column = "SYMBOL",       # 최종 목표는 항상 SYMBOL
    multiVals = "first"
  )
  gene_symbols <- na.omit(gene_symbols)
  # ---
  
  if (length(gene_symbols) == 0) {
    stop(paste("No valid gene symbols could be mapped using keytype:", input_keytype))
  }
  message(paste(length(gene_symbols), "gene symbols were successfully mapped."))
  
  gene_set <- GeneSet(gene_symbols, setName = signature_name)
  gene_sets_collection <- GeneSetCollection(gene_set)
  
  message("Running enrichIt...")
  expr_matrix <- GetAssayData(seurat_obj, assay = assay, layer = layer)
  enrichment_scores <- enrichIt(
    obj = expr_matrix,
    gene.sets = gene_sets_collection,
    ...
  )
  
  message("Adding scores to Seurat metadata...")
  seurat_obj <- AddMetaData(
    object = seurat_obj,
    metadata = as.data.frame(enrichment_scores)
  )
  
  return(seurat_obj)
}

#' @title Add Pathway Activity Scores using progeny
#' @description Infers pathway activities using progeny and adds them to the Seurat object's metadata.
#'
#' @param seurat_obj A Seurat object.
#' @param organism A character string specifying the organism. Can be "Human" or "Mouse". Defaults to "Human".
#' @param topn An integer specifying the number of top genes to use for each pathway. Defaults to 100.
#' @param ... Additional arguments to be passed to `progeny::progeny`.
#'
#' @return A Seurat object with pathway activity scores added to its metadata.
#' @export
#'
#' @examples
#' \dontrun{
#' # 예시 데이터 생성
#' pbmc_small <- SeuratObject::pbmc_small
#' pbmc_with_progeny <- add_progeny_scores(pbmc_small, organism = "Human")
#'
#' # 추가된 메타데이터 확인 (14개 경로)
#' head(pbmc_with_progeny@meta.data)
#'
#' # DimPlot으로 특정 경로 활성도 시각화
#' DimPlot(pbmc_with_progeny, reduction = "umap", group.by = "seurat_clusters", label = TRUE)
#' FeaturePlot(pbmc_with_progeny, features = "NFkB")
#' }
add_progeny_scores <- function(seurat_obj, organism = "Human", topn = 100, ...) {
  
  # 1. Progeny를 실행하여 새로운 assay 추가
  message("Running progeny...")
  seurat_obj <- progeny(
    seurat_obj,
    scale = FALSE, # Scaling은 ScaleData에서 별도 수행
    organism = organism,
    topn = topn,
    return_assay = TRUE,
    ...
  )
  
  # 2. Progeny assay를 스케일링
  message("Scaling progeny assay...")
  seurat_obj <- ScaleData(seurat_obj, assay = "progeny")
  
  # 3. 스케일링된 데이터를 메타데이터로 변환하여 추가
  message("Adding scores to Seurat metadata...")
  progeny_scores <- as.data.frame(t(GetAssayData(seurat_obj, assay = "progeny", layer = "scale.data")))
  
  seurat_obj <- AddMetaData(
    object = seurat_obj,
    metadata = progeny_scores
  )
  
  return(seurat_obj)
}

# NOTE: Package dependencies should be declared in DESCRIPTION, not with library() calls

linear_seurat <- function(sobj, 
                          layer = c("counts", "data", "scale.data"), 
                          features = "all", 
                          regressor = "val1", 
                          regressor.type = c("continuous", "categorical", "ordinal"),
                          reference.level = NULL,
                          ordinal.method = c("linear", "polynomial", "spline"),
                          link.function = "linear",
                          effect = c("fixed", "random"), 
                          covariates = NULL,
                          min.cells = 10,
                          return.full = FALSE,
                          ...) {
  
  # Input validation
  if (!inherits(sobj, "Seurat")) {
    stop("Input must be a Seurat object")
  }
  
  layer <- match.arg(layer)
  effect <- match.arg(effect)
  regressor.type <- match.arg(regressor.type)
  ordinal.method <- match.arg(ordinal.method)
  
  # Check if regressor exists in metadata
  if (!regressor %in% colnames(sobj@meta.data)) {
    stop(paste("Regressor", regressor, "not found in metadata"))
  }
  
  # Get expression data based on layer
  if (layer == "counts") {
    expr_data <- GetAssayData(sobj, layer = "counts")
  } else if (layer == "data") {
    expr_data <- GetAssayData(sobj, layer = "data")
  } else if (layer == "scale.data") {
    expr_data <- GetAssayData(sobj, layer = "scale.data")
  }
  
  # Select features
  if (features[1] == "all") {
    features <- rownames(expr_data)
  } else {
    # Check if all features exist
    missing_features <- setdiff(features, rownames(expr_data))
    if (length(missing_features) > 0) {
      warning(paste("Features not found:", paste(missing_features, collapse = ", ")))
      features <- intersect(features, rownames(expr_data))
    }
  }
  
  # Filter features by minimum cell expression
  if (min.cells > 0) {
    feature_counts <- Matrix::rowSums(expr_data[features, ] > 0)
    features <- features[feature_counts >= min.cells]
  }
  
  if (length(features) == 0) {
    stop("No features passed filtering criteria")
  }
  
  # Prepare metadata
  meta_data <- sobj@meta.data
  regressor_values <- meta_data[[regressor]]
  
  # Process regressor based on type
  if (regressor.type == "categorical") {
    regressor_values <- as.factor(regressor_values)
    
    # Set reference level if specified
    if (!is.null(reference.level)) {
      if (!reference.level %in% levels(regressor_values)) {
        stop(paste("Reference level", reference.level, "not found in regressor levels"))
      }
      regressor_values <- relevel(regressor_values, ref = reference.level)
    }
    
    cat("Categorical regressor with levels:", paste(levels(regressor_values), collapse = ", "), "\n")
    cat("Reference level:", levels(regressor_values)[1], "\n")
    
  } else if (regressor.type == "ordinal") {
    # Check if it's already ordered
    if (!is.ordered(regressor_values)) {
      if (is.factor(regressor_values)) {
        regressor_values <- ordered(regressor_values)
      } else {
        # Try to convert to ordered factor
        unique_vals <- sort(unique(regressor_values[!is.na(regressor_values)]))
        regressor_values <- ordered(regressor_values, levels = unique_vals)
      }
    }
    
    cat("Ordinal regressor with levels:", paste(levels(regressor_values), collapse = " < "), "\n")
    cat("Ordinal method:", ordinal.method, "\n")
    
  } else if (regressor.type == "continuous") {
    regressor_values <- as.numeric(regressor_values)
    if (all(is.na(regressor_values))) {
      stop("Regressor cannot be converted to numeric for continuous analysis")
    }
  }
  
  # Check for missing values in regressor
  if (any(is.na(regressor_values))) {
    warning("Missing values found in regressor variable")
    valid_cells <- !is.na(regressor_values)
    expr_data <- expr_data[, valid_cells]
    meta_data <- meta_data[valid_cells, ]
    regressor_values <- regressor_values[valid_cells]
  }
  
  # Prepare covariate formula
  covariate_formula <- ""
  if (!is.null(covariates)) {
    # Check if covariates exist in metadata
    missing_covariates <- setdiff(covariates, colnames(meta_data))
    if (length(missing_covariates) > 0) {
      warning(paste("Covariates not found:", paste(missing_covariates, collapse = ", ")))
      covariates <- intersect(covariates, colnames(meta_data))
    }
    if (length(covariates) > 0) {
      covariate_formula <- paste("+", paste(covariates, collapse = " + "))
    }
  }
  
  # Function to fit model for each gene
  fit_gene_model <- function(gene) {
    expression <- as.numeric(expr_data[gene, ])
    
    # Create data frame for modeling
    model_data <- data.frame(
      expression = expression,
      regressor = regressor_values
    )
    
    # Add covariates if specified
    if (!is.null(covariates) && length(covariates) > 0) {
      for (cov in covariates) {
        model_data[[cov]] <- meta_data[[cov]]
      }
    }
    
    # Remove rows with missing values
    model_data <- model_data[complete.cases(model_data), ]
    
    if (nrow(model_data) < 10) {
      return(data.frame(
        gene = gene,
        estimate = NA,
        std.error = NA,
        statistic = NA,
        p.value = NA,
        n_cells = nrow(model_data),
        regressor_type = regressor.type
      ))
    }
    
    # Prepare formula based on regressor type
    if (regressor.type == "continuous") {
      regressor_formula <- "regressor"
    } else if (regressor.type == "categorical") {
      regressor_formula <- "regressor"  # R automatically handles factor contrasts
    } else if (regressor.type == "ordinal") {
      if (ordinal.method == "linear") {
        # Convert to numeric for linear trend
        model_data$regressor_numeric <- as.numeric(model_data$regressor)
        regressor_formula <- "regressor_numeric"
      } else if (ordinal.method == "polynomial") {
        # Use polynomial contrasts
        regressor_formula <- "poly(as.numeric(regressor), degree = min(3, length(levels(regressor))-1))"
      } else if (ordinal.method == "spline") {
        # Use natural splines (requires splines package)
        if (requireNamespace("splines", quietly = TRUE)) {
          regressor_formula <- "splines::ns(as.numeric(regressor), df = min(3, length(levels(regressor))-1))"
        } else {
          warning("splines package not available, using linear method")
          model_data$regressor_numeric <- as.numeric(model_data$regressor)
          regressor_formula <- "regressor_numeric"
        }
      }
    }
    
    # Fit model based on effect type
    tryCatch({
      if (effect == "fixed") {
        formula_str <- paste("expression ~", regressor_formula, covariate_formula)
        
        if (link.function == "linear") {
          model <- lm(as.formula(formula_str), data = model_data, ...)
        } else if (link.function == "poisson") {
          model <- glm(as.formula(formula_str), data = model_data, family = poisson(), ...)
        } else if (link.function == "negative.binomial") {
          model <- MASS::glm.nb(as.formula(formula_str), data = model_data, ...)
        }
        
        # Extract results - handle different regressor types
        model_summary <- tidy(model)
        
        if (regressor.type == "categorical") {
          # For categorical variables, extract all factor levels
          regressor_rows <- model_summary[grepl("^regressor", model_summary$term), ]
          
          if (nrow(regressor_rows) == 0) {
            # Single level case
            regressor_rows <- model_summary[model_summary$term == "regressor", ]
          }
          
          # Calculate overall F-test p-value for categorical variables
          if (nrow(regressor_rows) > 1) {
            model_anova <- anova(model)
            # More robust way to get p-value from anova table
            pval_col <- which(grepl("Pr\\(>F\\)", colnames(model_anova)))
            if (length(pval_col) > 0) {
              overall_p <- model_anova[1, pval_col]
            } else {
              overall_p <- regressor_rows$p.value[1]
            }
          } else {
            overall_p <- regressor_rows$p.value[1]
          }
          
          # Return summary statistics
          result <- data.frame(
            gene = gene,
            estimate = ifelse(nrow(regressor_rows) > 0, regressor_rows$estimate[1], NA),
            std.error = ifelse(nrow(regressor_rows) > 0, regressor_rows$std.error[1], NA),
            statistic = ifelse(nrow(regressor_rows) > 0, regressor_rows$statistic[1], NA),
            p.value = overall_p,
            n_cells = nrow(model_data),
            model_type = paste(effect, link.function, regressor.type, sep = "_"),
            n_levels = length(levels(model_data$regressor))
          )
          
        } else {
          # For continuous and ordinal (treated as continuous)
          if (regressor.type == "ordinal" && ordinal.method == "linear") {
            regressor_rows <- model_summary[model_summary$term == "regressor_numeric", ]
            overall_p <- regressor_rows$p.value[1]
          } else if (regressor.type == "ordinal" && ordinal.method %in% c("polynomial", "spline")) {
            regressor_rows <- model_summary[grepl("poly|ns", model_summary$term), ]
            # For polynomial/spline, use F-test
            if (nrow(regressor_rows) > 1) {
              model_anova <- anova(model)
              # Find the row corresponding to polynomial/spline term
              poly_spline_rows <- grepl("poly|ns", rownames(model_anova))
              pval_col <- which(grepl("Pr\\(>F\\)", colnames(model_anova)))
              
              if (any(poly_spline_rows) && length(pval_col) > 0) {
                overall_p <- model_anova[which(poly_spline_rows)[1], pval_col]
              } else {
                overall_p <- regressor_rows$p.value[1]
              }
            } else {
              overall_p <- regressor_rows$p.value[1]
            }
          } else {
            regressor_rows <- model_summary[model_summary$term == "regressor", ]
            overall_p <- regressor_rows$p.value[1]
          }
          
          result <- data.frame(
            gene = gene,
            estimate = ifelse(nrow(regressor_rows) > 0, regressor_rows$estimate[1], NA),
            std.error = ifelse(nrow(regressor_rows) > 0, regressor_rows$std.error[1], NA),
            statistic = ifelse(nrow(regressor_rows) > 0, regressor_rows$statistic[1], NA),
            p.value = overall_p,
            n_cells = nrow(model_data),
            model_type = paste(effect, link.function, regressor.type, sep = "_")
          )
        }
        
      } else if (effect == "random") {
        # Random effects implementation
        if (is.null(covariates) || length(covariates) == 0) {
          stop("Random effects models require at least one grouping variable in covariates")
        }
        
        group_var <- covariates[1]
        formula_str <- paste("expression ~", regressor_formula, "+ (1|", group_var, ")")
        if (length(covariates) > 1) {
          formula_str <- paste(formula_str, "+", paste(covariates[-1], collapse = " + "))
        }
        
        model <- lmer(as.formula(formula_str), data = model_data, ...)
        model_summary <- tidy(model, effects = "fixed")
        
        if (regressor.type == "ordinal" && ordinal.method == "linear") {
          regressor_rows <- model_summary[model_summary$term == "regressor_numeric", ]
        } else {
          regressor_rows <- model_summary[grepl("regressor", model_summary$term), ]
        }
        
        result <- data.frame(
          gene = gene,
          estimate = ifelse(nrow(regressor_rows) > 0, regressor_rows$estimate[1], NA),
          std.error = ifelse(nrow(regressor_rows) > 0, regressor_rows$std.error[1], NA),
          statistic = ifelse(nrow(regressor_rows) > 0, regressor_rows$statistic[1], NA),
          p.value = ifelse(nrow(regressor_rows) > 0, regressor_rows$p.value[1], NA),
          n_cells = nrow(model_data),
          model_type = paste(effect, link.function, regressor.type, sep = "_")
        )
      }
      
      return(result)
      
    }, error = function(e) {
      data.frame(
        gene = gene,
        estimate = NA,
        std.error = NA,
        statistic = NA,
        p.value = NA,
        n_cells = nrow(model_data),
        model_type = paste(effect, link.function, regressor.type, sep = "_"),
        error = as.character(e)
      )
    })
  }
  
  # Apply function to all features
  cat("Fitting models for", length(features), "features...\n")
  
  # Use parallel processing if available
  if (requireNamespace("parallel", quietly = TRUE) && length(features) > 100) {
    results <- parallel::mclapply(features, fit_gene_model, mc.cores = parallel::detectCores() - 1)
  } else {
    results <- lapply(features, fit_gene_model)
  }
  
  # Combine results
  results_df <- do.call(rbind, results)
  
  # Multiple testing correction
  valid_pvals <- !is.na(results_df$p.value)
  results_df$adj.p.value <- NA
  if (sum(valid_pvals) > 0) {
    results_df$adj.p.value[valid_pvals] <- p.adjust(results_df$p.value[valid_pvals], method = "BH")
  }
  
  # Sort by p-value
  results_df <- results_df[order(results_df$p.value, na.last = TRUE), ]
  
  # Add metadata about the analysis
  attr(results_df, "analysis_info") <- list(
    regressor = regressor,
    regressor.type = regressor.type,
    layer = layer,
    effect = effect,
    link.function = link.function,
    covariates = covariates,
    n_features_tested = length(features),
    n_cells = ncol(expr_data),
    reference.level = ifelse(regressor.type == "categorical", levels(regressor_values)[1], NA),
    ordinal.method = ifelse(regressor.type == "ordinal", ordinal.method, NA)
  )
  
  if (return.full) {
    return(list(
      results = results_df,
      seurat_object = sobj,
      features_tested = features
    ))
  } else {
    return(results_df)
  }
}

# Helper function to visualize top results
plot_top_genes <- function(results, sobj, layer = "data", top_n = 6) {
  library(ggplot2)
  library(gridExtra)
  
  # Get analysis info
  analysis_info <- attr(results, "analysis_info")
  regressor <- analysis_info$regressor
  regressor.type <- analysis_info$regressor.type
  
  # Get top significant genes
  top_genes <- head(results[!is.na(results$p.value), ], top_n)$gene
  
  # Get expression data
  if (layer == "counts") {
    expr_data <- GetAssayData(sobj, layer = "counts")
  } else if (layer == "data") {
    expr_data <- GetAssayData(sobj, layer = "data")
  } else if (layer == "scale.data") {
    expr_data <- GetAssayData(sobj, layer = "scale.data")
  }
  
  # Prepare regressor data
  regressor_data <- sobj@meta.data[[regressor]]
  if (regressor.type == "categorical") {
    regressor_data <- as.factor(regressor_data)
  } else if (regressor.type == "ordinal") {
    if (!is.ordered(regressor_data)) {
      if (is.factor(regressor_data)) {
        regressor_data <- ordered(regressor_data)
      } else {
        unique_vals <- sort(unique(regressor_data[!is.na(regressor_data)]))
        regressor_data <- ordered(regressor_data, levels = unique_vals)
      }
    }
  } else {
    regressor_data <- as.numeric(regressor_data)
  }
  
  # Create plots
  plots <- list()
  for (i in seq_along(top_genes)) {
    gene <- top_genes[i]
    gene_result <- results[results$gene == gene, ]
    
    plot_data <- data.frame(
      expression = as.numeric(expr_data[gene, ]),
      regressor = regressor_data
    )
    
    # Remove missing values
    plot_data <- plot_data[complete.cases(plot_data), ]
    
    if (regressor.type == "categorical") {
      p <- ggplot(plot_data, aes(x = regressor, y = expression)) +
        geom_boxplot(aes(fill = regressor), alpha = 0.7) +
        geom_jitter(width = 0.2, alpha = 0.5) +
        labs(
          title = paste0(gene, " (p=", format(gene_result$p.value, digits = 3), ")"),
          x = regressor,
          y = paste("Expression (", layer, ")", sep = "")
        ) +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        guides(fill = "none")
      
    } else if (regressor.type == "ordinal") {
      p <- ggplot(plot_data, aes(x = regressor, y = expression)) +
        geom_boxplot(aes(group = regressor, fill = regressor), alpha = 0.7) +
        geom_jitter(width = 0.2, alpha = 0.5) +
        geom_smooth(aes(group = 1), method = "lm", se = TRUE, color = "red") +
        labs(
          title = paste0(gene, " (p=", format(gene_result$p.value, digits = 3), ")"),
          x = regressor,
          y = paste("Expression (", layer, ")", sep = "")
        ) +
        theme_minimal() +
        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
        guides(fill = "none")
      
    } else {  # continuous
      p <- ggplot(plot_data, aes(x = regressor, y = expression)) +
        geom_point(alpha = 0.6) +
        geom_smooth(method = "lm", se = TRUE, color = "red") +
        labs(
          title = paste0(gene, " (p=", format(gene_result$p.value, digits = 3), ")"),
          x = regressor,
          y = paste("Expression (", layer, ")", sep = "")
        ) +
        theme_minimal()
    }
    
    plots[[i]] <- p
  }
  
  # Arrange plots
  do.call(grid.arrange, c(plots, ncol = 2))
}

# Example usage function
example_usage <- function() {
  # === CATEGORICAL VARIABLES ===
  # results_cat <- linear_seurat(sobj, 
  #                             regressor = "cell_type",
  #                             regressor.type = "categorical",
  #                             reference.level = "Control")
  
  # === ORDINAL VARIABLES ===
  # results_ord <- linear_seurat(sobj,
  #                             regressor = "disease_stage",
  #                             regressor.type = "ordinal",
  #                             ordinal.method = "linear")
  
  # === CONTINUOUS VARIABLES ===
  # results_cont <- linear_seurat(sobj,
  #                              regressor = "age",
  #                              regressor.type = "continuous")
}







#' Find Gene Signatures that Best Separate Target Variable
#'
#' @param data Seurat object, count matrix, or data.frame with genes as rows/columns
#' @param meta.data Optional metadata data.frame (required if data is not Seurat)
#' @param target_var Column name in metadata representing the target variable
#' @param target_group For numeric targets: quantile cutoff (0-1) or list(low=0.25, high=0.75)
#'                     For factor: specific levels to compare (default: all vs all)
#' @param method One of: "tree_based", "lasso", "limma", "nmf", "wilcoxon", "gam", "pca_loadings"
#' @param n_features Number of top features to return (default: 50)
#' @param preprocess Logical, whether to normalize/scale data (default: TRUE)
#' @param min_cells Minimum cells expressing gene (default: 10)
#' @param min_pct Minimum percentage of cells expressing gene (default: 0.01)
#' @param return_model Logical, return full model object (default: FALSE)
#' @param seed Random seed for reproducibility (default: 42)
#' @param ... Additional method-specific parameters
#'
#' @return List containing:
#'   - genes: Character vector of selected genes
#'   - weights: Named numeric vector of gene weights/importance
#'   - scores: Per-cell signature scores (if applicable)
#'   - performance: Separation metrics (AUC, accuracy, etc.)
#'   - method: Method used
#'   - model: Full model object (if return_model=TRUE)
#'
#' @examples
#' # Random Forest for binary classification
#' result <- find_gene_signature(seurat_obj, target_var="cell_type", 
#'                                target_group=c("TypeA", "TypeB"), 
#'                                method="tree_based")
#' 
#' # LASSO for continuous variable (top vs bottom quartile)
#' result <- find_gene_signature(seurat_obj, target_var="pseudotime", 
#'                                target_group=0.25, method="lasso")
#' 
#' # NMF for multi-class
#' result <- find_gene_signature(count_matrix, meta.data=metadata, 
#'                                target_var="condition", method="nmf")

find_gene_signature <- function(data, 
                                meta.data = NULL,
                                target_var,
                                target_group = NULL,
                                method = c("tree_based", "lasso", "limma", 
                                           "nmf", "wilcoxon", "gam", "pca_loadings"),
                                n_features = 50,
                                preprocess = TRUE,
                                min_cells = 10,
                                min_pct = 0.01,
                                return_model = FALSE,
                                fgs_seed = 42,
                                ...) {
  
  set.seed(fgs_seed)
  method <- match.arg(method)
  
  # ===
  # 1. Input validation and data extraction
  # ===
  
  # Check if Seurat object
  is_seurat <- inherits(data, "Seurat")
  
  if (is_seurat) {
    if (!requireNamespace("Seurat", quietly = TRUE)) {
      stop("Seurat package required but not installed")
    }
    if (is.null(meta.data)) {
      meta.data <- data@meta.data
    }
    # Extract normalized data or raw counts
    if ("data" %in% names(data@assays[[1]])) {
      expr_mat <- as.matrix(Seurat::GetAssayData(data, layer = "data"))
    } else {
      expr_mat <- as.matrix(Seurat::GetAssayData(data, layer = "counts"))
    }
  } else {
    # Assume matrix or data.frame
    if (is.null(meta.data)) {
      stop("meta.data must be provided when data is not a Seurat object")
    }
    expr_mat <- as.matrix(data)
    # Transpose if cells are rows
    if (nrow(expr_mat) == nrow(meta.data)) {
      expr_mat <- t(expr_mat)
    }
  }
  
  # Validate target_var exists
  if (!target_var %in% colnames(meta.data)) {
    stop(sprintf("target_var '%s' not found in metadata columns: %s", 
                 target_var, paste(colnames(meta.data), collapse=", ")))
  }
  
  # Align cells
  common_cells <- intersect(colnames(expr_mat), rownames(meta.data))
  if (length(common_cells) == 0) {
    stop("No common cells found between expression matrix and metadata")
  }
  expr_mat <- expr_mat[, common_cells]
  meta.data <- meta.data[common_cells, ]
  
  # ===
  # 2. Process target variable
  # ===
  
  target_values <- meta.data[[target_var]]
  target_type <- class(target_values)[1]
  
  if (is.numeric(target_values)) {
    # Continuous variable - create binary groups
    if (is.null(target_group)) {
      target_group <- 0.25  # default: bottom 25% vs top 25%
    }
    
    if (is.list(target_group)) {
      low_cutoff <- quantile(target_values, target_group$low, na.rm=TRUE)
      high_cutoff <- quantile(target_values, target_group$high, na.rm=TRUE)
      group_labels <- ifelse(target_values <= low_cutoff, "Low",
                             ifelse(target_values >= high_cutoff, "High", NA))
    } else if (length(target_group) == 1 && target_group < 1) {
      low_cutoff <- quantile(target_values, target_group, na.rm=TRUE)
      high_cutoff <- quantile(target_values, 1 - target_group, na.rm=TRUE)
      group_labels <- ifelse(target_values <= low_cutoff, "Low",
                             ifelse(target_values >= high_cutoff, "High", NA))
    } else {
      group_labels <- ifelse(target_values < target_group, "Low", "High")
    }
    
    # Remove NAs (middle group)
    keep_cells <- !is.na(group_labels)
    expr_mat <- expr_mat[, keep_cells]
    meta.data <- meta.data[keep_cells, ]
    target_binary <- factor(group_labels[keep_cells])
    
  } else {
    # Categorical variable
    if (!is.null(target_group)) {
      # Select specific groups
      keep_cells <- target_values %in% target_group
      expr_mat <- expr_mat[, keep_cells]
      meta.data <- meta.data[keep_cells, ]
      target_binary <- factor(target_values[keep_cells])
    } else {
      target_binary <- factor(target_values)
    }
  }
  
  if (length(unique(target_binary)) < 2) {
    stop("Target variable must have at least 2 groups after processing")
  }
  
  n_groups <- length(unique(target_binary))
  
  # ===
  # 3. Filter and preprocess genes
  # ===
  
  # Filter low-expressed genes
  n_cells_expr <- rowSums(expr_mat > 0)
  pct_cells_expr <- n_cells_expr / ncol(expr_mat)
  keep_genes <- (n_cells_expr >= min_cells) & (pct_cells_expr >= min_pct)
  
  expr_mat <- expr_mat[keep_genes, ]
  
  if (nrow(expr_mat) == 0) {
    stop("No genes pass filtering criteria")
  }
  
  # Preprocessing
  if (preprocess) {
    # Log-normalize if data appears to be raw counts
    if (max(expr_mat) > 100) {
      expr_mat <- log1p(expr_mat)
    }
    # Scale genes (z-score)
    if (method %in% c("lasso", "gam", "pca_loadings")) {
      gene_means <- rowMeans(expr_mat)
      gene_sds <- apply(expr_mat, 1, sd)
      gene_sds[gene_sds == 0] <- 1  # avoid division by zero
      expr_mat <- (expr_mat - gene_means) / gene_sds
    }
  }
  
  # ===
  # 4. Method-specific signature discovery
  # ===
  
  result <- switch(method,
                   
                   # ---
                   # Random Forest / Tree-based methods
                   # ---
                   tree_based = {
                     if (!requireNamespace("randomForest", quietly = TRUE)) {
                       stop("randomForest package required. Install with: install.packages('randomForest')")
                     }
                     
                     # Transpose for modeling (samples as rows)
                     X <- t(expr_mat)
                     y <- target_binary
                     
                     # Subsample genes if too many (RF can be slow)
                     if (nrow(expr_mat) > 2000) {
                       # Pre-filter by variance
                       gene_vars <- apply(expr_mat, 1, var)
                       top_var_genes <- names(sort(gene_vars, decreasing=TRUE)[1:2000])
                       X <- X[, top_var_genes]
                     }
                     
                     # Train Random Forest
                     rf_model <- randomForest::randomForest(
                       x = X, y = y,
                       ntree = 500,
                       importance = TRUE,
                       ...
                     )
                     
                     # Extract feature importance
                     importance_scores <- randomForest::importance(rf_model)
                     if (n_groups == 2) {
                       weights <- importance_scores[, "MeanDecreaseGini"]
                     } else {
                       weights <- rowMeans(importance_scores[, grep("MeanDecreaseGini", 
                                                                    colnames(importance_scores))])
                     }
                     
                     # Select top features
                     top_genes <- names(sort(weights, decreasing=TRUE)[1:min(n_features, length(weights))])
                     weights <- weights[top_genes]
                     
                     # Calculate signature scores
                     scores <- as.numeric(X[, top_genes] %*% weights)
                     names(scores) <- rownames(X)
                     
                     # Performance metrics
                     pred <- rf_model$predicted
                     if (n_groups == 2) {
                       if (requireNamespace("pROC", quietly = TRUE)) {
                         roc_obj <- pROC::roc(y, scores, quiet=TRUE)
                         auc <- as.numeric(pROC::auc(roc_obj))
                       } else {
                         auc <- NA
                       }
                       acc <- mean(pred == y)
                       perf <- list(accuracy = acc, auc = auc, confusion = table(pred, y))
                     } else {
                       acc <- mean(pred == y)
                       perf <- list(accuracy = acc, confusion = table(pred, y))
                     }
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = if(return_model) rf_model else NULL)
                   },
                   
                   # ---
                   # LASSO regression
                   # ---
                   lasso = {
                     if (!requireNamespace("glmnet", quietly = TRUE)) {
                       stop("glmnet package required. Install with: install.packages('glmnet')")
                     }
                     
                     X <- t(expr_mat)
                     y <- target_binary
                     
                     # Fit LASSO with cross-validation
                     if (n_groups == 2) {
                       cv_fit <- glmnet::cv.glmnet(X, y, family="binomial", alpha=1, ...)
                     } else {
                       cv_fit <- glmnet::cv.glmnet(X, y, family="multinomial", alpha=1, ...)
                     }
                     
                     # Extract coefficients at lambda.1se (more regularized)
                     coefs <- coef(cv_fit, s="lambda.1se")
                     
                     if (n_groups == 2) {
                       weights <- as.numeric(coefs[-1])  # remove intercept
                       names(weights) <- rownames(coefs)[-1]
                     } else {
                       # Average coefficients across classes
                       coef_list <- lapply(coefs, function(x) as.numeric(x[-1]))
                       weights <- rowMeans(do.call(cbind, coef_list))
                       names(weights) <- rownames(coefs[[1]])[-1]
                     }
                     
                     # Select non-zero coefficients
                     nonzero_genes <- names(weights)[weights != 0]
                     if (length(nonzero_genes) == 0) {
                       warning("No genes selected by LASSO. Returning top genes by coefficient magnitude.")
                       top_genes <- names(sort(abs(weights), decreasing=TRUE)[1:min(n_features, length(weights))])
                     } else {
                       top_genes <- nonzero_genes[1:min(n_features, length(nonzero_genes))]
                     }
                     weights <- weights[top_genes]
                     
                     # Signature scores
                     scores <- as.numeric(X[, top_genes] %*% weights)
                     names(scores) <- rownames(X)
                     
                     # Performance
                     pred_probs <- predict(cv_fit, newx=X, s="lambda.1se", type="response")
                     if (n_groups == 2) {
                       pred <- factor(ifelse(pred_probs > 0.5, levels(y)[2], levels(y)[1]), levels=levels(y))
                       if (requireNamespace("pROC", quietly = TRUE)) {
                         roc_obj <- pROC::roc(y, as.numeric(pred_probs), quiet=TRUE)
                         auc <- as.numeric(pROC::auc(roc_obj))
                       } else {
                         auc <- NA
                       }
                       acc <- mean(pred == y)
                       perf <- list(accuracy = acc, auc = auc, confusion = table(pred, y))
                     } else {
                       pred <- levels(y)[apply(pred_probs, 1, which.max)]
                       acc <- mean(pred == y)
                       perf <- list(accuracy = acc, confusion = table(pred, y))
                     }
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = if(return_model) cv_fit else NULL)
                   },
                   
                   # ---
                   # Differential Expression (limma/wilcoxon)
                   # ---
                   limma = {
                     if (!requireNamespace("limma", quietly = TRUE)) {
                       stop("limma package required. Install with: BiocManager::install('limma')")
                     }
                     
                     design <- model.matrix(~0 + target_binary)
                     colnames(design) <- levels(target_binary)
                     
                     # Fit linear model
                     fit <- limma::lmFit(expr_mat, design)
                     
                     # Define contrasts
                     if (n_groups == 2) {
                       contrast_str <- paste(levels(target_binary)[2], levels(target_binary)[1], sep="-")
                     } else {
                       # All pairwise comparisons
                       contrast_str <- limma::makeContrasts(
                         contrasts = combn(levels(target_binary), 2, function(x) paste(x, collapse="-")),
                         levels = design
                       )
                     }
                     
                     contrast_mat <- limma::makeContrasts(contrasts=contrast_str, levels=design)
                     fit2 <- limma::contrasts.fit(fit, contrast_mat)
                     fit2 <- limma::eBayes(fit2)
                     
                     # Extract results
                     top_table <- limma::topTable(fit2, number=Inf, sort.by="B")
                     
                     # Weights as moderated t-statistics
                     weights <- top_table$t
                     names(weights) <- rownames(top_table)
                     
                     top_genes <- rownames(top_table)[1:min(n_features, nrow(top_table))]
                     weights <- weights[top_genes]
                     
                     # Signature scores
                     scores <- colSums(expr_mat[top_genes, ] * weights)
                     
                     # Performance (simple)
                     score_cutoff <- median(scores)
                     pred <- factor(ifelse(scores > score_cutoff, levels(target_binary)[2], 
                                           levels(target_binary)[1]), levels=levels(target_binary))
                     acc <- mean(pred == target_binary)
                     perf <- list(accuracy = acc, top_table = top_table[top_genes, ])
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = if(return_model) fit2 else NULL)
                   },
                   
                   wilcoxon = {
                     # Fast Wilcoxon rank-sum test
                     pvals <- numeric(nrow(expr_mat))
                     effect_sizes <- numeric(nrow(expr_mat))
                     
                     for (i in 1:nrow(expr_mat)) {
                       if (n_groups == 2) {
                         group1 <- expr_mat[i, target_binary == levels(target_binary)[1]]
                         group2 <- expr_mat[i, target_binary == levels(target_binary)[2]]
                         test <- wilcox.test(group1, group2)
                         pvals[i] <- test$p.value
                         effect_sizes[i] <- median(group2) - median(group1)
                       } else {
                         test <- kruskal.test(expr_mat[i, ] ~ target_binary)
                         pvals[i] <- test$p.value
                         effect_sizes[i] <- var(tapply(expr_mat[i, ], target_binary, median))
                       }
                     }
                     
                     names(pvals) <- rownames(expr_mat)
                     names(effect_sizes) <- rownames(expr_mat)
                     
                     # Adjust p-values
                     padj <- p.adjust(pvals, method="BH")
                     
                     # Select by p-value and effect size
                     ranks <- rank(pvals) + rank(-abs(effect_sizes))
                     top_genes <- names(sort(ranks)[1:min(n_features, length(ranks))])
                     
                     weights <- effect_sizes[top_genes]
                     scores <- colSums(expr_mat[top_genes, ] * weights)
                     
                     perf <- list(pvalues = pvals[top_genes], padj = padj[top_genes],
                                  effect_sizes = effect_sizes[top_genes])
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = NULL)
                   },
                   
                   # ---
                   # NMF
                   # ---
                   nmf = {
                     if (!requireNamespace("NMF", quietly = TRUE)) {
                       stop("NMF package required. Install with: install.packages('NMF')")
                     }
                     
                     # Ensure non-negative data
                     expr_mat_pos <- expr_mat - min(expr_mat) + 0.01
                     
                     # Run NMF
                     rank <- min(n_groups + 2, 10)  # adaptive rank
                     
                     # The 'seed' argument from find_gene_signature conflicts with an NMF internal generic.
                     # We remove it and rely on the set.seed() call at the start of the function.
                     dots <- list(...)
                     dots$seed <- NULL
                     nmf_res <- do.call(NMF::nmf, c(list(x = expr_mat_pos, rank = rank), dots))

                     W <- NMF::basis(nmf_res)  # gene loadings
                     H <- NMF::coef(nmf_res)   # cell scores
                     
                     # Find component most associated with target
                     component_cors <- numeric(rank)
                     for (k in 1:rank) {
                       if (n_groups == 2) {
                         component_cors[k] <- abs(cor(H[k, ], as.numeric(target_binary)))
                       } else {
                         # ANOVA F-statistic
                         component_cors[k] <- summary(aov(H[k, ] ~ target_binary))[[1]][1, "F value"]
                       }
                     }
                     
                     best_component <- which.max(component_cors)
                     weights <- W[, best_component]
                     names(weights) <- rownames(expr_mat)
                     
                     top_genes <- names(sort(weights, decreasing=TRUE)[1:min(n_features, length(weights))])
                     weights <- weights[top_genes]
                     
                     scores <- H[best_component, ]
                     names(scores) <- colnames(expr_mat)
                     
                     perf <- list(component = best_component, correlation = component_cors[best_component])
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = if(return_model) nmf_res else NULL)
                   },
                   
                   # ---
                   # GAM (Generalized Additive Model)
                   # ---
                   gam = {
                     if (!requireNamespace("mgcv", quietly = TRUE)) {
                       stop("mgcv package required. Install with: install.packages('mgcv')")
                     }
                     
                     # Fit GAM for each gene
                     deviance_explained <- numeric(nrow(expr_mat))
                     
                     for (i in 1:min(500, nrow(expr_mat))) {  # limit for speed
                       gene_expr <- expr_mat[i, ]
                       if (n_groups == 2) {
                         gam_fit <- mgcv::gam(as.numeric(target_binary) ~ s(gene_expr), 
                                              family="binomial")
                       } else {
                         gam_fit <- mgcv::gam(as.numeric(target_binary) ~ s(gene_expr))
                       }
                       deviance_explained[i] <- summary(gam_fit)$dev.expl
                     }
                     
                     names(deviance_explained) <- rownames(expr_mat)[1:length(deviance_explained)]
                     
                     top_genes <- names(sort(deviance_explained, decreasing=TRUE)[1:min(n_features, 
                                                                                        sum(deviance_explained > 0))])
                     weights <- deviance_explained[top_genes]
                     
                     scores <- colSums(expr_mat[top_genes, ] * weights)
                     
                     perf <- list(deviance_explained = deviance_explained[top_genes])
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = NULL)
                   },
                   
                   # ---
                   # PCA loadings
                   # ---
                   pca_loadings = {
                     # Run PCA
                     pca_res <- prcomp(t(expr_mat), center=FALSE, scale.=FALSE)
                     
                     # Find PC most correlated with target
                     pc_cors <- numeric(min(50, ncol(pca_res$x)))
                     for (k in 1:length(pc_cors)) {
                       if (n_groups == 2) {
                         pc_cors[k] <- abs(cor(pca_res$x[, k], as.numeric(target_binary)))
                       } else {
                         pc_cors[k] <- summary(aov(pca_res$x[, k] ~ target_binary))[[1]][1, "F value"]
                       }
                     }
                     
                     best_pc <- which.max(pc_cors)
                     weights <- pca_res$rotation[, best_pc]
                     
                     top_genes <- names(sort(abs(weights), decreasing=TRUE)[1:min(n_features, length(weights))])
                     weights <- weights[top_genes]
                     
                     scores <- pca_res$x[, best_pc]
                     
                     perf <- list(PC = best_pc, correlation = pc_cors[best_pc],
                                  variance_explained = summary(pca_res)$importance[2, best_pc])
                     
                     list(genes = top_genes, weights = weights, scores = scores,
                          performance = perf, model = if(return_model) pca_res else NULL)
                   }
  )
  
  # ===
  # 5. Return results
  # ===
  
  result$method <- method
  result$target_var <- target_var
  result$n_groups <- n_groups
  result$n_cells <- ncol(expr_mat)
  
  class(result) <- c("gene_signature", "list")
  return(result)
}


# Helper function to score new data with signature
score_signature <- function(expr_data, signature, normalize=TRUE) {
  genes <- signature$genes
  weights <- signature$weights
  
  # Extract expression matrix
  if (inherits(expr_data, "Seurat")) {
    expr_mat <- as.matrix(Seurat::GetAssayData(expr_data, layer="data"))
  } else {
    expr_mat <- as.matrix(expr_data)
  }
  
  # Check gene availability
  available_genes <- intersect(genes, rownames(expr_mat))
  if (length(available_genes) == 0) {
    stop("None of the signature genes found in data")
  }
  if (length(available_genes) < length(genes)) {
    warning(sprintf("%d/%d signature genes not found in data", 
                    length(genes) - length(available_genes), length(genes)))
  }
  
  # Calculate scores
  weights <- weights[available_genes]
  scores <- colSums(expr_mat[available_genes, , drop=FALSE] * weights)
  
  if (normalize) {
    scores <- scale(scores)[,1]
  }
  
  return(scores)
}


#' Print Method for Gene Signature Objects
#'
#' @param x A gene_signature object
#' @param ... Additional arguments (not used)
#'
#' @export
print.gene_signature <- function(x, ...) {
  cat("Gene Signature Object\n")
  cat("====================\n")
  cat(sprintf("Method: %s\n", x$method))
  cat(sprintf("Target variable: %s (%d groups)\n", x$target_var, x$n_groups))
  cat(sprintf("Number of cells: %d\n", x$n_cells))
  cat(sprintf("Number of genes in signature: %d\n", length(x$genes)))
  cat(sprintf("\nTop 10 genes:\n"))
  print(head(data.frame(gene=x$genes, weight=x$weights[x$genes]), 10))
  
  if (!is.null(x$performance)) {
    cat("\nPerformance:\n")
    print(x$performance)
  }
}