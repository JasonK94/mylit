---
title: "stroke_total"
output: html_document
date: "2025-03-08"
---
# log
```
set1은 cellragner 7.2
set2은 cellranger 8.0.1

240425 ; revised 기준으로 합치려 함. GEM, exp_sample_no, set, group만 transfer하면 될듯함.
중복되는 column 최대한 없애서 saveRDS(meta,"/data/kjc1/projects/#130.stroke/sobj/meta_250425.rds")로 저장하였음

250508: R --max-mem-size=64G로 R을 켜줘야... 메모리 제한 안 걸리는 것 같다! 확인 중
kernel에서 굳이 안해도 될 것 같다. 일단 해결이 잘 안 됨. (문제는 파악해두는 게 좋겠다)
scVI는 결국 raw counts를 쓸 것이기 때문에, scVI에 feed 할 목적이라면 SCT는 굳이 안 살려서 저장해도 될듯. 용량이 3배 이상이 되는 듯.
250509:
1. SNP 부문에서 Barcode가 어떻게 처리되는 것인가?
1) 첫 ol의 AddMetaData에서 잘 일치하는지? Barcode_mapping_list 끝에 _1이 있음에도 잘 작동하는 이유가 무엇일까?
-> 이것은 잠재적으로 문제가 있다. 중복이 있을 수도 있기 때문에.
-> $Barcode에서 알아서 찾아 준다고는 한다.
duplicated(Barcode_mapping_list$Barcode)같은 걸 해봐야겠다.

2) colnames(ol[[i]])=ol[[i]]$Barcode를 추가해 sl에도 변환된 Barcode가 잘 추가되도록 하고, cell 수가 줄어들어도 AddMetaData가 잘 작동하도록.
3) 근데 애초에 SoupChannel에서 metaData를 추가해주면 문제가 없을 것 같다.
4) CreateSeuratObject에서도 meta.data를 명시해줄 수가 있다.
-> 잘 작동하므로, 이 둘로 해결. SoupChannel에 metaData를 추가하는 것은 redundant하고, HTO version에서 문제를 일으키니 빼주기.
2. HTO 부문에서 metadat 관련
1) sample_karo 말고 $Best_Sample에 추가하도록 하여 SNP와 compatible하게
2) GEM도 적절히 추가.
3) ol_time_point도 추가해서 추후 잘 제거할 수 있도록.

3. metadata 로직도 좀 수정해야 함.
1) meta_clinical1의 identifier는 sample_no 또는 exp_sample_no
2) meta_clinical2의 identifier는 sample_no.1
3) meta_seurat - SNP의 Best_Sample과 meta_clinical1의 exp_sample_no
```

# 퇴장
```{r}
set.seed(1234)
while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}
```

# libraries
```{r}
suppressMessages(suppressWarnings(library(Seurat)))
suppressMessages(suppressWarnings(library(scDblFinder)))
suppressMessages(suppressWarnings(library(SoupX)))
suppressMessages(suppressWarnings(library(reticulate)))
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(readxl)))
library(myR)

# metadata
metadata_join=function(meta1,meta2,join_key){
  meta1=meta1[,!duplicated(names(meta1))]
  meta2=meta2[,!duplicated(names(meta2))]
  cols_to_remove=setdiff(intersect(names(meta1),names(meta2)), join_key)
  meta2=meta2%>%
    select(-all_of(cols_to_remove))
  meta=meta1 %>%
  left_join(meta2,by=join_key)
  return(meta)
}
```

# Data First Generation: Pipeline & Metadata Incorporation & Integration
## defaulting
```{r}
ol=list()
sl=list()
```
## dir_list
```{r}
# SNP list

list_snp=list(
  GEM1="/data/kjc1/projects/#130.stroke/gems/stroke1/outs/filtered_feature_bc_matrix",
  GEM2="/data/kjc1/projects/#130.stroke/gems/stroke2/outs/filtered_feature_bc_matrix",
  GEM3="/data/kjc1/projects/#130.stroke/gems/stroke3/outs/filtered_feature_bc_matrix",
  GEM4="/data/kjc1/projects/#130.stroke/gems/stroke4/outs/filtered_feature_bc_matrix",
  GEM5="/data/kjc1/projects/#130.stroke/gems/GEX1/outs/filtered_feature_bc_matrix",
  GEM6="/data/kjc1/projects/#130.stroke/gems/GEX2/outs/filtered_feature_bc_matrix",
  GEM7="/data/kjc1/projects/#130.stroke/gems/GEX3/outs/filtered_feature_bc_matrix",
  GEM8="/data/kjc1/projects/#130.stroke/gems/GEX4/outs/filtered_feature_bc_matrix"
)


list_snp_raw=list(
  GEM1="/data/kjc1/projects/#130.stroke/gems/stroke1/outs/raw_feature_bc_matrix",
  GEM2="/data/kjc1/projects/#130.stroke/gems/stroke2/outs/raw_feature_bc_matrix",
  GEM3="/data/kjc1/projects/#130.stroke/gems/stroke3/outs/raw_feature_bc_matrix",
  GEM4="/data/kjc1/projects/#130.stroke/gems/stroke4/outs/raw_feature_bc_matrix",
  GEM5="/data/kjc1/projects/#130.stroke/gems/GEX1/outs/raw_feature_bc_matrix",
  GEM6="/data/kjc1/projects/#130.stroke/gems/GEX2/outs/raw_feature_bc_matrix",
  GEM7="/data/kjc1/projects/#130.stroke/gems/GEX3/outs/raw_feature_bc_matrix",
  GEM8="/data/kjc1/projects/#130.stroke/gems/GEX4/outs/raw_feature_bc_matrix"
)

list_demux=list(
  "/data/kjc1/projects/#130.stroke/demux/xlot_1_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_2_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_3_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_4_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_5_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_6_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_7_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_8_posterior.csv"
)

#HTO list; 이것은 사실 list가 아니라 vector다.

list_hto=list.dirs("/data/kjc1/projects/#130.stroke/count_matrix")
list_hto=list_hto[grep("_IS_",list_hto)]
list_hto <- list_hto[-11] #empty 8_IS_24
names(list_hto)=basename(list_hto)

list_hto_raw=list.dirs("/data/kjc1/projects/#130.stroke/count_matrix_raw")
list_hto_raw=list_hto_raw[-1]
names(list_hto_raw)=basename(list_hto_raw)

list_hto_raw_match=list(
  "14_IS_24"="GEM1_2",
  "18_IS_24"="GEM1_2",
  "22_IS_24"="GEM2_2",
  "23_IS_24"="GEM2_2",
  "28_IS_24"="GEM2_2",
  "1_IS_72"="Samples1_4",
  "2_IS_24"="Samples1_4",
  "2_IS_72"="Samples1_4",
  "4_IS_24"="Samples1_4",
  "4_IS_72"="Samples1_4",
  "8_IS_72"="Samples5_9"
)


save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/"

```



## test
```{r}
set.seed(1234)

sample_numbers=c(6,6,6,6,8,8,8,8)
barcode_mapping_list=list()

start_num=1
# SNP demultiplexing & object pipeline preprocessing
for(i in seq_along(list_snp)){
  # demultiplexing
  demux_data=read.csv(list_demux[[i]])
  colnames(demux_data)=c("BARCODE",generate_sample_names(start_num:(start_num+sample_numbers[i]-1)))
  start_num=start_num+sample_numbers[i]
  barcode_mapping_list[[i]]=get_barcode_mapping(demux_data)%>%
    mutate(droplet_demulti=ifelse(is_doublet(Best_Sample),"doublet_demulti","singlet_demulti"), GEM=paste0("GEM",i))%>%
    {rownames(.)=.$Barcode;
      .} %>%
    mutate(join_key=Best_Sample, day=1)
  
  # object pipeline preprocessing
  ol[[i]]=Read10X(list_snp[[i]])
  
  orig_n   <- ncol(ol[[i]])
  sample_n <- floor(orig_n / 100)   # 1/100 크기
  
  set.seed(1234)  # 재현성을 위한 시드 고정
  cells_keep <- sample(colnames(ol[[i]]), size = sample_n)
  
  ol[[i]]=ol[[i]][,cells_keep]
  
  sprintf("1. number:%d, raw count:%d",i,ncol(ol[[i]]))
  ol[[i]]=CreateSeuratObject(ol[[i]])
  
  ## demultiplexing - doublet removal
  ol[[i]]=AddMetaData(ol[[i]],barcode_mapping_list[[i]])
  
  ol[[i]]=subset(ol[[i]],droplet_demulti=="singlet_demulti")
  
  ## Pre-processing
  sprintf("2. number:%d, raw count:%d",i,ncol(ol[[i]]))
  # ol[[i]]=subset(ol[[i]],subset=percent.mt<5)
  ol[[i]]=SCTransform(ol[[i]],verbose=F)
  DefaultAssay(ol[[i]])="SCT"
  ol[[i]]=FindVariableFeatures(ol[[i]],verbose=F)
  ol[[i]]=RunPCA(ol[[i]],verbose=F)
  ol[[i]]=FindNeighbors(ol[[i]],verbose=F)
  ol[[i]]=FindClusters(ol[[i]],verbose=F)
  
  ## SoupX
  sprintf("sample: %s, step: soupx",i)
  raw_count=Read10X(list_snp_raw[[i]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  sc=SoupChannel(raw_count[rownames(ol[[i]]),],ol[[i]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[i]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  ## re-preprocessing
  sl[[i]]=CreateSeuratObject(out, project="LIT_2024_Stroke_SNPDemultiAndDoubletRemoval_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[i]]@meta.data)
  sl[[i]]=SCTransform(sl[[i]],verbose=F)
  DefaultAssay(sl[[i]])="SCT"
  sl[[i]]=FindVariableFeatures(sl[[i]],verbose=F)
  sl[[i]]=RunPCA(sl[[i]],verbose=F)
  sl[[i]]=FindNeighbors(sl[[i]],verbose=F)
  sl[[i]]=FindClusters(sl[[i]],verbose=F)
  
  ## scDblFinder doublet removal
  sce <- scDblFinder(GetAssayData(sl[[i]], layer= "counts"), clusters = Idents(sl[[i]]))
  sl[[i]]$"droplet"=sce$scDblFinder.class
  sl[[i]]=subset(sl[[i]],droplet=="singlet")
  sprintf("3. number:%d, raw count:%d",i,ncol(sl[[i]]))
  
  
  # saving
  save_seurat_to_h5ad(
    sl[[i]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0("stroke_GEM",i,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
  )
}

#HTO의 경우, HTO 갯수가 들어있는 layer도 있어서 명시적으로 layer 불러내어 SCTransform 시행 필요.
for(dir in list_hto){
  sample=basename(dir)
  # Extract first number (prefix)
  prefix <- stringr::str_extract(sample, "^\\d+")
  # Extract last number (time point)
  time_point <- stringr::str_extract(sample, "\\d+$")
  day=case_when(
    time_point=="72" ~3,
    time_point=="48" ~2,
    time_point=="24" ~1,
    time_point=="NA" ~NA
  )
  GEM_hto=basename(list_hto_raw[[list_hto_raw_match[[sample]]]])
  GEM=case_when(
    GEM_hto=="Samples1_4"~9,
    GEM_hto=="Samples5_9"~10,
    GEM_hto=="GEM1_2"~11,
    GEM_hto=="GEM2_2"~12
  )
  
  # HTO based demultiplexing already done
  
  # object pipeline preprocessing
  ol[[sample]]=Read10X(list_hto[[sample]])
  ol[[sample]]=ol[[sample]]$`Gene Expression`
  
  orig_n   <- ncol(ol[[sample]])
  sample_n <- floor(orig_n / 100)   # 1/100 크기
  
  set.seed(1234)  # 재현성을 위한 시드 고정
  cells_keep <- sample(colnames(ol[[sample]]), size = sample_n)
  ol[[sample]]=ol[[sample]][,cells_keep]
  
  sprintf("1. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  ol[[sample]]=CreateSeuratObject(ol[[sample]])
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=sample,col.name = "sample_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM_hto,col.name = "GEM_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM,col.name = "GEM")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=time_point,col.name = "ol_time_point")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=day,col.name = "day")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=colnames(ol[[sample]]),col.name = "Barcode")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=paste0(prefix,"_",day),col.name = "join_key")
  
  sprintf("2. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  # ol[[sample]]=subset(ol[[sample]],subset=percent.mt<5)
  ol[[sample]] <- SCTransform(
    ol[[sample]],
    assay           = "RNA",
    new.assay.name  = "SCT",
    verbose         = FALSE
  )
  DefaultAssay(ol[[sample]])="SCT"
  ol[[sample]]=FindVariableFeatures(ol[[sample]])
  ol[[sample]]=RunPCA(ol[[sample]], npcs = 5)
  ol[[sample]]=FindNeighbors(ol[[sample]], dims = 5)
  ol[[sample]]=FindClusters(ol[[sample]])
  
  ## SoupX
  sprintf("sample: %s, step: soupx",sample)
  raw_count=Read10X(list_hto_raw[[list_hto_raw_match[[sample]]]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  
  
  #sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts,metaData = ol[[i]]@meta.data)
  # Error in SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),  : 
  #   Rownames of metaData must match column names of table of counts.
  # In addition: Warning message:
  # In sort(colnames(toc)) == sort(rownames(metaData)) :
  #   longer object length is not a multiple of shorter object length
  
  sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[sample]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  sl[[sample]]=CreateSeuratObject(out, project="LIT_2023_Stroke_HTO_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[sample]]@meta.data)
  sl[[sample]]=SCTransform(sl[[sample]],verbose=F)
  DefaultAssay(sl[[sample]])="SCT"
  sl[[sample]]=FindVariableFeatures(sl[[sample]],verbose=F)
  sl[[sample]]=RunPCA(sl[[sample]],verbose=F, npcs = 5)
  sl[[sample]]=FindNeighbors(sl[[sample]],verbose=F,dims=5)
  sl[[sample]]=FindClusters(sl[[sample]],verbose=F)
  
  sce <- scDblFinder(GetAssayData(sl[[sample]], layer= "counts"), clusters = Idents(sl[[sample]]))
  sl[[sample]]$"droplet"=sce$scDblFinder.class
  sprintf("3. sample:%s, raw count:%f",sample,ncol(sl[[sample]]))
  

  # Seurat 객체에서 데이터 추출
  save_seurat_to_h5ad(
    sl[[sample]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0(sample,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
    )
}

# merging only carries raw/data/scale.data and meta.data slots.
# because there's no safe way to merge reductions, graphs, etc.
# set merge.SCT=TRUE

# features <- SelectIntegrationFeatures(object.list = ol, nfeatures = 3000)
# sct_list <- PrepSCTIntegration(object.list = ol, anchor.features = features) #what's this?

features <- SelectIntegrationFeatures(object.list = sl, nfeatures = 3000)
sct_list <- PrepSCTIntegration(object.list = sl, anchor.features = features) #what's this?
integrated_data <- FindIntegrationAnchors(object.list = sct_list, normalization.method = "SCT",
                                  anchor.features = features,reduction="rpca",
                                  k.anchor=20) #it makes anchorset object. but after IntegrateData it becomes seurat object. before rpca, RunPCA is needed
integrated_data <- IntegrateData(anchorset = integrated_data, normalization.method = "SCT")
# Re-SCTranform to merge multiple SCT layers
integrated_data=SCTransform(integrated_data)

# Run PCA on integrated data
integrated_data <- RunPCA(integrated_data, verbose = FALSE)
# Run UMAP/t-SNE and clustering
integrated_data <- RunUMAP(integrated_data, dims = 1:30) #The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric. To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'
integrated_data <- FindNeighbors(integrated_data, dims = 1:30)
# integrated_data <- FindClusters(integrated_data)
integrated_data <- FindClusters(integrated_data,graph.name = "SCT_snn")

DefaultAssay(integrated_data)="SCT"
integrated_data = PrepSCTFindMarkers(integrated_data)


markers=list()
for(cluster in levels(integrated_data$seurat_clusters)){
  markers[[cluster]]=FindMarkers(integrated_data, ident.1=cluster)
  markers[[cluster]]$gene=rownames(markers[[cluster]])
}

time1=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_beforeQC_",time1,".rds"))
#saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_SCT_integrated_beforeQC_",time1,".rds"))

time2=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_markers_",time2,".rds"))
#saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_markers_",time2,".rds"))

while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
```


## reading & integration
```{r}
set.seed(1234)

sample_numbers=c(6,6,6,6,8,8,8,8)
barcode_mapping_list=list()

start_num=1
# SNP demultiplexing & object pipeline preprocessing
for(i in seq_along(list_snp)){
  # demultiplexing
  demux_data=read.csv(list_demux[[i]])
  colnames(demux_data)=c("BARCODE",generate_sample_names(start_num:(start_num+sample_numbers[i]-1)))
  start_num=start_num+sample_numbers[i]
  barcode_mapping_list[[i]]=get_barcode_mapping(demux_data)%>%
    mutate(droplet_demulti=ifelse(is_doublet(Best_Sample),"doublet_demulti","singlet_demulti"), GEM=paste0("GEM",i), Barcode = paste0(Barcode, "_",i))%>%
    {rownames(.)=.$Barcode;
      .} %>%
    mutate(join_key=Best_Sample, day=1)
  
  # object pipeline preprocessing
  ol[[i]]=Read10X(list_snp[[i]])
  sprintf("1. number:%d, raw count:%d",i,ncol(ol[[i]]))
  ol[[i]]=CreateSeuratObject(ol[[i]])
  
  ## demultiplexing - doublet removal
  ol[[i]]=AddMetaData(ol[[i]],barcode_mapping_list[[i]])
  
  ol[[i]]=subset(ol[[i]],droplet_demulti=="singlet_demulti")
  
  ## Pre-processing
  sprintf("2. number:%d, raw count:%d",i,ncol(ol[[i]]))
  # ol[[i]]=subset(ol[[i]],subset=percent.mt<5)
  ol[[i]]=SCTransform(ol[[i]],verbose=F)
  DefaultAssay(ol[[i]])="SCT"
  ol[[i]]=FindVariableFeatures(ol[[i]],verbose=F)
  ol[[i]]=RunPCA(ol[[i]],verbose=F)
  ol[[i]]=FindNeighbors(ol[[i]],verbose=F)
  ol[[i]]=FindClusters(ol[[i]],verbose=F)
  
  ## SoupX
  sprintf("sample: %s, step: soupx",i)
  raw_count=Read10X(list_snp_raw[[i]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  sc=SoupChannel(raw_count[rownames(ol[[i]]),],ol[[i]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[i]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  ## re-preprocessing
  sl[[i]]=CreateSeuratObject(out, project="LIT_2024_Stroke_SNPDemultiAndDoubletRemoval_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[i]]@meta.data)
  sl[[i]]=SCTransform(sl[[i]],verbose=F)
  DefaultAssay(sl[[i]])="SCT"
  sl[[i]]=FindVariableFeatures(sl[[i]],verbose=F)
  sl[[i]]=RunPCA(sl[[i]],verbose=F)
  sl[[i]]=FindNeighbors(sl[[i]],verbose=F)
  sl[[i]]=FindClusters(sl[[i]],verbose=F)
  
  ## scDblFinder doublet removal
  sce <- scDblFinder(GetAssayData(sl[[i]], layer= "counts"), clusters = Idents(sl[[i]]))
  sl[[i]]$"droplet"=sce$scDblFinder.class
  sl[[i]]=subset(sl[[i]],droplet=="singlet")
  sprintf("3. number:%d, raw count:%d",i,ncol(sl[[i]]))
  
  
  # saving
  save_seurat_to_h5ad(
    sl[[i]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0("stroke_GEM",i,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
  )
}

#HTO의 경우, HTO 갯수가 들어있는 layer도 있어서 명시적으로 layer 불러내어 SCTransform 시행 필요.
for(dir in list_hto){
  sample=basename(dir)
  # Extract first number (prefix)
  prefix <- stringr::str_extract(sample, "^\\d+")
  # Extract last number (time point)
  time_point <- stringr::str_extract(sample, "\\d+$")
  day=case_when(
    time_point=="72" ~3,
    time_point=="48" ~2,
    time_point=="24" ~1,
    time_point=="NA" ~NA
  )
  GEM_hto=basename(list_hto_raw[[list_hto_raw_match[[sample]]]])
  GEM=case_when(
    GEM_hto=="Samples1_4"~9,
    GEM_hto=="Samples5_9"~10,
    GEM_hto=="GEM1_2"~11,
    GEM_hto=="GEM2_2"~12
  )
  
  # HTO based demultiplexing already done
  
  # object pipeline preprocessing
  ol[[sample]]=Read10X(list_hto[[sample]])
  sprintf("1. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  ol[[sample]]=CreateSeuratObject(ol[[sample]])
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=sample,col.name = "sample_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM_hto,col.name = "GEM_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM,col.name = "GEM")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=time_point,col.name = "ol_time_point")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=day,col.name = "day")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=colnames(ol[[sample]]),col.name = "Barcode")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=paste0(prefix,"_",day),col.name = "join_key")
  
  sprintf("2. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  # ol[[sample]]=subset(ol[[sample]],subset=percent.mt<5)
  ol[[sample]] <- SCTransform(
    ol[[sample]],
    assay           = "RNA",
    layer           = "counts.Gene Expression",
    new.assay.name  = "SCT",
    verbose         = FALSE
  )
  DefaultAssay(ol[[sample]])="SCT"
  ol[[sample]]=FindVariableFeatures(ol[[sample]])
  ol[[sample]]=RunPCA(ol[[sample]])
  ol[[sample]]=FindNeighbors(ol[[sample]])
  ol[[sample]]=FindClusters(ol[[sample]])
  
  ## SoupX
  sprintf("sample: %s, step: soupx",sample)
  raw_count=Read10X(list_hto_raw[[list_hto_raw_match[[sample]]]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  
  
  #sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts,metaData = ol[[i]]@meta.data)
  # Error in SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),  : 
  #   Rownames of metaData must match column names of table of counts.
  # In addition: Warning message:
  # In sort(colnames(toc)) == sort(rownames(metaData)) :
  #   longer object length is not a multiple of shorter object length
  
  sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[sample]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  sl[[sample]]=CreateSeuratObject(out, project="LIT_2023_Stroke_HTO_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[sample]]@meta.data)
  sl[[sample]]=SCTransform(sl[[sample]],verbose=F)
  DefaultAssay(sl[[sample]])="SCT"
  sl[[sample]]=FindVariableFeatures(sl[[sample]],verbose=F)
  sl[[sample]]=RunPCA(sl[[sample]],verbose=F)
  sl[[sample]]=FindNeighbors(sl[[sample]],verbose=F)
  sl[[sample]]=FindClusters(sl[[sample]],verbose=F)
  
  sce <- scDblFinder(GetAssayData(sl[[sample]], layer= "counts"), clusters = Idents(sl[[sample]]))
  sl[[sample]]$"droplet"=sce$scDblFinder.class
  sprintf("3. sample:%s, raw count:%f",sample,ncol(sl[[sample]]))
  

  # Seurat 객체에서 데이터 추출
  save_seurat_to_h5ad(
    sl[[sample]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0(sample,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
    )
}

# merging only carries raw/data/scale.data and meta.data slots.
# because there's no safe way to merge reductions, graphs, etc.
# set merge.SCT=TRUE

# features <- SelectIntegrationFeatures(object.list = ol, nfeatures = 3000)
# sct_list <- PrepSCTIntegration(object.list = ol, anchor.features = features) #what's this?

features <- SelectIntegrationFeatures(object.list = sl, nfeatures = 3000)
sct_list <- PrepSCTIntegration(object.list = sl, anchor.features = features) #what's this?
integrated_data <- FindIntegrationAnchors(object.list = sct_list, normalization.method = "SCT",
                                  anchor.features = features,reduction="rpca",
                                  k.anchor=20) #it makes anchorset object. but after IntegrateData it becomes seurat object. before rpca, RunPCA is needed
integrated_data <- IntegrateData(anchorset = integrated_data, normalization.method = "SCT")
# Re-SCTranform to merge multiple SCT layers
integrated_data=SCTransform(integrated_data)

# Run PCA on integrated data
integrated_data <- RunPCA(integrated_data, verbose = FALSE)
# Run UMAP/t-SNE and clustering
integrated_data <- RunUMAP(integrated_data, dims = 1:30) #The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric. To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'
integrated_data <- FindNeighbors(integrated_data, dims = 1:30)
# integrated_data <- FindClusters(integrated_data)
integrated_data <- FindClusters(integrated_data,graph.name = "SCT_snn")

DefaultAssay(integrated_data)="SCT"
integrated_data = PrepSCTFindMarkers(integrated_data)


markers=list()
for(cluster in levels(integrated_data$seurat_clusters)){
  markers[[cluster]]=FindMarkers(integrated_data, ident.1=cluster)
  markers[[cluster]]$gene=rownames(markers[[cluster]])
}

time1=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_beforeQC_",time1,".rds"))
#saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_SCT_integrated_beforeQC_",time1,".rds"))

time2=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_markers_",time2,".rds"))
#saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_markers_",time2,".rds"))

while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}

```


## metadata prep
```{r}
### GEM n, exp_sample_no 챙기기: 모든 환자를 포함. 대신 필수 정보만 들어있음.
meta_clinical1=readxl::read_xlsx("/data/kjc1/projects/#130.stroke/sample_info_250407_merged.xlsx", .name_repair = "minimal") %>%
  .[,!duplicated(names(.))] %>%
  filter(type == "IS")
  # 여기서 GEM, exp_sample_no,set, group만 건지면 될 듯. 여기서의 group은 맨 처음 설정한 1~4와, 내가 임의로 준 0, 6임.
#6은 IS가 아니고, 0은...

### clinical metadata 챙기기: IS 환자의 다양한 변수.
meta_clinical2=readxl::read_excel("/data/kjc1/projects/#130.stroke/variables_IS_250225_data_cleaned_250416_revised.xlsx", .name_repair = "minimal") %>%
  .[,!duplicated(names(.))]

overlap_cols=intersect(names(meta_clinical1),names(meta_clinical2))
cols_to_remove=setdiff(overlap_cols,"hos_no")

meta_clinical2_prepped=meta_clinical2 %>%
  select(-all_of(cols_to_remove))

### 합치기
meta_clinical3=meta_clinical1 %>%
  left_join(meta_clinical2_prepped,by="hos_no") %>% #EMR ID로 join하겠다!
  mutate(join_key_samp=ifelse(multi_method=="SNP",exp_sample_no,sample_no))

meta_seurat=sss@meta.data

overlap_cols=intersect(names(meta_seurat),names(meta_clinical3))
cols_to_remove=setdiff(overlap_cols,"hos_no")
meta_seurat=meta_seurat%>%
  select(-all_of(cols_to_remove))

meta_joined=right_join(meta_seurat, meta_clinical3, by=c("join_key"="join_key_samp")) #left를 쓸지, right를 쓸지는 매우 중요한 이슈다..

```


# reloading
```{r}
s=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_beforeQC_25-04-24-12-37.rds")
metadata=readRDS("/data/kjc1/projects/#130.stroke/sobj/meta_250425.rds")
s=AddMetaData(s,metadata)
is=subset(s,type=="IS"&time_point!=72)
stroke=subset(is,group3%in%c(1,2))
#markers=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_markers_25-03-10-18-05.rds")
```


# plottings for annotation
## overview
```{r}
table(s$seurat_clusters)
table(s$droplet, s$seurat_clusters)
VlnPlot(s,features=c("nFeature_RNA","nCount_RNA","percent.mt"), pt.size = 0, group.by = )
DimPlot(s,label=T)
DimPlot(s,split.by="GEM")
myhm_genesets2(s, gene_sets=G_azi)

table(is$seurat_clusters)
table(is$droplet, is$seurat_clusters)
VlnPlot(is,features=c("nFeature_RNA","nCount_RNA","percent.mt"), pt.size = 0, group.by = )
DimPlot(is,label=T)
DimPlot(is,split.by="GEM")
myhm_genesets2(is, gene_sets=G_azi)
```


## markers - Log2FC > 0 sorting
```{r}
for(i in names(markers)){
  markers[[i]]$gene=rownames(markers[[i]])
  print(i)
  print(paste(markers[[i]][markers[[i]]$avg_log2FC>0,][1:100,]$gene,collapse = ", "))
}
```

### FindAllMarker & Filtering 세련되게
```{r}
marker_list=list()
all_markers=FindAllMarkers(is)

all_markers_filtered=all_markers[!grepl("^RPL|^RPS|^MT-|^(AC\\d+|AL\\d+|ENSG|LINC)",all_markers$gene),]
for(cluster in unique(all_markers_filtered$cluster)){
  marker_list[[paste0("cluster_",cluster)]]=all_markers_filtered[all_markers_filtered[["cluster"]]==cluster,]
}

View(marker_list[["cluster_14"]])


```
### 다시 sorting
```{r}

for(i in c(14,17)){
  index=paste0("cluster_",i)
  print(index)
  markers=marker_list[[index]]%>%
    .[.$pct.1>0.1,]%>%
    .[order(.$avg_log2FC,decreasing=T),]
  markers_vector=markers[1:100,]$gene
  print(paste(markers_vector,collapse = ", "))
}

for(i in levels(is$seurat_clusters)){
  index=paste0("cluster_",i)
  print(index)
  markers=marker_list[[index]]%>%
    .[.$pct.1>0.1,]%>%
    .[order(.$avg_log2FC,decreasing=T),]
  markers_vector=markers[1:100,]$gene
  print(paste(markers_vector,collapse = ", "))
}
```


## FeaturePlot
```{r}
# CD8 vs CD4
FeaturePlot(is,features=c("CD8A","CD8B", "IL7R","CXCR4","CD40LG","IKZF3","BCL11B"))
# NKc
FeaturePlot(is,features=c("KLRD1","CD94", "KLRB1", "KLRK1","NKG2D","KLRF1"))
# CD16+ Monocytes
FeaturePlot(is, c("FCGR3A"))
# Cytotoxicity
FeaturePlot(is, c("NKG7", "GNLY", "GZMB", "GZMH", "GZMA", "GZMM", "PRF1", "CTSW"))
# Next Steps:
# If you want to distinguish NK cells from CD8+ T cells, check expression of CD3E/CD3D (T cells) and NCAM1/CD56, FCGR3A/CD16 (NK cells).
# If KIR genes and NCRs (NCR1/NKp46, NCR3/NKp30) are highly expressed without strong TCR markers, it's very likely an NK cell cluster.
FeaturePlot(is, c("CD3E","CD3D","NCAM1","FCGR3A","NCR1","NCR3"))
"
Monocytes: High CD14, VCAN, FCN1 but low MERTK, CD163.
Macrophages: High CD68, MERTK, CD163, MARCO.
To assess activation status, check expression of:
M1 macrophage markers (pro-inflammatory): IL1B, TNF, CXCL8, INOS (NOS2).
M2 macrophage markers (anti-inflammatory): MRC1 (CD206), ARG1, IL10.
"
#monocytes
FeaturePlot(is,c("CD14","VCAN","FCN1","MERTK","CD163"))
#Macrophages
FeaturePlot(is,c("CD68","MERTK","CD163","MARCO"))
#M1: TNFA, NOS2가 없
FeaturePlot(is,c("IL1B","TNFA","CXCL8","NOS2"))
#M2: 없
FeaturePlot(is,c("MRC1","ARG1","IL10"))


#gdTc; CD45RO=PTPRC, CD103=ITGAE, NKG2D=KLRK1, TNF
FeaturePlot(is,c("TRDC","TRGC1","TRGC2","CD3D","CD3E","CD3G","CD2","CD7","CD27","CD45RO","CD69","NKG7","GNLY","GZMB","GZMA","PRF1","KLRD1","KLRG1","KLRK1","IFNG","TRDV1","CD103","TRDV2","BTN3A1","NKG2D","FCGR3A","TNF","ITGAE","PTPRC"))

# NKT cell markers CD161=KLRB1, CD56="NCAM1", IL13=P600
NKT_markers <- c(
  "TRAV10", "TRBV25-1", 
  "CD3D", "CD3E", "CD3G", "NCAM1", 
  "CD4", "CD8A", "CD8B", 
  "NKG7", "GNLY", "GZMB", "GZMA", "PRF1", 
  "KLRD1", "KLRK1", "KLRB1", "IFNG", "TNF", "IL4",
  "ICOS", "PDCD1", "CD1D"
)
FeaturePlot(is,NKT_markers)

# ASDC
FeaturePlot(is,c("AXL","SIGLEC6"))
```

## DotPlot
```{r}
DotPlot(s,features=c("CCL4","CCL5","CD40LG"))
```

# annotation

## first annotation - naming
```{r}
is$annotation1=case_when(
  is$seurat_clusters%in%c(0,2,6,9,10,19,26) ~ "NK/T",
  is$seurat_clusters%in%c(1,3,5,8,11,12,13) ~ "mo",
  is$seurat_clusters%in%c(15,18, 7, 21) ~ "NKc",
  is$seurat_clusters%in%c(4,22,23) ~ "Bc",
  is$seurat_clusters%in%c(16) ~ "erythrocytes",
  is$seurat_clusters%in%c(14) ~ "CD4Tem",
  is$seurat_clusters%in%c(17) ~ "Mph_M2",
  is$seurat_clusters%in%c(20,27) ~ "DCs",
  is$seurat_clusters%in%c(25) ~ "plasma",
  is$seurat_clusters%in%c(28) ~ "mast/plt",
  is$seurat_clusters%in%c(30) ~ "hspc",
  is$seurat_clusters%in%c(24, 29) ~ "doublets",
  TRUE ~ is$seurat_clusters
)

DimPlot(is,group.by="annotation1",label=T)

```
### GPT
```{r}
## annotation1 : my refined cell‑type calls for each Seurat cluster
is$annotation_gpt <- dplyr::case_when(
  ## ‑‑‑ T‑lineage ----------------------------------------------------------
  is$seurat_clusters %in% 0                ~ "CD4_CentralMemory",
  is$seurat_clusters %in% 2                ~ "CD4_Naive",
  is$seurat_clusters %in% 6                ~ "CD8_EM_GZMK",
  is$seurat_clusters %in% c(10, 21)        ~ "CD8_Effector/EMRA",
  is$seurat_clusters %in% 14               ~ "CD4_EffectorMemory",
  is$seurat_clusters %in% 19               ~ "CD8_Naive",
  is$seurat_clusters %in% 9                ~ "γδ_T",
  is$seurat_clusters %in% 26               ~ "Cycling_T",
  
  ## ‑‑‑ NK lineage --------------------------------------------------------
  is$seurat_clusters %in% c(7, 15, 18)     ~ "NK_Cytotoxic",
  
  ## ‑‑‑ Monocytes / Macrophages ------------------------------------------
  is$seurat_clusters %in% c(1, 3, 8, 11, 13) ~ "Monocyte_Inflammatory",
  is$seurat_clusters %in% 12               ~ "Monocyte_NonClassical",
  is$seurat_clusters %in% c(5, 17)         ~ "M2‑like_Macrophage",
  
  ## ‑‑‑ Dendritic cells ---------------------------------------------------
  is$seurat_clusters %in% c(20, 27)    ~ "DendriticCells",
  
  ## ‑‑‑ B lineage ---------------------------------------------------------
  is$seurat_clusters %in% c(4, 22, 23)         ~ "B_Naive/Transitional",
  is$seurat_clusters %in% 25               ~ "Plasma",
  
  ## ‑‑‑ Erythroid & Megakaryocyte lines ----------------------------------
  is$seurat_clusters %in% c(16, 24)        ~ "Erythroid",
  is$seurat_clusters %in% 28               ~ "Megakaryocyte/Platelet",
  
  ## ‑‑‑ Haematopoietic progenitors & doublets ----------------------------
  is$seurat_clusters %in% 30               ~ "HSPC",
  is$seurat_clusters %in% 29               ~ "Doublet",
  
  ## fallback: keep numeric cluster label
  TRUE ~ as.character(is$seurat_clusters)
)
DimPlot(is,group.by="annotation_gpt",label=T)
```
#### GPT - detailed
```{r}
## annotation2 : more granular immune subsets
library(dplyr)

is$annotation_gpt2 <- case_when(
  ## ---- CD4 T ----------------------------------------------------------------
  is$seurat_clusters %in% 0              ~ "CD4_TCM"  ,   # CCR7+ IL7R+ CD40LG+
  is$seurat_clusters %in% 2              ~ "CD4_TN"   ,   # Naïve
  is$seurat_clusters %in% 14             ~ "CD4_TEM"  ,   # CCR7– GZMK(low) PKCθhi
  ## Cycling CD4/CD8 mixed
  is$seurat_clusters %in% 26             ~ "T_Cycling",
  
  ## ---- CD8 T ----------------------------------------------------------------
  is$seurat_clusters %in% 19             ~ "CD8_TN"   ,   # Naïve
  is$seurat_clusters %in% 6              ~ "CD8_TEM_GZMK",# Early eff‑mem (GZMK IL7R+)
  is$seurat_clusters %in% 21             ~ "CD8_TEM_Cyto",# CCR7– GZMA/H high
  is$seurat_clusters %in% 10             ~ "CD8_EMRA" ,    # CD45RA re‑expr / GNLY GZMB PRF1
  is$seurat_clusters %in% 9              ~ "γδ_T",
  
  ## ---- NK lineage -----------------------------------------------------------
  is$seurat_clusters %in% 7              ~ "NK_CD56bright",
  is$seurat_clusters %in% c(15,18)       ~ "NK_CD56dim",
  
  ## ---- Monocytes / Macrophages ---------------------------------------------
  is$seurat_clusters %in% c(1,3,8,11,13) ~ "Mono_Classical/Inflam",
  is$seurat_clusters %in% 12             ~ "Mono_NonClassical",
  is$seurat_clusters %in% c(5,17)        ~ "Macrophage_M2like",
  
  ## ---- Dendritic cells ------------------------------------------------------
  is$seurat_clusters %in% 20             ~ "cDC2_CD1C",
  is$seurat_clusters %in% 27             ~ "pDC",
  
  ## ---- B lineage ------------------------------------------------------------
  is$seurat_clusters %in% c(4,22)        ~ "B_Naive/Transitional",
  is$seurat_clusters %in% 23             ~ "B_Memory_FCRL5",
  is$seurat_clusters %in% 25             ~ "Plasmablast/Plasma",
  
  ## ---- Others ---------------------------------------------------------------
  is$seurat_clusters %in% c(16,24)       ~ "Erythroid",
  is$seurat_clusters %in% 28             ~ "Megakaryocyte/Platelet",
  is$seurat_clusters %in% 30             ~ "HSPC",
  is$seurat_clusters %in% 29             ~ "Doublet",
  
  TRUE ~ as.character(is$seurat_clusters)
)

```

### addmodule scores
#### prep
```{r}
## -------------------- 1.3  merge & clean -------------------------------
sig_list_raw <- c(G_azi, G_new)

## keep only genes present in the object
genes_present <- rownames(is)
sig_list <- lapply(sig_list_raw, \(vec) intersect(vec, genes_present))

## drop empty entries (occasionally none of the genes exist)
sig_list <- sig_list[lengths(sig_list) > 0L]

## preview
purrr::imap(sig_list, \(v, n) sprintf("%s : %d genes", n, length(v))) %>% head()
```
#### AddModuleScores
```{r}
## 2.1  Iterate through the list
for (nm in names(sig_list)) {
  is <- AddModuleScore(
    object   = is,
    features = list(sig_list[[nm]]),  # AddModuleScore expects a *list of lists*
    name     = nm,                    # column will be e.g.  "memB_FCRL51"
    assay    = "SCT",
    seed     = 42
  )
}

## 2.2  Inspect a few scores
head(is@meta.data %>% select(matches("_1$")))

## 2.3  Quick UMAP overlay
FeaturePlot(is, features = c("memB_FCRL51", "CD8_GZMK1"), cols = c("lightgrey","red"))

## 2.4  Violin by your annotated celltypes
VlnPlot(is, features = "Treg_core1", group.by = "annotation1", pt.size = 0)

```
### signature featureplot
```{r}
FeaturePlot(is, features=c("cDC1_20241","cDC2_20241"))

```

### trim
```{r}
is=subset(is,subset=droplet=="singlet")
is=subset(is,subset=seurat_clusters%in%setdiff(1:30, c(16, 24,28,29,30)))
is$annotation1_1=case_when(
  is$annotation1 %in% c("NK/T", "CD4Tem") ~ "Tc",
  is$annotation1 == "DCs" ~ "DC",
  is$annotation1 %in% c("Mph_M2") ~ "mo",
  TRUE ~ as.character(is$annotation1)
)
DimPlot(is, group.by="annotation1_1",label=T)

is$time_point2=case_when(
  is.na(is$time_point) ~ "24",
  TRUE ~ as.character(is$time_point)
)
```

## second

### subclustering
```{r}
set.seed(1234)
Idents(s)="annotation1"
s=FindSubCluster(s,"Tc",subcluster.name = "Tc_sub",graph.name = "integrated_snn")
s=FindSubCluster(s,"Bc",subcluster.name = "Bc_sub",graph.name = "integrated_snn")
s=FindSubCluster(s,"NKc",subcluster.name = "NKc_sub",graph.name = "integrated_snn")
s=FindSubCluster(s,"CD14+Monocytes",subcluster.name = "Mo14_sub",graph.name = "integrated_snn")
DimPlot(s,label=T,group.by="Tc_sub")
```

### what is 12?
```{r}
m_12_nk=FindMarkers(s,ident.1 = 12,ident.2 = "NKc")
m_12_Tc=FindMarkers(s,ident.1 = 12,ident.2 = "Tc")
m_12=FindMarkers(s,ident.1 = "12")
printmy(m_12_nk)
printmy(m_12_Tc)
printmy(m_12)

s$annotation2=s$annotation1
Idents(s)="annotation2"
s=RenameIdents(s,"12"="Tc2")
s$annotation2=Idents(s)
s=FindSubCluster(s,"Tc2",subcluster.name = "Tc2_sub",graph.name = "integrated_snn")
```

### FindMarkers
```{r}
m_Bc=list()
m_Tc=list()
m_Tc2=list()
m_NKc=list()
m_Mo14=list()


Idents(s)="Bc_sub"
for(cluster in unique(s$Bc_sub[which(s$annotation1=="Bc")])){
  m_Bc[[cluster]]=FindMarkers(s, ident.1=cluster, ident.2=setdiff(unique(s$Bc_sub[which(s$annotation1=="Bc")]),cluster))
  m_Bc[[cluster]]$gene=rownames(m_Bc[[cluster]])
  m_Bc[[cluster]]$pct.diff=m_Bc[[cluster]]$pct.1-m_Bc[[cluster]]$pct.2
}
Idents(s)="Tc_sub"
for(cluster in unique(s$Tc_sub[which(s$annotation1=="Tc")])){
  m_Tc[[cluster]]=FindMarkers(s, ident.1=cluster, ident.2=setdiff(unique(s$Tc_sub[which(s$annotation1=="Tc")]),cluster))
  m_Tc[[cluster]]$gene=rownames(m_Tc[[cluster]])
  m_Tc[[cluster]]$pct.diff=m_Tc[[cluster]]$pct.1-m_Tc[[cluster]]$pct.2
}
Idents(s)="Tc2_sub"
for(cluster in unique(s$Tc2_sub[which(s$annotation2=="Tc_2")])){
  m_Tc2[[cluster]]=FindMarkers(s, ident.1=cluster, ident.2=setdiff(unique(s$Tc2_sub[which(s$annotation2=="Tc_2")]),cluster))
  m_Tc2[[cluster]]$gene=rownames(m_Tc2[[cluster]])
  m_Tc2[[cluster]]$pct.diff=m_Tc2[[cluster]]$pct.1-m_Tc2[[cluster]]$pct.2
}
Idents(s)="NKc_sub"
for(cluster in unique(s$NKc_sub[which(s$annotation1=="NKc")])){
  m_NKc[[cluster]]=FindMarkers(s, ident.1=cluster, ident.2=setdiff(unique(s$NKc_sub[which(s$annotation1=="NKc")]),cluster))
  m_NKc[[cluster]]$gene=rownames(m_NKc[[cluster]])
  m_NKc[[cluster]]$pct.diff=m_NKc[[cluster]]$pct.1-m_NKc[[cluster]]$pct.2
}
Idents(s)="Mo14_sub"
for(cluster in unique(s$Mo14_sub[which(s$annotation1=="CD14+Monocytes")])){
  m_Mo14[[cluster]]=FindMarkers(s, ident.1=cluster, ident.2=setdiff(unique(s$Mo14_sub[which(s$annotation1=="CD14+Monocytes")]),cluster))
  m_Mo14[[cluster]]$gene=rownames(m_Mo14[[cluster]])
  m_Mo14[[cluster]]$pct.diff=m_Mo14[[cluster]]$pct.1-m_Mo14[[cluster]]$pct.2
}

printMy(m_Bc)
printMy(m_Tc)
printMy(m_Tc2)
printMy(m_NKc)
printMy(m_Mo14)

# m_Bc_=list()
# m_Tc_=list()
# m_Tc2_=list()
# m_NKc_=list()
# m_Mo14_=list()
# for(name in names(m_Bc)){
#   marker=fm_re(m_Bc[[name]])
#   m_Bc_[[name]]=marker
# }
# for(name in names(m_Tc)){
#   marker=fm_re(m_Tc[[name]])
#   m_Tc_[[name]]=marker
# }
# for(name in names(m_Tc2)){
#   marker=fm_re(m_Tc2[[name]])
#   m_Tc2_[[name]]=marker
# }
# for(name in names(m_NKc)){
#   marker=fm_re(m_NKc[[name]])
#   m_NKc_[[name]]=marker
# }
# for(name in names(m_Mo14)){
#   marker=fm_re(m_Mo14[[name]])
#   m_Mo14_[[name]]=marker
# }

while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}
```


### plotting
```{r}
DimPlot(s,group.by="Bc_sub",label=T)
DimPlot(s,group.by="Tc_sub",label=T)
DimPlot(s,group.by="Tc2_sub",label=T)
DimPlot(s,group.by="NKc_sub",label=T)
DimPlot(s,group.by="Mo14_sub",label=T)

# Bc=subset(s,subset=annotation2=="Bc")
# Tc=subset(s,subset=annotation2%in%c("Tc","Tc_2"))
# NKc=subset(s,subset=annotation2=="NKc")
# Mo14=subset(s,subset=annotation2=="Mo14")

Idents(s)="Bc_sub"
DotPlot(s, group.by="Bc_sub",features=c("CXCR4","FCER2","TCL1A","DUSP1","CD69","CD37","CD83","IGHM","IGHD","PRF1","GZMB","GZMA","GNLY"),idents="Bc")+
  scale_color_viridis_c(option = "magma")


```

### naming each
```{r}
s@meta.data <- s@meta.data %>% mutate(
    Bc_sub = case_when(
        Bc_sub %in% c("Bc_0") ~ "B_naive",
        Bc_sub %in% c("Bc_1") ~ "B_transitional",
        Bc_sub %in% c("Bc_2") ~ "B_plasmablast",
        Bc_sub %in% c("Bc_3") ~ "B_GC",
        Bc_sub %in% c("Bc_4") ~ "B_memory",
        Bc_sub %in% c("Bc_5") ~ "B_inflammatory",
        Bc_sub %in% c("Bc_6") ~ "B_cytotoxic",
        Bc_sub %in% c("Bc_7") ~ "B_Tc_contam",
        Bc_sub %in% c("Bc_8") ~ "B_monocytelike",
        TRUE ~ Bc_sub
    )
)

s@meta.data <- s@meta.data %>%
  mutate(
    Tc_sub = case_when(
      Tc_sub %in% c("Tc_0") ~ "T_cd4_activated",
      Tc_sub %in% c("Tc_1") ~ "T_cd8_CTL",
      Tc_sub %in% c("Tc_2") ~ "T_cd8_cm",
      Tc_sub %in% c("Tc_3") ~ "T_reg",
      Tc_sub %in% c("Tc_4") ~ "T_cd8_CTL+",
      Tc_sub %in% c("Tc_5") ~ "T_cd8_NKlike",
      Tc_sub %in% c("Tc_6") ~ "T_cd4_naive",
      Tc_sub %in% c("Tc_7") ~ "T_cd4_cm",
      Tc_sub %in% c("Tc_8") ~ "T_cd8_naive",
      Tc_sub %in% c("Tc_9") ~ "T_cd8_CTL_tr",
      Tc_sub %in% c("Tc_10") ~ "T_gdT/innate_like",
      Tc_sub %in% c("Tc_11") ~ "T_platelet_contam",
      TRUE ~ Tc_sub
    )
  )

s@meta.data <- s@meta.data %>%
  mutate(
    Tc2_sub = case_when(
      Tc2_sub %in% c("Tc2_0") ~ "Tc2_cd8_naive/cm",
      Tc2_sub %in% c("Tc2_1") ~ "Tc2_cd8_CTL",
      Tc2_sub %in% c("Tc2_2") ~ "Tc2_cd8_reg",
      Tc2_sub %in% c("Tc2_3") ~ "Tc2_cd8_tr_inflammatory",
      Tc2_sub %in% c("Tc2_4") ~ "Tc2_cd8_mt_proliferative/activated",
      Tc2_sub %in% c("Tc2_5") ~ "Tc2_cd8_",
      Tc2_sub %in% c("Tc2_6") ~ "Tc2_cd4_naive",
      TRUE ~ Tc2_sub
    )
  )

s@meta.data <- s@meta.data %>%
  mutate(
    NKc_sub = case_when(
      NKc_sub %in% c("NKc_0") ~ "NK_CD56+",
      NKc_sub %in% c("NKc_1") ~ "NK_Cytotoxic_terminal",
      NKc_sub %in% c("NKc_2") ~ "NK_Cytotoxic_tr",
      NKc_sub %in% c("NKc_3") ~ "NK_early_diff",
      NKc_sub %in% c("NKc_4") ~ "NK_activated",
      NKc_sub %in% c("NKc_5") ~ "NK_circulating",
      NKc_sub %in% c("NKc_6") ~ "NK_activated_proliferating",
      NKc_sub %in% c("NKc_7") ~ "NK_Tc_contam",
      TRUE ~ NKc_sub
    )
  )

s@meta.data <- s@meta.data %>%
  mutate(
    Mo14_sub = case_when(
      Mo14_sub %in% c("CD14+Monocytes_0") ~ "CD14+Mo_inflammatory",
      Mo14_sub %in% c("CD14+Monocytes_1") ~ "CD14+Mo_reg_tr",
      Mo14_sub %in% c("CD14+Monocytes_2") ~ "CD14+Mo_Ag_presenting",
      Mo14_sub %in% c("CD14+Monocytes_3") ~ "CD14+Mo_inflammatory_circ",
      Mo14_sub %in% c("CD14+Monocytes_4") ~ "CD14+Mo_classical",
      Mo14_sub %in% c("CD14+Monocytes_5") ~ "CD14+Mo_CD8_like",
      Mo14_sub %in% c("CD14+Monocytes_6") ~ "CD14+Mo_Macrophage_diff",
      Mo14_sub %in% c("CD14+Monocytes_7") ~ "CD14+Mo_IFN_responsive",
      Mo14_sub %in% c("CD14+Monocytes_8") ~ "CD14+Mo_aniviral",
      Mo14_sub %in% c("CD14+Monocytes_9") ~ "CD14+Mo_Bc_associated",
      TRUE ~ Mo14_sub
    )
  )

```

### naming annotation2
```{r}
s@meta.data <- s@meta.data %>%
  mutate(
    annotation3 = case_when(
      annotation1 == "Bc" ~ case_when(
        Bc_sub %in% c("Bc_0") ~ "B_naive",
        Bc_sub %in% c("Bc_1") ~ "B_transitional",
        Bc_sub %in% c("Bc_2") ~ "B_plasmablast",
        Bc_sub %in% c("Bc_3") ~ "B_GC",
        Bc_sub %in% c("Bc_4") ~ "B_memory",
        Bc_sub %in% c("Bc_5") ~ "B_inflammatory",
        Bc_sub %in% c("Bc_6") ~ "B_cytotoxic",
        Bc_sub %in% c("Bc_7") ~ "B_Tc_contam",
        Bc_sub %in% c("Bc_8") ~ "B_monocytelike",
        TRUE ~ Bc_sub
      ),
      annotation1 == "Tc" ~ case_when(
        Tc_sub %in% c("Tc_0") ~ "T_cd4_activated",
        Tc_sub %in% c("Tc_1") ~ "T_cd8_CTL",
        Tc_sub %in% c("Tc_2") ~ "T_cd8_cm",
        Tc_sub %in% c("Tc_3") ~ "T_reg",
        Tc_sub %in% c("Tc_4") ~ "T_cd8_CTL+",
        Tc_sub %in% c("Tc_5") ~ "T_cd8_NKlike",
        Tc_sub %in% c("Tc_6") ~ "T_cd4_naive",
        Tc_sub %in% c("Tc_7") ~ "T_cd4_cm",
        Tc_sub %in% c("Tc_8") ~ "T_cd8_naive",
        Tc_sub %in% c("Tc_9") ~ "T_cd8_CTL_tr",
        Tc_sub %in% c("Tc_10") ~ "T_gdT/innate_like",
        Tc_sub %in% c("Tc_11") ~ "T_platelet_contam",
        TRUE ~ Tc_sub
      ),
      annotation1 == "12" ~ case_when(
        Tc2_sub %in% c("Tc2_0") ~ "Tc2_cd8_naive/cm",
        Tc2_sub %in% c("Tc2_1") ~ "Tc2_cd8_CTL",
        Tc2_sub %in% c("Tc2_2") ~ "Tc2_cd8_reg",
        Tc2_sub %in% c("Tc2_3") ~ "Tc2_cd8_tr_inflammatory",
        Tc2_sub %in% c("Tc2_4") ~ "Tc2_cd8_mt_proliferative/activated",
        Tc2_sub %in% c("Tc2_5") ~ "Tc2_cd8_",
        Tc2_sub %in% c("Tc2_6") ~ "Tc2_cd4_naive",
        TRUE ~ Tc2_sub
      ),
      annotation1 == "NKc" ~ case_when(
        NKc_sub %in% c("NKc_0") ~ "NK_CD56+",
        NKc_sub %in% c("NKc_1") ~ "NK_Cytotoxic_terminal",
        NKc_sub %in% c("NKc_2") ~ "NK_Cytotoxic_tr",
        NKc_sub %in% c("NKc_3") ~ "NK_early_diff",
        NKc_sub %in% c("NKc_4") ~ "NK_activated",
        NKc_sub %in% c("NKc_5") ~ "NK_circulating",
        NKc_sub %in% c("NKc_6") ~ "NK_activated_proliferating",
        NKc_sub %in% c("NKc_7") ~ "NK_Tc_contam",
        TRUE ~ NKc_sub
      ),
      annotation1 == "CD14+Monocytes" ~ case_when(
        Mo14_sub %in% c("CD14+Monocytes_0") ~ "CD14+Mo_inflammatory",
        Mo14_sub %in% c("CD14+Monocytes_1") ~ "CD14+Mo_reg_tr",
        Mo14_sub %in% c("CD14+Monocytes_2") ~ "CD14+Mo_Ag_presenting",
        Mo14_sub %in% c("CD14+Monocytes_3") ~ "CD14+Mo_inflammatory_circ",
        Mo14_sub %in% c("CD14+Monocytes_4") ~ "CD14+Mo_classical",
        Mo14_sub %in% c("CD14+Monocytes_5") ~ "CD14+Mo_CD8_like",
        Mo14_sub %in% c("CD14+Monocytes_6") ~ "CD14+Mo_Macrophage_diff",
        Mo14_sub %in% c("CD14+Monocytes_7") ~ "CD14+Mo_IFN_responsive",
        Mo14_sub %in% c("CD14+Monocytes_8") ~ "CD14+Mo_aniviral",
        Mo14_sub %in% c("CD14+Monocytes_9") ~ "CD14+Mo_Bc_associated",
        TRUE ~ Mo14_sub
      ),
      TRUE ~ annotation1  # subclustering 대상이 아니면 기존 annotation1 값 유지
    )
  )

saveRDS(s@meta.data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_SCT_metadata_",format(Sys.time(),"%y-%m-%d-%H-%M"),".rds"))
```
###subsetting & if PrepSCTFindMarkers fail

```{r}
stroke=subset(s,type=="IS")
stroke=PrepSCTFindMarkers(stroke)
# Check how many SCT models you have
names(stroke@assays$SCT@SCTModel.list)

# If there's more than one, you can remove extra ones:
stroke@assays$SCT@SCTModel.list <- stroke@assays$SCT@SCTModel.list[1]

# Then run:
stroke <- PrepSCTFindMarkers(stroke, assay = "SCT")
marker_nih <- FindMarkers(stroke, ident.1="high", group.by="nih_change_level", assay = "SCT")

```
# DEG analysis
## Frequency analysis

### visualization and statistics
```{r}
acmb(s,identity = "annotation1",group.by="type")
p=plot_cluster_freqs(s, identity="annotation2",group.by="type", add_significance = TRUE)
print(p)

p=test_cluster_association(s,variable_of_interest = "type", covariates=c("age.x","last_normal_dt"))
print(p)
forest_plot=plot_cluster_stats(p,plot_type = "forest")
```

## FindMarkers - by prognosis

```{r}
markers2=list()

Idents(is)="annotation1_1"
for(celltype in setdiff(unique(is$annotation1_1),c("DC","plasma"))){
  markers2[[celltype]]=FindMarkers(is,ident.1=2,group.by="group3",subset.ident=celltype)
  markers2[[celltype]]$gene=rownames(markers2[[celltype]])
  assign(paste0("marker_",celltype,"2"))=fm_re(markers2[[celltype]],"+",0.001)
  assign(paste0("marker_",celltype,"1"))=fm_re(markers2[[celltype]],"-",0.001)
}

marker_group_Tc_2=fm_re(marker_group_Tc,"+",0.001)
marker_group_Tc_1=fm_re(marker_group_Tc,"-",0.001)
marker_group_Bc_2=fm_re(marker_group_Bc,"+",0.001)
marker_group_Bc_1=fm_re(marker_group_Bc,"-",0.001)
marker_group_Mo_2=fm_re(marker_group_Mo,"+",0.001)
marker_group_Mo_1=fm_re(marker_group_Mo,"-",0.001)
marker_group_NKc_2=fm_re(marker_group_NKc,"+",0.001)
marker_group_NKc_1=fm_re(marker_group_NKc,"-",0.001)

# for(name in names(markers2)){
#   print(name)
#   print(paste(markers2[[name]][markers2[[name]]$avg_log2FC>0,]$gene[1:100],collapse = ", "))
#   print("-negative")
#   print(paste(markers2[[name]][markers2[[name]]$avg_log2FC<0,]$gene[1:100],collapse = ", "))
# }
```

## AddMetaData
```{r}
ribosomal_genes <- grep(pattern = "^(RPL|RPS)", x = rownames(s), value = TRUE)
rbs_expression <- FetchData(object = s, vars = ribosomal_genes)
means=rowMeans(rbs_expression)
# 메타데이터로 추가
s <- AddMetaData(object = s, metadata = means, col.name = "rbs")

VlnPlot(s,features="rbs",group.by="annotation1",pt.size=0)
# Idents(s)="cell_group"
VlnPlot(s,features="rbs",group.by="cell_group",pt.size=0,idents = c("Bc_3","Bc_4","Tc_3","Tc_4","cDC_3","cDC_4"))

Idents(s)="group"
VlnPlot(s,features="rbs",group.by="annotation1",split.by="group",pt.size=0,idents=c("3","4"))+stat_compare_means()
VlnPlot(subset(s,subset=annotation1%in%c("Tc","Bc","gdTc","cDC","CD14+Monocytes","CD16+Monocytes","NKc")),features="rbs",group.by="annotation1",split.by = "group",pt.size=0,idents=c("3","4"))+stat_compare_means()
```
## 
```{r}

```
## 
```{r}

```
## 
```{r}

```


# Advanced Freq Analysis

```{r}
# Run the complete analysis
analysis_results <- analyze_cell_type_frequencies(
  seurat_obj = s,
  cell_type_col = "annotation1",
  sample_col = "sample_no",
  main_var = "type",
  covariates = c("sex", "age.x", "nih1d"),
  methods = c("lm")
)

# Create a dashboard of results
dashboard <- create_cell_type_dashboard(analysis_results)
```


```{r}
cell_freqs <- extract_cell_type_freq(
  seurat_obj = s,
  cell_type_col = "annotation1",  # column with cell type annotations
  sample_col = "sample_no",    # column with patient IDs
  metadata_cols = c("type", "sex", "age.x", "nih1d")
)

# View the results
head(cell_freqs$wide)  # Wide format (each cell type is a column)
head(cell_freqs$long)  # Long format (cell types in rows)

analysis_results <- analyze_cell_type_frequencies(
  seurat_obj = s,
  cell_type_col = "annotation1",
  sample_col = "sample_no",
  main_var = "type",        # Main variable of interest
  covariates = c("sex", "age"),     # Covariates to account for
  metadata_cols = c("nih1d"),    # Additional metadata
  categorical_vars = c("type", "sex"),  # Specify categorical variables
  methods = c("lm")   # Methods to use
)

# Extract results
cell_frequencies <- analysis_results$freq_data
univariate_tests <- analysis_results$univariate_results
multivariable_models <- analysis_results$multivariable_results

# View significant cell types from univariate analysis
sig_cell_types <- univariate_tests[univariate_tests$significant, ]
print(sig_cell_types)

# View plots
print(analysis_results$plots$cell_type_freq)

# For a specific cell type, view variable importance from random forest
top_cell_type <- sig_cell_types$cell_type[1]
print(analysis_results$plots$importance[[top_cell_type]][["random_forest"]])

#-------------------------------------------------
# Example 3: Working with seurat_obj metadata directly
#-------------------------------------------------

# In practice, we often want to examine the metadata first
# Here's how to do that with a Seurat object:

# examine_metadata <- function(seurat_obj) {
#   # Extract metadata
#   meta <- seurat_obj@meta.data
# 
#   # Print column names
#   cat("Metadata columns:", paste(colnames(meta), collapse=", "), "\n\n")
# 
#   # For each column, show basic statistics
#   for (col in colnames(meta)) {
#     cat("Column:", col, "\n")
# 
#     # If numeric, show summary
#     if (is.numeric(meta[[col]])) {
#       print(summary(meta[[col]]))
#     } else {
#       # If categorical, show frequency table
#       freq_table <- table(meta[[col]])
#       print(freq_table)
# 
#       # Also show percentages
#       pct_table <- prop.table(freq_table) * 100
#       print(round(pct_table, 2))
#     }
#     cat("\n")
#   }
# 
#   return(meta)
# }
# 
# metadata <- examine_metadata(stroke_seurat)

#-------------------------------------------------
# Example 4: Custom analysis for specific cell types
#-------------------------------------------------

# If you want to focus on specific cell types of interest:

# cell_types_of_interest <- c("T_cells", "Microglia", "Astrocytes")
#
# # Run univariate analysis for these cell types
# custom_univariate <- univariate_analysis(
#   freq_data = cell_freqs$wide,
#   var_of_interest = "disease_type",
#   cell_types = cell_types_of_interest,
#   is_categorical = TRUE
# )
#
# print(custom_univariate)
#
# # For cell types with significant differences, run multivariable analysis
# sig_cells <- custom_univariate$cell_type[custom_univariate$significant]
#
# for (cell_type in sig_cells) {
#   # Run lasso regression
#   lasso_model <- multivariable_analysis(
#     freq_data = cell_freqs$wide,
#     cell_type = cell_type,
#     main_var = "disease_type",
#     covariates = c("sex", "age", "severity"),
#     method = "lasso"
#   )
#
#   # Plot variable importance
#   importance_plot <- plot_variable_importance(
#     model_result = lasso_model,
#     title = paste("Importance for", cell_type)
#   )
#
#   print(importance_plot)
# }

#-------------------------------------------------
# Example 5: Using a real-world dataset
#-------------------------------------------------

# This example shows how to apply these functions to a real dataset

# 1. Load and preprocess your Seurat object
# stroke_seurat <- readRDS("path/to/your/seurat_object.rds")

# 2. Make sure cell types are annotated
# If not already annotated, you might need to run clustering and annotation
# stroke_seurat <- FindNeighbors(stroke_seurat, dims = 1:20)
# stroke_seurat <- FindClusters(stroke_seurat, resolution = 0.5)
# stroke_seurat <- RenameIdents(stroke_seurat, ...)  # Assign cell type names
# stroke_seurat$cell_type <- Idents(stroke_seurat)

# 3. Extract frequencies and run analysis
# analysis_results <- analyze_cell_type_frequencies(
#   seurat_obj = stroke_seurat,
#   cell_type_col = "cell_type",
#   sample_col = "patient_id",
#   main_var = "disease_type",
#   covariates = c("sex", "age", "severity")
# )

# 4. Save results to files
# save(analysis_results, file = "cell_type_analysis_results.RData")
#
# # Save univariate results to CSV
# write.csv(analysis_results$univariate_results, "univariate_results.csv", row.names = FALSE)
#
# # Save plots to PDF
# pdf("cell_type_plots.pdf", width = 10, height = 8)
# print(analysis_results$plots$cell_type_freq)
# for (cell_type in names(analysis_results$plots$importance)) {
#   for (method in names(analysis_results$plots$importance[[cell_type]])) {
#     print(analysis_results$plots$importance[[cell_type]][[method]])
#   }
# }
# dev.off()
```

# prognosis outcome
```{r}
meta_merged$nih_change_numeric <- as.numeric(as.character(meta_merged$nih_change))

# 2) 변환된 값의 중앙값 구하기 (NA는 제외)
median_val <- median(meta_merged$nih_change_numeric, na.rm = TRUE)
# 3) 중앙값을 기준으로 "high", "low" 분류
#    NA를 어떻게 처리할지는 ifelse문이나 dplyr::case_when 등을 활용해 조건 지정
# meta_merged$nih_change_level <- ifelse(
#   meta_merged$nih_change_numeric >= median_val, 
#   "high", 
#   "low"
# )

# (선택) NA는 따로 처리하고 싶다면 예:
meta_merged$nih_change_level <- ifelse(
  is.na(meta_merged$nih_change_numeric), 
  NA,
  ifelse(meta_merged$nih_change_numeric >= median_val, "high", "low")
)

stroke$Best_Sample=as.character(stroke$Best_Sample)
stroke=AddMetaData(stroke,left_join(stroke@meta.data,meta_merged,by=c("Best_Sample"="exp_sample_no")))
stroke=PrepSCTFindMarkers(stroke)

marker_nih=FindMarkers(stroke,ident.1="high",group.by="nih_change_level")
marker_nih$gene=rownames(marker_nih)
marker_nih <- marker_nih %>%
  filter(!grepl("^RPS|^RPL", gene))

marker_group=FindMarkers(stroke,ident.1="3",group.by="group")


marker_group$gene=rownames(marker_group)
marker_group <- marker_group %>%
  filter(!grepl("^RPS|^RPL", gene))

# marker_nih_bad=marker_nih[marker_nih$avg_log2FC>0,]
# marker_nih_good=marker_nih[marker_nih$avg_log2FC<0,]
# 
# marker_group_3=marker_group[marker_group$avg_log2FC>0,]
# marker_group_4=marker_group[marker_group$avg_log2FC<0,]

marker_nih_bad=marker_nih[marker_nih$avg_log2FC>0&marker_nih$p_val_adj<0.001,]
marker_nih_good=marker_nih[marker_nih$avg_log2FC<0&marker_nih$p_val_adj<0.001,]

marker_group_3=marker_group[marker_group$avg_log2FC>0&marker_group$p_val_adj<0.001,]
marker_group_4=marker_group[marker_group$avg_log2FC<0&marker_group$p_val_adj<0.001,]


ggvenn::ggvenn(
    list(bad=marker_nih_bad$gene,good=marker_nih_good$gene,g3=marker_group_3$gene,g4=marker_group_4$gene),
    c("bad","good","g3","g4"),
    show_percentage=TRUE
)
paste(intersect(marker_nih_bad$gene,marker_group_3$gene),collapse = ", ")
paste(intersect(marker_nih_good$gene,marker_group_4$gene),collapse = ", ")
```
## others
```{r}
stroke=subset(is,subset=time_point2!="72")
stroke=subset(is,subset=group3%in%c(1,2))
stroke=SCTransform(stroke, assay="RNA")
#stroke=PrepSCTFindMarkers(stroke)



Idents(stroke)="group3"
# marker_nih_re=FindMarkers(stroke,ident.1="high",group.by="nih_change_level", subset.ident=c("3","4"))
marker_nih_re=FindMarkers(stroke,ident.1="2",group.by="group3")
marker_nih_re_bad=fm_re(marker_nih_re,"+",0.001)
marker_nih_re_good=fm_re(marker_nih_re,"-",0.001)

Idents(stroke)="annotation1_1"
marker_group_Tc=FindMarkers(stroke,ident.1="2",ident.2="1",group.by="group3",subset.ident = "Tc")
marker_group_Bc=FindMarkers(stroke,ident.1="2",ident.2="1",group.by="group3", subset.ident = "Bc")
marker_group_Mo=FindMarkers(stroke,ident.1="2",ident.2="1",group.by="group3", subset.ident=c("mo"))
marker_group_NKc=FindMarkers(stroke,ident.1="2",ident.2="1",group.by="group3", subset.ident = "NKc")

marker_group_Tc=fm_filter(marker_group_Tc)
marker_group_Bc=fm_filter(marker_group_Bc)
marker_group_Mo=fm_filter(marker_group_Mo)
marker_group_NKc=fm_filter(marker_group_NKc)

marker_group_Tc_3=fm_re(marker_group_Tc,"+",0.01)
marker_group_Tc_4=fm_re(marker_group_Tc,"-",0.01)
marker_group_Bc_3=fm_re(marker_group_Bc,"+",0.01)
marker_group_Bc_4=fm_re(marker_group_Bc,"-",0.01)
marker_group_Mo_3=fm_re(marker_group_Mo,"+",0.01)
marker_group_Mo_4=fm_re(marker_group_Mo,"-",0.01)
marker_group_NKc_3=fm_re(marker_group_NKc,"+",0.01)
marker_group_NKc_4=fm_re(marker_group_NKc,"-",0.01)

marker_group_Tc_3=fm_re(marker_group_Tc,"+",0.001)
marker_group_Tc_4=fm_re(marker_group_Tc,"-",0.001)
marker_group_Bc_3=fm_re(marker_group_Bc,"+",0.001)
marker_group_Bc_4=fm_re(marker_group_Bc,"-",0.001)
marker_group_Mo_3=fm_re(marker_group_Mo,"+",0.001)
marker_group_Mo_4=fm_re(marker_group_Mo,"-",0.001)
marker_group_NKc_3=fm_re(marker_group_NKc,"+",0.001)
marker_group_NKc_4=fm_re(marker_group_NKc,"-",0.001)

nih_tc=mygv(marker_nih_re,marker_group_Tc)
nih_bc=mygv(marker_nih_re,marker_group_Bc)
nih_mo=mygv(marker_nih_re,marker_group_Mo)
nih_nk=mygv(marker_nih_re,marker_group_NKc)

full_bad=ggvenn::ggvenn(
    list(bad_Tc=intersect(marker_nih_re_bad$gene,marker_group_Tc_3$gene),
         bad_Bc=intersect(marker_nih_re_bad$gene,marker_group_Bc_3$gene),
         bad_Mo=intersect(marker_nih_re_bad$gene,marker_group_Mo_3$gene),
         bad_NKc=intersect(marker_nih_re_bad$gene,marker_group_NKc_3$gene)),
    c("bad_Tc","bad_Bc","bad_Mo","bad_NKc"),
    show_percentage=TRUE
)

full_bad_good=ggvenn::ggvenn(
    list(bad_Tc=intersect(marker_nih_re_bad$gene,marker_group_Tc_4$gene),
         bad_Bc=intersect(marker_nih_re_bad$gene,marker_group_Bc_4$gene),
         bad_Mo=intersect(marker_nih_re_bad$gene,marker_group_Mo_4$gene),
         bad_NKc=intersect(marker_nih_re_bad$gene,marker_group_NKc_4$gene)),
    c("bad_Tc","bad_Bc","bad_Mo","bad_NKc"),
    show_percentage=TRUE
)
full_good=ggvenn::ggvenn(
    list(good_Tc=intersect(marker_nih_re_good$gene,marker_group_Tc_4$gene),
         good_Bc=intersect(marker_nih_re_good$gene,marker_group_Bc_4$gene),
         good_Mo=intersect(marker_nih_re_good$gene,marker_group_Mo_4$gene),
         good_NKc=intersect(marker_nih_re_good$gene,marker_group_NKc_4$gene)),
    c("good_Tc","good_Bc","good_Mo","good_NKc"),
    show_percentage=TRUE
)

full_good_bad=ggvenn::ggvenn(
    list(good_Tc3=intersect(marker_nih_re_good$gene,marker_group_Tc_3$gene),
         good_Bc3=intersect(marker_nih_re_good$gene,marker_group_Bc_3$gene),
         good_Mo3=intersect(marker_nih_re_good$gene,marker_group_Mo_3$gene),
         good_NKc3=intersect(marker_nih_re_good$gene,marker_group_NKc_3$gene)),
    c("good_Tc3","good_Bc3","good_Mo3","good_NKc3"),
    show_percentage=TRUE
)

paste(intersect(marker_nih_re_bad$gene,marker_group_Tc_3$gene),collapse = ", ")
paste(intersect(marker_nih_re_good$gene,marker_group_Tc_4$gene),collapse = ", ")
paste(intersect(marker_nih_re_bad$gene,marker_group_Bc_3$gene),collapse = ", ")
paste(intersect(marker_nih_re_good$gene,marker_group_Bc_4$gene),collapse = ", ")
paste(intersect(marker_nih_re_bad$gene,marker_group_Mo_3$gene),collapse = ", ")
paste(intersect(marker_nih_re_good$gene,marker_group_Mo_4$gene),collapse = ", ")
paste(intersect(marker_nih_re_bad$gene,marker_group_NKc_3$gene),collapse = ", ")
paste(intersect(marker_nih_re_good$gene,marker_group_NKc_4$gene),collapse = ", ")

all_bad=Reduce(intersect,
       list(marker_nih_re_bad$gene,
          marker_group_Tc_3$gene,
          marker_group_Bc_3$gene,
          marker_group_Mo_3$gene,
          marker_group_NKc_3$gene)
)
all_good=Reduce(intersect,
       list(marker_nih_re_good$gene,
          marker_group_Tc_4$gene,
          marker_group_Bc_4$gene,
          marker_group_Mo_4$gene,
          marker_group_NKc_4$gene)
)



full_bad=ggvenn::ggvenn(
    list(bad_Tc=marker_group_Tc_3$gene,
         bad_Bc=marker_group_Bc_3$gene,
         bad_Mo=marker_group_Mo_3$gene,
         bad_NKc=marker_group_NKc_3$gene),
    c("bad_Tc","bad_Bc","bad_Mo","bad_NKc"),
    show_percentage=TRUE
)

paste(setdiff(marker_group_Tc_3$gene,c(marker_group_Bc_3$gene,marker_group_Mo_3$gene)),collapse = ", ")
paste(setdiff(marker_group_Bc_3$gene,c(marker_group_Tc_3$gene,marker_group_Mo_3$gene)),collapse = ", ")
paste(setdiff(marker_group_Mo_3$gene,c(marker_group_Tc_3$gene,marker_group_Bc_3$gene)),collapse = ", ")
paste(setdiff(marker_group_NKc_3$gene,c(marker_group_Mo_3$gene, marker_group_Tc_3$gene)),collapse = ", ")
paste(setdiff(intersect(marker_group_Bc_3$gene,marker_group_Tc_3$gene),marker_group_Mo_3$gene),collapse = ", ")
paste(setdiff(intersect(marker_group_Tc_3$gene,marker_group_Mo_3$gene),marker_group_Bc_3$gene),collapse = ", ")

paste(intersect(intersect(marker_group_Bc_3$gene,marker_group_Tc_3$gene),marker_group_Mo_3$gene),collapse = ", ")
paste(intersect(marker_group_NKc_3$gene,marker_group_Mo_3$gene),collapse = ", ")
paste(intersect(marker_group_Bc_3$gene,marker_group_Mo_3$gene),collapse = ", ")

```

### 체계적으로...
```{r}
# 1) 리스트로 묶기
marker_lists <- list(
  Tc  = marker_group_Tc_3$gene,
  Bc  = marker_group_Bc_3$gene,
  Mo  = marker_group_Mo_3$gene,
  NKc = marker_group_NKc_3$gene
)

# 2) 조합별로 해당 조건에 맞는 gene 계산
all_names <- names(marker_lists)
n <- length(all_names)

result <- list()
for (k in 1:n) {
  # k개짜리 조합 생성
  combs <- combn(all_names, k, simplify = FALSE)
  for (inc in combs) {
    exc <- setdiff(all_names, inc)
    # 포함된 그룹들에 모두 존재하는 gene 추출
    genes <- Reduce(intersect, marker_lists[inc])
    # 제외된 그룹에 하나라도 있으면 제거
    if (length(exc) > 0) {
      genes <- setdiff(genes, unlist(marker_lists[exc]))
    }
    # 결과에 저장 (키는 "Tc&Bc" 등)
    key <- paste(inc, collapse = "&")
    result[[key]] <- genes
  }
}

# 3) 출력 예시: 조합별로 쉼표로 붙여서 보기
for (nm in names(result)) {
  cat(sprintf("%-15s : %s\n", nm, paste(result[[nm]], collapse = ", ")), "\n")
}

```
### FeaturePlot
```{r}
FeaturePlot(stroke, features=c("YBX3","BTG1","DUSP1","CHASERR","TXNIP","JUND"))
Idents(stroke)="annotation1_1"
VlnPlot(stroke, features=c("YBX3","BTG1","DUSP1","CHASERR","TXNIP","JUND"),group.by = "group3",idents = "Bc",pt.size = 0)
```

### meta-analysis
```{r}
library(dplyr)
library(metap)     # sumlog, sumz 등

## 0) ------------- 입력 예시 -----------------
## each marker dataframe has columns: gene, p_val, log2FC, pct.1, pct.2
dfs <- list(
  Tc  = marker_group_Tc_3,
  Bc  = marker_group_Bc_3,
  Mo  = marker_group_Mo_3,
  NKc = marker_group_NKc_3
)

## 1) ------------- 조합 15개 생성 -----------------
group_sets <- list()
all_names <- names(dfs)
for (k in 1:length(all_names)) {
  for (inc in combn(all_names, k, simplify = FALSE)) {
    exc <- setdiff(all_names, inc)

    # 포함 그룹 교집합
    genes_inc <- Reduce(intersect, lapply(dfs[inc], `[[`, "gene"))
    # 제외 그룹 제거
    genes_exc <- if (length(exc)) unlist(lapply(dfs[exc], `[[`, "gene")) else character()
    genes <- setdiff(genes_inc, genes_exc)

    group_sets[[paste(inc, collapse="&")]] <- genes
  }
}

## 2) ------------- meta‑p 계산 함수 -----------------
meta_p <- function(gene, tables, method = c("fisher","stouffer")) {
  # p 추출
  ps <- sapply(tables, function(tb) {
    p <- tb$p_val[match(gene, tb$gene)]
    ifelse(is.na(p), 1, p)          # 없는 경우 p=1 (무시)
  })
  ps <- ps[!is.na(ps)]              # 모든 NA 제거
  if (length(ps) == 0) return(NA)

  switch(match.arg(method),
    fisher   = sumlog(ps)$p,
    stouffer = sumz(ps)$p
  )
}

## 3) ------------- 각 15개 집합에 대해 meta‑p 계산 -----------------
meta_p_results <- lapply(names(group_sets), function(set_nm) {
  genes <- group_sets[[set_nm]]
  data.frame(
    gene   = genes,
    meta_p = sapply(genes, meta_p, tables = dfs, method = "fisher")
  ) %>% arrange(meta_p) %>% mutate(set = set_nm)
})
meta_p_results <- bind_rows(meta_p_results)

## 4) ------------- 결과 확인 -----------------
meta_p_results %>% 
  group_by(set) %>% 
  slice_head(n = 10)  # 각 조합 상위 10개 유전자

```

## conventional seurat plots

```{r}
FeaturePlot(stroke,c("HIF1A","TXNIP","FKBP5","SESN3","DDIT4","TSC22D3"))
```

# scatter plot
```{r}
# (1) "TXNIP" 발현값과 환자 식별자(sample_no)를 셀 단위로 추출
df <- data.frame(
  sample_no = s2@meta.data$sample_no,
  TXNIP = as.numeric(FetchData(s2, vars = "FAM107B")[, "FAM107B"])
)

# (2) 환자별 평균 "TXNIP" 발현값 계산
df_avg <- df %>%
  group_by(sample_no) %>%
  summarise(avg_TXNIP = mean(TXNIP, na.rm = TRUE))
```


```{r}
# (1) 환자 수준의 nih_change를 추출 (중복 제거)
meta_patient <- s@meta.data %>%
  select(sample_no, nih_change) %>%
  distinct(sample_no, .keep_all = TRUE)

# (2) 평균 TXNIP 데이터프레임과 환자 메타데이터를 합치기
df_merged <- left_join(df_avg, meta_patient, by = "sample_no")
df_merged$nih_change_numeric=as.numeric(df_merged$nih_change)
```

## scatterplot with fitted line
```{r}
# library(ggpmisc) # for stat_poly_eq
ggplot(df_merged, aes(x = nih_change, y = avg_TXNIP)) +
  geom_point() +
  theme_bw() +
  xlab("NIH Change") +
  ylab("Average TXNIP Expression") +
  geom_smooth(method="lm",se=TRUE,color="blue")+
  # stat_poly_eq(
  #   aes(label = paste(..eq.label.., ..p.value.label.., sep = "~~~")),
  #   formula = y ~ x,
  #   parse = TRUE,
  #   label.x.npc = "left",
  #   label.y.npc = 0.95
  # ) +
  ggtitle("Patient-wise NIH Change vs. TXNIP Expression")
```

## without ggpmisc
```{r}
# Extract components
# Ensure nih_change is numeric
df_merged$nih_change_numeric <- as.numeric(as.character(df_merged$nih_change))

# Fit the model
model <- lm(avg_TXNIP ~ nih_change_numeric, data = df_merged)

# Summary gives coefficients, p-value, R-squared, etc.
summary(model)

intercept <- round(coef(model)[1], 3)
slope <- round(coef(model)[2], 3)
pval <- signif(summary(model)$coefficients[2, 4], 3)

label_text <- paste0("y = ", intercept, " + ", slope, "*x\np = ", pval)

# Plot with manual annotation
ggplot(df_merged, aes(x = nih_change_numeric, y = avg_TXNIP)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  annotate("text", x = min(df_merged$nih_change_numeric, na.rm=TRUE),
           y = max(df_merged$avg_TXNIP, na.rm=TRUE),
           label = label_text, hjust = 0, vjust = 1, size = 5) +
  theme_bw() +
  xlab("NIH Change") +
  ylab("Average TXNIP Expression")

```

## functionalize
```{r}
# scatter_smooth=function(sobj, feature,clinical_variable="nih_change"){
#   df <- data.frame(
#   sample_no = sobj@meta.data$sample_no,
#   FEATURE = as.numeric(FetchData(sobj, vars = feature)[, feature])
# )
# 
# # (2) 환자별 평균 "feature" 발현값 계산
# df_avg <- df %>%
#   group_by(sample_no) %>%
#   summarise(avg_FEATURE = mean(FEATURE, na.rm = TRUE))
# # (1) 환자 수준의 nih_change를 추출 (중복 제거)
# meta_patient <- s@meta.data %>%
#   select(sample_no, nih_change) %>%
#   distinct(sample_no, .keep_all = TRUE)
# 
# # (2) 평균 FEATURE 데이터프레임과 환자 메타데이터를 합치기
# df_merged <- left_join(df_avg, meta_patient, by = "sample_no")
# df_merged$nih_change_numeric=as.numeric(df_merged$nih_change)
# 
# # Extract components
# # Ensure nih_change is numeric
# df_merged$nih_change_numeric <- as.numeric(as.character(df_merged$nih_change))
# 
# # Fit the model
# model <- lm(avg_FEATURE ~ nih_change_numeric, data = df_merged)
# 
# # Summary gives coefficients, p-value, R-squared, etc.
# summary(model)
# 
# intercept <- round(coef(model)[1], 3)
# slope <- round(coef(model)[2], 3)
# pval <- signif(summary(model)$coefficients[2, 4], 3)
# 
# label_text <- paste0("y = ", intercept, " + ", slope, "*x\np = ", pval)
# 
# # Plot with manual annotation
# p=ggplot(df_merged, aes(x = nih_change_numeric, y = avg_FEATURE)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = TRUE, color = "blue") +
#   annotate("text", x = min(df_merged$nih_change_numeric, na.rm=TRUE),
#            y = max(df_merged$avg_FEATURE, na.rm=TRUE),
#            label = label_text, hjust = 0, vjust = 1, size = 5) +
#   theme_bw() +
#   xlab("NIH Change") +
#   ylab(paste0("Average ", feature," Expression"))
# return(p)
# }

scatter_smooth = function(sobj, feature, clinical_variable = "nih_change", transpose = FALSE) {
  library(dplyr)
  library(ggplot2)

  # 1) Make a per-cell data.frame with the expression for 'feature'
  df <- data.frame(
    sample_no = sobj@meta.data$sample_no,
    FEATURE = as.numeric(FetchData(sobj, vars = feature)[, feature])
  )

  # 2) Compute average expression per patient
  df_avg <- df %>%
    group_by(sample_no) %>%
    summarise(avg_FEATURE = mean(FEATURE, na.rm = TRUE))

  # 3) Merge with your clinical variable
  meta_patient <- sobj@meta.data %>%
    select(sample_no, all_of(clinical_variable)) %>%
    distinct(sample_no, .keep_all = TRUE)

  df_merged <- left_join(df_avg, meta_patient, by = "sample_no") %>%
    mutate(
      nih_change_numeric = as.numeric(as.character(.data[[clinical_variable]]))
    )

  # 4) Branch logic for transpose:
  #    transpose = FALSE -> x = clinical_variable, y = avg_FEATURE
  #    transpose = TRUE  -> x = avg_FEATURE,         y = clinical_variable

  if (!transpose) {
    # Model: avg_FEATURE ~ nih_change_numeric
    model <- lm(avg_FEATURE ~ nih_change_numeric, data = df_merged)
    summary(model)

    intercept <- round(coef(model)[1], 3)
    slope <- round(coef(model)[2], 3)
    pval <- signif(summary(model)$coefficients[2, 4], 3)
    label_text <- paste0("y = ", intercept, " + ", slope, " * x\np = ", pval)

    # Plot: x = nih_change_numeric, y = avg_FEATURE
    p = ggplot(df_merged, aes(x = nih_change_numeric, y = avg_FEATURE)) +
      geom_point() +
      geom_smooth(method = "lm", se = TRUE) +
      annotate(
        "text",
        x = min(df_merged$nih_change_numeric, na.rm = TRUE),
        y = max(df_merged$avg_FEATURE, na.rm = TRUE),
        label = label_text, hjust = 0, vjust = 1, size = 5
      ) +
      theme_bw() +
      xlab(clinical_variable) +
      ylab(paste0("Average ", feature, " Expression"))

  } else {
    # transpose = TRUE -> we flip the roles:
    # Model: nih_change_numeric ~ avg_FEATURE
    model <- lm(nih_change_numeric ~ avg_FEATURE, data = df_merged)
    summary(model)

    intercept <- round(coef(model)[1], 3)
    slope <- round(coef(model)[2], 3)
    pval <- signif(summary(model)$coefficients[2, 4], 3)
    label_text <- paste0("y = ", intercept, " + ", slope, " * x\np = ", pval)

    # Plot: x = avg_FEATURE, y = nih_change_numeric
    p = ggplot(df_merged, aes(x = avg_FEATURE, y = nih_change_numeric)) +
      geom_point() +
      geom_smooth(method = "lm", se = TRUE) +
      annotate(
        "text",
        x = min(df_merged$avg_FEATURE, na.rm = TRUE),
        y = max(df_merged$nih_change_numeric, na.rm = TRUE),
        label = label_text, hjust = 0, vjust = 1, size = 5
      ) +
      theme_bw() +
      xlab(paste0("Average ", feature, " Expression")) +
      ylab(clinical_variable)
  }

  return(p)
}

```

###usage
```{r}
# bads
scatter_smooth(stroke,"DUS1L")
scatter_smooth(stroke,"FAM107B")
scatter_smooth(stroke,"RBM38")
scatter_smooth(stroke,"NCK2")
scatter_smooth(stroke,"UBALD2")
scatter_smooth(stroke,"SNX9")
scatter_smooth(stroke,"RBM3")
scatter_smooth(stroke,"mhc2_genes")
scatter_smooth(stroke,"bad_genes")
scatter_smooth(stroke,"good_genes")
scatter_smooth(stroke,"bad_good")
scatter_smooth(stroke,"rbgenes")

# goods
scatter_smooth(stroke,"DYNLL1")
scatter_smooth(stroke,"SDHD")
scatter_smooth(stroke,"POLD4")
scatter_smooth(stroke,"TRMT112")
scatter_smooth(stroke,"AHSA1")
scatter_smooth(stroke,"TRIM69")
scatter_smooth(stroke,"ERP29")
scatter_smooth(stroke,"CCNDBP1")
scatter_smooth(stroke,"ARRDC1")
scatter_smooth(stroke,"HSPA1B")
scatter_smooth(stroke,"HLA-DPB1")
scatter_smooth(stroke,"MRPL18")
scatter_smooth(stroke,"MRPL18",transpose=T)
scatter_smooth(stroke,"MRPL18",transpose=F)
scatter_smooth(stroke,"MRPL18","mrs3mo")
scatter_smooth(stroke,"MRPL18","mrs3mo",T)
a=scatter_smooth(stroke,"TXNIP","nih_change","Best_Sample_final")
scatter_smooth(cd4tn,"TXNIP","nih_change","Best_Sample_final")
```
#### list
```{r}
genes=marker_group_Tc_2$gene
cd4tn=subset(stroke,annotation_gpt2=="CD4_TN")
tc=subset(stroke,seurat_clusters%in%c(0,2,6,10,14,19,21,26))


results <- lapply(genes, function(g) {
  scatter_smooth(
    cd4tn,
    feature= g,
    clinical_variable      = "nih_change",
    sample_column          = "Best_Sample_final",
    transpose              = TRUE,
    plot                    = FALSE      # suppress the ggplot
  )
})
names(results) <- genes
coef_table <- bind_rows(
  lapply(results, function(x){
    tibble(
      gene      = x$gene,
      intercept = x$intercept,
      slope     = x$slope,
      pval      = x$pval
    )
  })
)

```
# checking all the genes
```{r}
library(dplyr)

# genes of interest (your 89 genes)
gene_list <- intersect(marker_nih_bad$gene,marker_group_3$gene)  # replace ... with actual gene names
gene_list=intersect(marker_nih_good$gene,marker_group_4$gene)

# Get expression matrix
expr <- FetchData(stroke, vars = gene_list)

# Add sample_no info
expr$sample_no <- stroke$sample_no

# Average gene expression per patient
avg_expr_by_patient <- expr %>%
  group_by(sample_no) %>%
  summarise(across(all_of(gene_list), ~ mean(.x, na.rm = TRUE)))



meta_patient <- stroke@meta.data %>%
  select(sample_no, nih_change) %>%
  distinct()

df_merged <- left_join(avg_expr_by_patient, meta_patient, by = "sample_no")
df_merged$nih_change <- as.numeric(as.character(df_merged$nih_change))


results_lm <- lapply(gene_list, function(gene) {
  model <- lm(df_merged[[gene]] ~ df_merged$nih_change)
  summary_model <- summary(model)
  data.frame(
    gene = gene,
    intercept = coef(model)[1],
    slope = coef(model)[2],
    p_value = summary_model$coefficients[2, 4],
    r_squared = summary_model$r.squared
  )
})

results_lm_df <- do.call(rbind, results_lm)

```
## functionalize
```{r}
# genes of interest
linear_fit=function(sobj, genes,category="type",outcome="nih_change")
{
gene_list=genes

# Get expression matrix
expr <- FetchData(sobj, vars = gene_list)

# Add sample_no info
expr[[category]] <- sobj@meta.data[[category]]

# Average gene expression per patient
avg_expr_by_patient <- expr %>%
  group_by(!!sym(category)) %>%
  summarise(across(all_of(gene_list), ~ mean(.x, na.rm = TRUE)))



meta_patient <- sobj@meta.data %>%
  select(category, outcome) %>%
  distinct()


# type unifying
# meta_patient[[category]]=as.character(meta_patient[[category]])
# avg_expr_by_patient[[category]]=as.character(avg_expr_by_patient[[category]])

df_merged <- left_join(avg_expr_by_patient, meta_patient, by = category)
df_merged[[outcome]] <- as.numeric(as.character(df_merged[[outcome]]))


results_lm <- lapply(gene_list, function(gene) {
  model <- lm(df_merged[[gene]] ~ df_merged[[outcome]])
  summary_model <- summary(model)
  data.frame(
    gene = gene,
    intercept = coef(model)[1],
    slope = coef(model)[2],
    p_value = summary_model$coefficients[2, 4],
    r_squared = summary_model$r.squared
  )
})

results_lm_df <- do.call(rbind, results_lm)
return(results_lm_df)
}
```

# modules
```{r}
mhc2_genes <- grep("^HLA-D(?!$)", rownames(stroke), value = TRUE, perl = TRUE)
feature_avg8=rowMeans(FetchData(stroke,vars=mhc2_genes))
stroke=AddMetaData(stroke,metadata=feature_avg8,col.name="mhc2_genes")
VlnPlot(stroke,features="mhc2_genes",group.by="group", pt.size = 0)
scatter_smooth(stroke,"rbgenes")

rbgenes <- grep("^RPL|^RPS", rownames(stroke), value = TRUE, perl = TRUE)
feature_avg3=rowMeans(FetchData(stroke,vars=rbgenes))
stroke=AddMetaData(stroke,metadata=feature_avg3,col.name="rbgenes")
VlnPlot(stroke,features="rbgenes",group.by="group", pt.size = 0)
scatter_smooth(stroke,"rbgenes")

bad_genes <- intersect(marker_nih_bad$gene,marker_group_3$gene)
feature_avg1=rowMeans(FetchData(stroke,vars=bad_genes))
stroke=AddMetaData(stroke,metadata=feature_avg1,col.name="bad_genes")
VlnPlot(stroke,features="bad_genes",group.by="group", pt.size = 0)
scatter_smooth(stroke,"bad_genes")

good_genes <- intersect(marker_nih_good$gene,marker_group_4$gene)
feature_avg2=rowMeans(FetchData(stroke,vars=good_genes))
stroke=AddMetaData(stroke,metadata=feature_avg2,col.name="good_genes")
VlnPlot(stroke,features="good_genes",group.by="group", pt.size = 0)
scatter_smooth(stroke,"good_genes")

feature_avg3=feature_avg1-feature_avg2
stroke=AddMetaData(stroke,metadata=feature_avg3,col.name="bad_good")
VlnPlot(stroke,features="bad_good",group.by="group", pt.size = 0)
scatter_smooth(stroke,"bad_good")

good_slope_0.01=paste(results_lm_df[results_lm_df$p_value<0.01,]$gene,sep = " ")
fe4=rowMeans(FetchData(stroke,vars=good_slope_0.01))
stroke=AddMetaData(stroke, metadata = fe4, col.name="good_slope_0.01")
VlnPlot(stroke,features="good_slope_0.01",group.by="group", pt.size = 0)
scatter_smooth(stroke,"good_slope_0.01")
```


```{r}
FeaturePlot(stroke,c("mhc2_genes","rbgenes","bad_genes","good_genes","bad_good"))
DimPlot(stroke, group.by="annotation3",label=T)
VlnPlot(stroke,c("mhc2_genes","rbgenes","bad_genes","good_genes","bad_good"),group.by="annotation1", pt.size = 0)

myhm_genesets2(stroke, group="annotation2",gene_sets=list(mhc2_genes=mhc2_genes,rbgenes=rbgenes,bad_genes=bad_genes,good_genes=good_genes))
```

# monocle
```{r}
library(monocle3)
cds <- load_mm_data(mat_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/matrix.mtx.gz", 
                    feature_anno_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/features.tsv.gz", 
                    cell_anno_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/barcodes.tsv.gz")
```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```

