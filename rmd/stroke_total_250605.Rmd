---
title: "stroke_total"
output: html_document
date: "2025-03-08"
output:
  html_document:
    df_print: paged
runtime: knitr
kernelspec:
  name: python3
  display_name: Python 3
---
# log
```
set1은 cellragner 7.2
set2은 cellranger 8.0.1

240425 ; revised 기준으로 합치려 함. GEM, exp_sample_no, set, group만 transfer하면 될듯함.
중복되는 column 최대한 없애서 saveRDS(meta,"/data/kjc1/projects/#130.stroke/sobj/meta_250425.rds")로 저장하였음

250508: R --max-mem-size=64G로 R을 켜줘야... 메모리 제한 안 걸리는 것 같다! 확인 중
kernel에서 굳이 안해도 될 것 같다. 일단 해결이 잘 안 됨. (문제는 파악해두는 게 좋겠다)
scVI는 결국 raw counts를 쓸 것이기 때문에, scVI에 feed 할 목적이라면 SCT는 굳이 안 살려서 저장해도 될듯. 용량이 3배 이상이 되는 듯.
250509:
1. SNP 부문에서 Barcode가 어떻게 처리되는 것인가?
1) 첫 ol의 AddMetaData에서 잘 일치하는지? Barcode_mapping_list 끝에 _1이 있음에도 잘 작동하는 이유가 무엇일까?
-> 이것은 잠재적으로 문제가 있다. 중복이 있을 수도 있기 때문에.
-> $Barcode에서 알아서 찾아 준다고는 한다.
duplicated(Barcode_mapping_list$Barcode)같은 걸 해봐야겠다.

2) colnames(ol[[i]])=ol[[i]]$Barcode를 추가해 sl에도 변환된 Barcode가 잘 추가되도록 하고, cell 수가 줄어들어도 AddMetaData가 잘 작동하도록.
3) 근데 애초에 SoupChannel에서 metaData를 추가해주면 문제가 없을 것 같다.
4) CreateSeuratObject에서도 meta.data를 명시해줄 수가 있다.
-> 잘 작동하므로, 이 둘로 해결. SoupChannel에 metaData를 추가하는 것은 redundant하고, HTO version에서 문제를 일으키니 빼주기.
2. HTO 부문에서 metadat 관련
1) sample_karo 말고 $Best_Sample에 추가하도록 하여 SNP와 compatible하게
2) GEM도 적절히 추가.
3) ol_time_point도 추가해서 추후 잘 제거할 수 있도록.

3. metadata 로직도 좀 수정해야 함.
1) meta_clinical1의 identifier는 sample_no 또는 exp_sample_no
2) meta_clinical2의 identifier는 sample_no.1
3) meta_seurat - SNP의 Best_Sample과 meta_clinical1의 exp_sample_no
```

# 퇴장
```{r}
set.seed(1234)
while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}
```

# libraries
## myR 관리
```{r}
setwd("/data/kjc1/mylit/myR")
devtools::load_all() #
devtools::document()
devtools::build()
devtools::install()
devtools::check()
library(myR)
```
### 수정, detach 후 재 로드
```{r}
# 1) 패키지 이름으로 detach
detach("package:myR", unload = TRUE)

# 2) 네임스페이스까지 완전 언로드 (C/C++ 코드도 언로드)
if ("myR" %in% loadedNamespaces()) {
  unloadNamespace("myR")
}

# 3) 이제 다시 설치된 버전을 로드
library(myR)

```

## 다른 라이브러리들
```{r}
suppressMessages(suppressWarnings(library(Seurat)))
suppressMessages(suppressWarnings(library(scDblFinder)))
suppressMessages(suppressWarnings(library(SoupX)))
suppressMessages(suppressWarnings(library(reticulate)))
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(readxl)))
library(tidyr)
library(edgeR)
```

# Data First Generation: Pipeline & Metadata Incorporation & Integration
## defaulting
```{r}
ol=list()
sl=list()
```
## dir_list
```{r}
# SNP list

list_snp=list(
  GEM1="/data/kjc1/projects/#130.stroke/gems/stroke1/outs/filtered_feature_bc_matrix",
  GEM2="/data/kjc1/projects/#130.stroke/gems/stroke2/outs/filtered_feature_bc_matrix",
  GEM3="/data/kjc1/projects/#130.stroke/gems/stroke3/outs/filtered_feature_bc_matrix",
  GEM4="/data/kjc1/projects/#130.stroke/gems/stroke4/outs/filtered_feature_bc_matrix",
  GEM5="/data/kjc1/projects/#130.stroke/gems/GEX1/outs/filtered_feature_bc_matrix",
  GEM6="/data/kjc1/projects/#130.stroke/gems/GEX2/outs/filtered_feature_bc_matrix",
  GEM7="/data/kjc1/projects/#130.stroke/gems/GEX3/outs/filtered_feature_bc_matrix",
  GEM8="/data/kjc1/projects/#130.stroke/gems/GEX4/outs/filtered_feature_bc_matrix"
)


list_snp_raw=list(
  GEM1="/data/kjc1/projects/#130.stroke/gems/stroke1/outs/raw_feature_bc_matrix",
  GEM2="/data/kjc1/projects/#130.stroke/gems/stroke2/outs/raw_feature_bc_matrix",
  GEM3="/data/kjc1/projects/#130.stroke/gems/stroke3/outs/raw_feature_bc_matrix",
  GEM4="/data/kjc1/projects/#130.stroke/gems/stroke4/outs/raw_feature_bc_matrix",
  GEM5="/data/kjc1/projects/#130.stroke/gems/GEX1/outs/raw_feature_bc_matrix",
  GEM6="/data/kjc1/projects/#130.stroke/gems/GEX2/outs/raw_feature_bc_matrix",
  GEM7="/data/kjc1/projects/#130.stroke/gems/GEX3/outs/raw_feature_bc_matrix",
  GEM8="/data/kjc1/projects/#130.stroke/gems/GEX4/outs/raw_feature_bc_matrix"
)

list_demux=list(
  "/data/kjc1/projects/#130.stroke/demux/xlot_1_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_2_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_3_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_4_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_5_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_6_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_7_posterior.csv",
  "/data/kjc1/projects/#130.stroke/demux/xlot_8_posterior.csv"
)

#HTO list; 이것은 사실 list가 아니라 vector다.

list_hto=list.dirs("/data/kjc1/projects/#130.stroke/count_matrix")
list_hto=list_hto[grep("_IS_",list_hto)]
list_hto <- list_hto[-11] #empty 8_IS_24
names(list_hto)=basename(list_hto)

list_hto_raw=list.dirs("/data/kjc1/projects/#130.stroke/count_matrix_raw")
list_hto_raw=list_hto_raw[-1]
names(list_hto_raw)=basename(list_hto_raw)

list_hto_raw_match=list(
  "14_IS_24"="GEM1_2",
  "18_IS_24"="GEM1_2",
  "22_IS_24"="GEM2_2",
  "23_IS_24"="GEM2_2",
  "28_IS_24"="GEM2_2",
  "1_IS_72"="Samples1_4",
  "2_IS_24"="Samples1_4",
  "2_IS_72"="Samples1_4",
  "4_IS_24"="Samples1_4",
  "4_IS_72"="Samples1_4",
  "8_IS_72"="Samples5_9"
)


save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/"

```



## test
```{r}
set.seed(1234)

sample_numbers=c(6,6,6,6,8,8,8,8)
barcode_mapping_list=list()

start_num=1
# SNP demultiplexing & object pipeline preprocessing
for(i in seq_along(list_snp)){
  # demultiplexing
  demux_data=read.csv(list_demux[[i]])
  colnames(demux_data)=c("BARCODE",generate_sample_names(start_num:(start_num+sample_numbers[i]-1)))
  start_num=start_num+sample_numbers[i]
  barcode_mapping_list[[i]]=get_barcode_mapping(demux_data)%>%
    mutate(droplet_demulti=ifelse(is_doublet(Best_Sample),"doublet_demulti","singlet_demulti"), GEM=paste0("GEM",i))%>%
    {rownames(.)=.$Barcode;
      .} %>%
    mutate(join_key=Best_Sample, day=1)
  
  # object pipeline preprocessing
  ol[[i]]=Read10X(list_snp[[i]])
  
  orig_n   <- ncol(ol[[i]])
  sample_n <- floor(orig_n / 100)   # 1/100 크기
  
  set.seed(1234)  # 재현성을 위한 시드 고정
  cells_keep <- sample(colnames(ol[[i]]), size = sample_n)
  
  ol[[i]]=ol[[i]][,cells_keep]
  
  sprintf("1. number:%d, raw count:%d",i,ncol(ol[[i]]))
  ol[[i]]=CreateSeuratObject(ol[[i]])
  
  ## demultiplexing - doublet removal
  ol[[i]]=AddMetaData(ol[[i]],barcode_mapping_list[[i]])
  
  ol[[i]]=subset(ol[[i]],droplet_demulti=="singlet_demulti")
  
  ## Pre-processing
  sprintf("2. number:%d, raw count:%d",i,ncol(ol[[i]]))
  # ol[[i]]=subset(ol[[i]],subset=percent.mt<5)
  ol[[i]]=SCTransform(ol[[i]],verbose=F)
  DefaultAssay(ol[[i]])="SCT"
  ol[[i]]=FindVariableFeatures(ol[[i]],verbose=F)
  ol[[i]]=RunPCA(ol[[i]],verbose=F)
  ol[[i]]=FindNeighbors(ol[[i]],verbose=F)
  ol[[i]]=FindClusters(ol[[i]],verbose=F)
  
  ## SoupX
  sprintf("sample: %s, step: soupx",i)
  raw_count=Read10X(list_snp_raw[[i]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  sc=SoupChannel(raw_count[rownames(ol[[i]]),],ol[[i]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[i]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  ## re-preprocessing
  sl[[i]]=CreateSeuratObject(out, project="LIT_2024_Stroke_SNPDemultiAndDoubletRemoval_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[i]]@meta.data)
  sl[[i]]=SCTransform(sl[[i]],verbose=F)
  DefaultAssay(sl[[i]])="SCT"
  sl[[i]]=FindVariableFeatures(sl[[i]],verbose=F)
  sl[[i]]=RunPCA(sl[[i]],verbose=F)
  sl[[i]]=FindNeighbors(sl[[i]],verbose=F)
  sl[[i]]=FindClusters(sl[[i]],verbose=F)
  
  ## scDblFinder doublet removal
  sce <- scDblFinder(GetAssayData(sl[[i]], layer= "counts"), clusters = Idents(sl[[i]]))
  sl[[i]]$"droplet"=sce$scDblFinder.class
  sl[[i]]=subset(sl[[i]],droplet=="singlet")
  sprintf("3. number:%d, raw count:%d",i,ncol(sl[[i]]))
  
  
  # saving
  save_seurat_to_h5ad(
    sl[[i]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0("stroke_GEM",i,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
  )
}

#HTO의 경우, HTO 갯수가 들어있는 layer도 있어서 명시적으로 layer 불러내어 SCTransform 시행 필요.
for(dir in list_hto){
  sample=basename(dir)
  # Extract first number (prefix)
  prefix <- stringr::str_extract(sample, "^\\d+")
  # Extract last number (time point)
  time_point <- stringr::str_extract(sample, "\\d+$")
  day=case_when(
    time_point=="72" ~3,
    time_point=="48" ~2,
    time_point=="24" ~1,
    time_point=="NA" ~NA
  )
  GEM_hto=basename(list_hto_raw[[list_hto_raw_match[[sample]]]])
  GEM=case_when(
    GEM_hto=="Samples1_4"~"GEM9",
    GEM_hto=="Samples5_9"~"GEM10",
    GEM_hto=="GEM1_2"~"GEM11",
    GEM_hto=="GEM2_2"~"GEM12"
  )
  
  # HTO based demultiplexing already done
  
  # object pipeline preprocessing
  ol[[sample]]=Read10X(list_hto[[sample]])
  ol[[sample]]=ol[[sample]]$`Gene Expression`
  
  orig_n   <- ncol(ol[[sample]])
  sample_n <- floor(orig_n / 100)   # 1/100 크기
  
  set.seed(1234)  # 재현성을 위한 시드 고정
  cells_keep <- sample(colnames(ol[[sample]]), size = sample_n)
  ol[[sample]]=ol[[sample]][,cells_keep]
  
  sprintf("1. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  ol[[sample]]=CreateSeuratObject(ol[[sample]])
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=sample,col.name = "sample_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM_hto,col.name = "GEM_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM,col.name = "GEM")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=time_point,col.name = "ol_time_point")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=day,col.name = "day")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=colnames(ol[[sample]]),col.name = "Barcode")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=paste0(prefix,"_",day),col.name = "join_key")
  
  sprintf("2. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  # ol[[sample]]=subset(ol[[sample]],subset=percent.mt<5)
  ol[[sample]] <- SCTransform(
    ol[[sample]],
    assay           = "RNA",
    new.assay.name  = "SCT",
    verbose         = FALSE
  )
  DefaultAssay(ol[[sample]])="SCT"
  ol[[sample]]=FindVariableFeatures(ol[[sample]])
  ol[[sample]]=RunPCA(ol[[sample]], npcs = 5)
  ol[[sample]]=FindNeighbors(ol[[sample]], dims = 5)
  ol[[sample]]=FindClusters(ol[[sample]])
  
  ## SoupX
  sprintf("sample: %s, step: soupx",sample)
  raw_count=Read10X(list_hto_raw[[list_hto_raw_match[[sample]]]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  
  
  #sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts,metaData = ol[[i]]@meta.data)
  # Error in SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),  : 
  #   Rownames of metaData must match column names of table of counts.
  # In addition: Warning message:
  # In sort(colnames(toc)) == sort(rownames(metaData)) :
  #   longer object length is not a multiple of shorter object length
  
  sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[sample]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  sl[[sample]]=CreateSeuratObject(out, project="LIT_2023_Stroke_HTO_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[sample]]@meta.data)
  sl[[sample]]=SCTransform(sl[[sample]],verbose=F)
  DefaultAssay(sl[[sample]])="SCT"
  sl[[sample]]=FindVariableFeatures(sl[[sample]],verbose=F)
  sl[[sample]]=RunPCA(sl[[sample]],verbose=F, npcs = 5)
  sl[[sample]]=FindNeighbors(sl[[sample]],verbose=F,dims=5)
  sl[[sample]]=FindClusters(sl[[sample]],verbose=F)
  
  sce <- scDblFinder(GetAssayData(sl[[sample]], layer= "counts"), clusters = Idents(sl[[sample]]))
  sl[[sample]]$"droplet"=sce$scDblFinder.class
  sprintf("3. sample:%s, raw count:%f",sample,ncol(sl[[sample]]))
  

  # Seurat 객체에서 데이터 추출
  save_seurat_to_h5ad(
    sl[[sample]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0(sample,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
    )
}

# merging only carries raw/data/scale.data and meta.data slots.
# because there's no safe way to merge reductions, graphs, etc.
# set merge.SCT=TRUE

features <- SelectIntegrationFeatures(object.list = sl, nfeatures = 3000)
sct_list <- PrepSCTIntegration(object.list = sl, anchor.features = features) #what's this?
integrated_data <- FindIntegrationAnchors(object.list = sct_list, normalization.method = "SCT",
                                  anchor.features = features,reduction="rpca",
                                  k.anchor=20) #it makes anchorset object. but after IntegrateData it becomes seurat object. before rpca, RunPCA is needed
integrated_data <- IntegrateData(anchorset = integrated_data, normalization.method = "SCT")

DefaultAssay(integrated_data)="integrated"
# Run PCA on integrated data
integrated_data <- RunPCA(integrated_data, verbose = FALSE, reduction.name = "pca_integrated")
# Run UMAP/t-SNE and clustering
integrated_data <- RunUMAP(integrated_data, dims = 1:30, reduction = "pca_integrated", reduction.name = "umap_integrated") #The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric. To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'
integrated_data <- FindNeighbors(integrated_data, dims = 1:30, graph.name = c("integrated_snn","integrated_nn"))
# integrated_data <- FindClusters(integrated_data)
integrated_data <- FindClusters(integrated_data,graph.name = "integrated_snn", cluster.name = "integrated_0.8")

# Re-SCTranform to merge multiple SCT layers
DefaultAssay(integrated_data)="SCT"
integrated_data=SCTransform(integrated_data, new.assay.name="SCT_RE")
integrated_data = PrepSCTFindMarkers(integrated_data)


markers=list()
for(cluster in levels(integrated_data$seurat_clusters)){
  markers[[cluster]]=FindMarkers(integrated_data, ident.1=cluster)
  markers[[cluster]]$gene=rownames(markers[[cluster]])
}

time1=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_beforeQC_",time1,".rds"))
#saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_SCT_integrated_beforeQC_",time1,".rds"))

time2=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_markers_",time2,".rds"))
#saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_markers_",time2,".rds"))

while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}
```


## reading & integration
```{r}
set.seed(1234)

sample_numbers=c(6,6,6,6,8,8,8,8)
barcode_mapping_list=list()

start_num=1
# SNP demultiplexing & object pipeline preprocessing
for(i in seq_along(list_snp)){
  # demultiplexing
  demux_data=read.csv(list_demux[[i]])
  colnames(demux_data)=c("BARCODE",generate_sample_names(start_num:(start_num+sample_numbers[i]-1)))
  start_num=start_num+sample_numbers[i]
  barcode_mapping_list[[i]]=get_barcode_mapping(demux_data)%>%
    mutate(droplet_demulti=ifelse(is_doublet(Best_Sample),"doublet_demulti","singlet_demulti"), GEM=paste0("GEM",i), Barcode = paste0(Barcode, "_",i))%>%
    {rownames(.)=.$Barcode;
      .} %>%
    mutate(join_key=Best_Sample, day=1)
  
  # object pipeline preprocessing
  ol[[i]]=Read10X(list_snp[[i]])
  sprintf("1. number:%d, raw count:%d",i,ncol(ol[[i]]))
  ol[[i]]=CreateSeuratObject(ol[[i]])
  
  ## demultiplexing - doublet removal
  ol[[i]]=AddMetaData(ol[[i]],barcode_mapping_list[[i]])
  
  ol[[i]]=subset(ol[[i]],droplet_demulti=="singlet_demulti")
  
  ## Pre-processing
  sprintf("2. number:%d, raw count:%d",i,ncol(ol[[i]]))
  # ol[[i]]=subset(ol[[i]],subset=percent.mt<5)
  ol[[i]]=SCTransform(ol[[i]],verbose=F)
  DefaultAssay(ol[[i]])="SCT"
  ol[[i]]=FindVariableFeatures(ol[[i]],verbose=F)
  ol[[i]]=RunPCA(ol[[i]],verbose=F)
  ol[[i]]=FindNeighbors(ol[[i]],verbose=F)
  ol[[i]]=FindClusters(ol[[i]],verbose=F)
  
  ## SoupX
  sprintf("sample: %s, step: soupx",i)
  raw_count=Read10X(list_snp_raw[[i]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  sc=SoupChannel(raw_count[rownames(ol[[i]]),],ol[[i]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[i]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  ## re-preprocessing
  sl[[i]]=CreateSeuratObject(out, project="LIT_2024_Stroke_SNPDemultiAndDoubletRemoval_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[i]]@meta.data)
  sl[[i]]=SCTransform(sl[[i]],verbose=F)
  DefaultAssay(sl[[i]])="SCT"
  sl[[i]]=FindVariableFeatures(sl[[i]],verbose=F)
  sl[[i]]=RunPCA(sl[[i]],verbose=F)
  sl[[i]]=FindNeighbors(sl[[i]],verbose=F)
  sl[[i]]=FindClusters(sl[[i]],verbose=F)
  
  ## scDblFinder doublet removal
  sce <- scDblFinder(GetAssayData(sl[[i]], layer= "counts"), clusters = Idents(sl[[i]]))
  sl[[i]]$"droplet"=sce$scDblFinder.class
  sl[[i]]=subset(sl[[i]],droplet=="singlet")
  sprintf("3. number:%d, raw count:%d",i,ncol(sl[[i]]))
  
  
  # saving
  save_seurat_to_h5ad(
    sl[[i]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0("stroke_GEM",i,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
  )
}

#HTO의 경우, HTO 갯수가 들어있는 layer도 있어서 명시적으로 layer 불러내어 SCTransform 시행 필요.
for(dir in list_hto){
  sample=basename(dir)
  # Extract first number (prefix)
  prefix <- stringr::str_extract(sample, "^\\d+")
  # Extract last number (time point)
  time_point <- stringr::str_extract(sample, "\\d+$")
  day=case_when(
    time_point=="72" ~3,
    time_point=="48" ~2,
    time_point=="24" ~1,
    time_point=="NA" ~NA
  )
  GEM_hto=basename(list_hto_raw[[list_hto_raw_match[[sample]]]])
  GEM=case_when(
    GEM_hto=="Samples1_4"~9,
    GEM_hto=="Samples5_9"~10,
    GEM_hto=="GEM1_2"~11,
    GEM_hto=="GEM2_2"~12
  )
  
  # HTO based demultiplexing already done
  
  # object pipeline preprocessing
  ol[[sample]]=Read10X(list_hto[[sample]])
  sprintf("1. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  ol[[sample]]=CreateSeuratObject(ol[[sample]])
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=sample,col.name = "sample_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM_hto,col.name = "GEM_hto")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=GEM,col.name = "GEM")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=time_point,col.name = "ol_time_point")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=day,col.name = "day")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=colnames(ol[[sample]]),col.name = "Barcode")
  ol[[sample]]=AddMetaData(ol[[sample]],metadata=paste0(prefix,"_",day),col.name = "join_key")
  
  sprintf("2. sample:%s, raw count:%d",sample,ncol(ol[[sample]]))
  # ol[[sample]]=subset(ol[[sample]],subset=percent.mt<5)
  ol[[sample]] <- SCTransform(
    ol[[sample]],
    assay           = "RNA",
    layer           = "counts.Gene Expression",
    new.assay.name  = "SCT",
    verbose         = FALSE
  )
  DefaultAssay(ol[[sample]])="SCT"
  ol[[sample]]=FindVariableFeatures(ol[[sample]])
  ol[[sample]]=RunPCA(ol[[sample]])
  ol[[sample]]=FindNeighbors(ol[[sample]])
  ol[[sample]]=FindClusters(ol[[sample]])
  
  ## SoupX
  sprintf("sample: %s, step: soupx",sample)
  raw_count=Read10X(list_hto_raw[[list_hto_raw_match[[sample]]]])
  
  ### SoupChannel(tod, toc, metaData=NULL, calcSoupProfile=TRUE)
  ### tod는 table of droplets으로 cell이 없는 droplet도 포함한 raw count matrix이며, toc는 table of counts로 filetered count matrix
  ### gene list(rownames)를 일치시켜줘야 함
  
  
  #sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts,metaData = ol[[i]]@meta.data)
  # Error in SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),  : 
  #   Rownames of metaData must match column names of table of counts.
  # In addition: Warning message:
  # In sort(colnames(toc)) == sort(rownames(metaData)) :
  #   longer object length is not a multiple of shorter object length
  
  sc=SoupChannel(raw_count$`Gene Expression`[rownames(ol[[sample]]),],ol[[sample]]@assays$SCT$counts)
  print("SoupChannel Done")
  
  ### [["seurat_clusters"]]와 $seurat_clusters는 다르다. identical(ol[[i]]$"seurat_clusters",ol[[i]][["seurat_clusters"]])
  sc=setClusters(sc,ol[[sample]]$"seurat_clusters")
  print("setCluster Done")
  
  sc=autoEstCont(sc, tfidfMin=0.05, soupQuantile=0.8, forceAccept=TRUE)
  print("autoEstCont Done")
  out=adjustCounts(sc)
  print("adjustCounts Done")
  
  sl[[sample]]=CreateSeuratObject(out, project="LIT_2023_Stroke_HTO_SoupXed_scDblFinderDoubletRemoval", meta.data = ol[[sample]]@meta.data)
  sl[[sample]]=SCTransform(sl[[sample]],verbose=F)
  DefaultAssay(sl[[sample]])="SCT"
  sl[[sample]]=FindVariableFeatures(sl[[sample]],verbose=F)
  sl[[sample]]=RunPCA(sl[[sample]],verbose=F)
  sl[[sample]]=FindNeighbors(sl[[sample]],verbose=F)
  sl[[sample]]=FindClusters(sl[[sample]],verbose=F)
  
  sce <- scDblFinder(GetAssayData(sl[[sample]], layer= "counts"), clusters = Idents(sl[[sample]]))
  sl[[sample]]$"droplet"=sce$scDblFinder.class
  sprintf("3. sample:%s, raw count:%f",sample,ncol(sl[[sample]]))
  

  # Seurat 객체에서 데이터 추출
  save_seurat_to_h5ad(
    sl[[sample]],
    condaenv="/home/jaecheon/miniconda3/envs/scenvi", #default
    save_path="/data/kjc1/projects/#130.stroke/sobj/h5ad/", #default
    save_name=paste0(sample,"_" ,format(Sys.time(),"%y-%m-%d-%H-%M"))
    )
}

# merging only carries raw/data/scale.data and meta.data slots.
# because there's no safe way to merge reductions, graphs, etc.
# set merge.SCT=TRUE

# features <- SelectIntegrationFeatures(object.list = ol, nfeatures = 3000)
# sct_list <- PrepSCTIntegration(object.list = ol, anchor.features = features) #what's this?

features <- SelectIntegrationFeatures(object.list = sl, nfeatures = 3000)
sct_list <- PrepSCTIntegration(object.list = sl, anchor.features = features) #what's this?
integrated_data <- FindIntegrationAnchors(object.list = sct_list, normalization.method = "SCT",
                                  anchor.features = features,reduction="rpca",
                                  k.anchor=20) #it makes anchorset object. but after IntegrateData it becomes seurat object. before rpca, RunPCA is needed
integrated_data <- IntegrateData(anchorset = integrated_data, normalization.method = "SCT")
# Re-SCTranform to merge multiple SCT layers
DefaultAssay(integrated_data)="SCT"
integrated_data=SCTransform(integrated_data)

# Run PCA on integrated data
DefaultAssay(integrated_data)="integrated"
integrated_data <- RunPCA(integrated_data, verbose = FALSE)
# Run UMAP/t-SNE and clustering
integrated_data <- RunUMAP(integrated_data, dims = 1:30) #The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric. To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'
integrated_data <- FindNeighbors(integrated_data, dims = 1:30)
# integrated_data <- FindClusters(integrated_data)
integrated_data <- FindClusters(integrated_data,graph.name = "integrated_snn",resolution = 0.8)

DefaultAssay(integrated_data)="SCT"
integrated_data = PrepSCTFindMarkers(integrated_data)


markers=list()
for(cluster in levels(integrated_data$seurat_clusters)){
  markers[[cluster]]=FindMarkers(integrated_data, ident.1=cluster)
  markers[[cluster]]$gene=rownames(markers[[cluster]])
}

time1=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_",time1,".rds"))
#saveRDS(integrated_data,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_SCT_integrated_beforeQC_",time1,".rds"))

time2=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_markers_",time2,".rds"))
#saveRDS(markers,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_markers_",time2,".rds"))

while (TRUE) {
  # result <- 1 + 1
  # print(result)
  print(format(Sys.time(),"%y-%m-%d-%H-%M"))
  Sys.sleep(100)  # 100초 대기
}

```


## metadata prep
```{r}
### GEM n, exp_sample_no 챙기기: 모든 환자를 포함. 대신 필수 정보만 들어있음.
meta_clinical1=readxl::read_xlsx("/data/kjc1/projects/#130.stroke/sample_info_250407_merged.xlsx", .name_repair = "minimal") %>%
  .[,!duplicated(names(.))] %>%
  filter(type == "IS")
  # 여기서 GEM, exp_sample_no,set, group만 건지면 될 듯. 여기서의 group은 맨 처음 설정한 1~4와, 내가 임의로 준 0, 6임.
#6은 IS가 아니고, 0은...

### clinical metadata 챙기기: IS 환자의 다양한 변수.
meta_clinical2=readxl::read_excel("/data/kjc1/projects/#130.stroke/variables_IS_250225_data_cleaned_250416_revised.xlsx", .name_repair = "minimal") %>%
  .[,!duplicated(names(.))]

overlap_cols=intersect(names(meta_clinical1),names(meta_clinical2))
cols_to_remove=setdiff(overlap_cols,"hos_no")

meta_clinical2_prepped=meta_clinical2 %>%
  select(-all_of(cols_to_remove))

### 합치기
meta_clinical3=meta_clinical1 %>%
  left_join(meta_clinical2_prepped,by="hos_no") %>% #EMR ID로 join하겠다!
  mutate(join_key_samp=ifelse(multi_method=="SNP",exp_sample_no,sample_no))

####################### extraction
meta_seurat=s@meta.data

overlap_cols=intersect(names(meta_seurat),names(meta_clinical3))
cols_to_remove=setdiff(overlap_cols,"hos_no")
meta_seurat=meta_seurat%>%
  select(-all_of(cols_to_remove))

#left를 쓸지, right를 쓸지는 매우 중요한 이슈다..
# left를 쓰면 meta_seurat은 일단 다 살고, 다만 join_key가 매칭이 안 되는 경우 NA가 생긴다.
# right를 쓰면 meta_clinical3의 join_key_sample가 있는 meta_seurat만 다 산다. 다만, meta_clinical3에서 meta_seurat의 join_key와 일치하지 않는 불필요한 행도 산다.
#right join을 하면 -> IS만 산다 (meta_clinical3에 IS 데이터만 있으니), 그러나 IS가 있으면 다 산다 -> orig.ident값 NA인 것 3개 행 제거하면 완전해짐.
#left_join을 하면 -> 전부 다 산다 -> IS 관련 메타데이터만 있는 것만 살리면 완전해짐.

meta_joined=right_join(meta_seurat, meta_clinical3, by=c("join_key"="join_key_samp")) %>%
  .[rownames(.)[!is.na(.$orig.ident)],]
meta_whole=left_join(meta_seurat, meta_clinical3, by=c("join_key"="join_key_samp"))

saveRDS(meta_joined,"/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_meta_IS_25-05-11-12-03.rds")
saveRDS(meta_whole,"/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_meta_whole_25-05-11-12-03.rds")
```

## time transform
```{r}
is$sx_onset_pos <- as.POSIXct(is$sx_onset, format = "%Y.%m.%d %H:%M", tz     = "Asia/Seoul") #POSIXct 형식의 시간(초 단위인듯)으로 변환
is$blood_sample_time_pos = as.POSIXct(is$blood_sample_time, format = "%Y.%m.%d %H:%M", tz     = "Asia/Seoul")

# 4. 혈액 채취 시간(분 단위)에서 sx_onset_num을 빼서 onset_to_sample 계산
#    (가정: is$blood_sample_time이 시작 기준부터 경과한 분 단위 숫자)
is$onset_to_sample <- (is$blood_sample_time_pos - is$sx_onset_pos)/3600
```

# reloading
```{r}
# s=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_25-05-11-12-03.rds")
# meta_joined=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_meta_IS_25-05-11-12-03.rds")
# meta_whole=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_meta_whole_25-05-11-12-03.rds")
# s=AddMetaData(s,meta_whole)
# is_all=subset(s,type=="IS")
# is=subset(is_all,group3%in%c(1,2))
# DefaultAssay(is)="integrated"
# is <- RunPCA(is, verbose = FALSE, reduction.name = "integrated_pca", seed.use=1234)
# is <- RunUMAP(is, dims = 1:30, reduction="integrated_pca", reduction.name="integrated_umap", seed.use = 1234) 
# is <- FindNeighbors(is, dims = 1:30, reduction="integrated_pca", graph.name = c("integrated_nn","integrated_snn"))
# time3=format(Sys.time(),"%y-%m-%d-%H-%M")
# saveRDS(is,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_group3_clustering_",time3,".rds"))

is_all=readRDS("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_group3_clustering_25-05-12-16-03.rds")
res=1.1
cluster_name=paste0("integrated_",res)
is_all <- FindClusters(is_all,graph.name = "integrated_snn",cluster.name=cluster_name, resolution = res,random.seed = 1234)
DefaultAssay(is_all)="SCT"
is_all = PrepSCTFindMarkers(is_all)
is=subset(is_all, day==1)
time3=format(Sys.time(),"%y-%m-%d-%H-%M")
saveRDS(is,file=paste0("/data/kjc1/projects/#130.stroke/sobj/stroke_karo_SCT_integrated_QC_group3_day1_subclustering_",time3,".rds"))
```

# MARKER - for annotation
## FindAllMarker & Filtering 세련되게
```{r}
all_markers=FindAllMarkers(is,group.by=cluster_name)
# all_markers_auc=FindAllMarkers(is,test.use = "roc")

# ribosomal, mitochondrial, hemoglobin, uncharacterized genes filtering
all_markers_filtered=marker_filter(all_markers, filter=c("rb","mt","hb","AC","ENSG","LINC"))

# make list
marker_list=all_markers_to_list(all_markers_filtered)

# markers printing - Log2FC > 0 sorting
marker_print(marker_list,n=100, cluster_to_print = NULL)
marker_print(marker_list["cluster_19"],n=500, cluster_to_print = NULL)
marker_print(marker_list["cluster_20"],n=500, cluster_to_print = NULL)

#all_pb_markers=pseudobulk_deg(is, "exp_sample_no", "annotation2_big", "annotation2_detail", test.use="edgeR")
all_pb_markers=FindAllMarkers_pseudobulk(is,"annotation2_big", "exp_sample_no")
all_pb_markers_list=all_markers_to_list(all_pb_markers)
marker_print(all_pb_markers_list, n=100, )
```




# Annotation for first clustering

## Gemini for resolution 0.8, for only IS group3 clustering

### big
```{r}
cluster_key="integrated_snn_res.0.8"
is$annotation1_gemini <- case_when(
  ## ---- CD4 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(0,8,11,14)   ~ "CD4Tc",      

  ## ---- CD8 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(2,24)   ~ "CD8Tc",
  ## ---- NK cells -------------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(3,9,10)   ~ "NKc",

  ## ---- B cells --------------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(5,20)   ~ "Bc",

  ## ---- Monocytes ------------------------------------------------------------------
  # Classical Monocytes (CD14++)
  is@meta.data[[cluster_key]] %in% c(1,4,6,7,12,15,21,22,13,23,26,27,17)   ~ "Monocyte",          


  ## ---- Dendritic Cells (DC) -------------------------------------------------------
  is@meta.data[[cluster_key]] %in% 18  ~ "DC",       # CD1C, CLEC10A, FCER1A (cDC2) & CLEC9A, XCR1, BATF3 (cDC1). High HLA-DR.

  ## ---- Other Lineages / States ----------------------------------------------------
  is@meta.data[[cluster_key]] %in% 16  ~ "Tc_Ambiguous",         # PTPRC, BCL11B, ZAP70, CD247 (low). Lacks strong naive/effector/Treg markers.
  is@meta.data[[cluster_key]] %in% 19  ~ "Erythroid",           # ALAS2, SLC4A1, AHSP, KLF1. (HBB family implied).
  is@meta.data[[cluster_key]] %in% 25  ~ "Megakaryocyte",    # PPBP, PF4, GP9, ITGA2B (CD41), ITGB3 (CD61).

  ## ---- Default for unassigned (should not happen if all clusters covered) ---------
  TRUE                      ~ "Unassigned"
)
DimPlot(is, group.by="annotation1_gemini", label=T)
```

### detail
```{r}
cluster_key="integrated_snn_res.0.8"
is$annotation1_gemini_detail <- case_when(
  ## ---- CD4 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] == 0   ~ "CD4_T_Naive_EarlyActivation_IL7R_CCR7_CD69",        # Naive: IL7R, CCR7, TCF7, LEF1. Activation: CD69, IL32. CD40LG.
  is@meta.data[[cluster_key]] == 8   ~ "CD4_T_Naive_EarlyActivation_IL7R_CCR7_CD69_v2",     # Similar to C0: IL7R, CCR7, TCF7, LEF1, CD69.
  is@meta.data[[cluster_key]] == 11  ~ "CD4_T_Naive_EarlyActivation_IL7R_CCR7_CD69_v3",     # Similar to C0/C8: IL7R, MAL, TCF7, CCR7, LEF1, CD69, IL32.
  is@meta.data[[cluster_key]] == 14  ~ "CD4_T_Regulatory_Treg_Proliferating_FOXP3_MKI67", # FOXP3, CTLA4, TNFRSF4, TIGIT, MKI67 (proliferating).

  ## ---- CD8 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] == 2   ~ "CD8_T_TEMRA_Cytotoxic_KLRG1_GZMs_TIGIT",         # CD8A/B, GZMA/B/H/M, PRF1, KLRG1, EOMES, TBX21, LAG3, TIGIT.
  is@meta.data[[cluster_key]] == 24  ~ "CD8_T_EffectorMemory_GZMKhigh_KLRG1",            # CD8A/B, GZMK high, GZMA/MM low, KLRG1, IL7R, CXCR4.

  ## ---- NK cells -------------------------------------------------------------------
  is@meta.data[[cluster_key]] == 3   ~ "NK_CD56dim_Cytotoxic_FCGR3A_GNLY_GZMB_KIRs",       # GNLY, GZMB, NKG7, FCGR3A, KLRD1/F1, NCR1/3, KIRs. No CD3.
  is@meta.data[[cluster_key]] == 9   ~ "NK_CD56dim_Cytotoxic_FCGR3A_GNLY_GZMB_KIRs_v2",    # Similar to C3: GNLY, GZMB, NKG7, FCGR3A, KIRs.
  is@meta.data[[cluster_key]] == 10  ~ "NK_CD56dim_Activated_Effector_IFNG_FASLG_XCLs",   # Similar to C3/C9 but with IFNG, FASLG, XCL1/2, CCL4/5.

  ## ---- B cells --------------------------------------------------------------------
  is@meta.data[[cluster_key]] == 5   ~ "B_Cell_Naive_MS4A1_IGHD_IGHM_FCER2_TCL1A",       # CD19, MS4A1(CD20), CD79A/B, IGHM, IGHD, TCL1A, FCER2(CD23), PAX5.
  is@meta.data[[cluster_key]] == 20  ~ "B_Cell_Plasmablast_Proliferating_MZB1_JCHAIN_IGHs_MKI67", # MZB1, JCHAIN, IGHs, CD38, IRF4, TNFRSF17, MKI67.

  ## ---- Monocytes ------------------------------------------------------------------
  # Classical Monocytes (CD14++)
  is@meta.data[[cluster_key]] == 1   ~ "Monocyte_Classical_CD14_S100Ahigh_FCN1",          # CD14, S100A8/9/12, LYZ, FCN1, VCAN.
  is@meta.data[[cluster_key]] == 4   ~ "Monocyte_Classical_CD14_Inflammatory_S100Ahigh_CXCL8", # CD14, S100A8/9/12, LYZ, FCN1, CXCL8.
  is@meta.data[[cluster_key]] == 6   ~ "Monocyte_Classical_CD14_S100Ahigh_FCN1_v2",       # Similar to C1/C4.
  is@meta.data[[cluster_key]] == 7   ~ "Monocyte_Classical_CD14_Highly_Inflammatory_IL1B_TNF_CD83", # CD14, S100A8/9, IL1B, CXCL8, TNF, NLRP3, CD83.
  is@meta.data[[cluster_key]] == 12  ~ "Monocyte_Classical_CD14_S100Ahigh_RETN",          # CD14, S100A8/9/12, PLBD1, RETN.
  is@meta.data[[cluster_key]] == 15  ~ "Monocyte_Classical_CD14_S100Ahigh_FCN1_v3",       # Similar to C1/C4/C6.
  is@meta.data[[cluster_key]] == 21  ~ "Monocyte_Classical_CD14_S100Ahigh_FOLR3_RNASE2",   # CD14, S100A8/9/12, FOLR3, RNASE2.
  is@meta.data[[cluster_key]] == 22  ~ "Monocyte_Classical_CD14_S100Ahigh_S100A4",         # CD14, S100A8/9/12, S100A4.
  # Non-Classical Monocytes (CD14+CD16++)
  is@meta.data[[cluster_key]] == 13  ~ "Monocyte_NonClassical_CD16_FCGR3A_MS4A7_HMOX1",  # FCGR3A high, MS4A7, LILRB2, HMOX1, CSF1R. CD14 low/mod.
  # Monocytes with Macrophage-like/Specialized features
  is@meta.data[[cluster_key]] == 23  ~ "Monocyte_Classical_CD14_MacrophageLike_MPEG1_VNN2", # CD14, S100A_high, MPEG1, VNN2, LILRB4, OSCAR.
  is@meta.data[[cluster_key]] == 26  ~ "Monocyte_Classical_CD14_MacrophageLike_ITGAM_TGFBI", # CD14, ITGAM(CD11b), TGFBI, F13A1, LILRB4.
  is@meta.data[[cluster_key]] == 27  ~ "Monocyte_Classical_CD14_HighlyActivated_Stress_TREM1_PLAUR", # CD14, S100A_high, TREM1, PLAUR, IL1B, CXCL1/8, CSF3.

  ## ---- Dendritic Cells (DC) -------------------------------------------------------
  is@meta.data[[cluster_key]] == 17  ~ "Myeloid_Activated_CD83_HLA-DRhigh_Mo-DC_Like_CSF3R", # CD83, HLA-DRA high, CSF3R, VCAN. Lacks canonical cDC/pDC markers.
  is@meta.data[[cluster_key]] == 18  ~ "DC_cDC_Mixed_cDC2dominant_CD1C_CLEC9A_XCR1",       # CD1C, CLEC10A, FCER1A (cDC2) & CLEC9A, XCR1, BATF3 (cDC1). High HLA-DR.

  ## ---- Other Lineages / States ----------------------------------------------------
  is@meta.data[[cluster_key]] == 16  ~ "T_Cell_Ambiguous_MemoryLike_BCL11B_ZAP70",         # PTPRC, BCL11B, ZAP70, CD247 (low). Lacks strong naive/effector/Treg markers.
  is@meta.data[[cluster_key]] == 19  ~ "Erythroid_Lineage_ALAS2_HBBfamily_KLF1",           # ALAS2, SLC4A1, AHSP, KLF1. (HBB family implied).
  is@meta.data[[cluster_key]] == 25  ~ "Platelet_Megakaryocyte_Lineage_PPBP_PF4_ITGA2B",    # PPBP, PF4, GP9, ITGA2B (CD41), ITGB3 (CD61).

  ## ---- Default for unassigned (should not happen if all clusters covered) ---------
  TRUE                      ~ "Unassigned"
)
```

## gemini 1.1
```{r}
# annotation_level1: Broad cell types
cluster_key="integrated_1.1"
is$annotation2_big <- case_when(
  is@meta.data[[cluster_key]] %in% c(1, 6, 10, 12, 18)      ~ "CD4_T_Cell",
  is@meta.data[[cluster_key]] %in% c(4, 17, 30)            ~ "CD8_T_Cell",
  is@meta.data[[cluster_key]] %in% c(3, 8, 9, 23)            ~ "NK_Cell",
  is@meta.data[[cluster_key]] %in% c(5, 25)                ~ "B_Cell_Lineage", # Includes Naive B and Plasmablasts
  is@meta.data[[cluster_key]] %in% c(0, 2, 7, 13, 14, 15, 16, 20, 21, 26, 27, 28, 29, 32) ~ "Monocyte_Macrophage",
  is@meta.data[[cluster_key]] %in% c(22)                   ~ "Dendritic_Cell",
  is@meta.data[[cluster_key]] %in% c(19)                   ~ "T_Cell_Differentiated",    # For the distinct T cell population
  is@meta.data[[cluster_key]] %in% c(24)                   ~ "Erythroid",
  is@meta.data[[cluster_key]] %in% c(31)                   ~ "Megakaryocyte_Platelet",
  is@meta.data[[cluster_key]] %in% c(11)                   ~ "Treg", # Treg, grouped under CD4 T cells broadly
  TRUE                                                      ~ "Unassigned"
)
DimPlot(is,group.by="annotation2_big",label=T)
```

```{r}
# annotation_level2: Detailed cell subtypes (grouped + %in% applied)
cluster_key="integrated_1.1"
is$annotation2_detail <- case_when(
  ## ---- CD4 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(1, 6, 12)      ~ "CD4_T_Naive",
  is@meta.data[[cluster_key]] %in% c(10)           ~ "CD4_T_M_GATA3", # GATA3, CCR6 high
  is@meta.data[[cluster_key]] %in% c(11)           ~ "Treg", # FOXP3, MKI67
  is@meta.data[[cluster_key]] %in% c(18)           ~ "CD4_T_EM", # JUN/FOS high, CCR7neg

  ## ---- CD8 T cells ----------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(4)            ~ "CD8_T_CTL", # GZMs, KLRG1
  is@meta.data[[cluster_key]] %in% c(17, 30)       ~ "CD8_T_EM",

  ## ---- NK cells -------------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(3, 8, 23)     ~ "NK_Cytotoxic",
  is@meta.data[[cluster_key]] %in% c(9)            ~ "NK_IFNG+", # IFNG, XCL1/2

  ## ---- B cell Lineage -------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(5)            ~ "B_Cell_Naive",
  is@meta.data[[cluster_key]] %in% c(25)           ~ "Plasmablast_Proliferating",

  ## ---- Monocytes / Macrophages ----------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(0, 2, 14, 16, 27) ~ "Monocyte_Classical",
  is@meta.data[[cluster_key]] %in% c(7, 21)        ~ "Monocyte_Inflammatory_Activated", # IL1B, CD83, TNF, CXCLs
  is@meta.data[[cluster_key]] %in% c(13)           ~ "Monocyte_VCAN", # VCAN high
  is@meta.data[[cluster_key]] %in% c(15)           ~ "Monocyte_CD16", # FCGR3A, MS4A7
  is@meta.data[[cluster_key]] %in% c(20)           ~ "Myeloid_Activated_CD83pos_HLA_DRpos",
  is@meta.data[[cluster_key]] %in% c(26, 29)       ~ "Monocyte_MphLike_RNASEpos",
  is@meta.data[[cluster_key]] %in% c(28, 32)       ~ "Monocyte_MphLike",

  ## ---- Dendritic Cells (DC) -------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(22)           ~ "cDC", # cDC1 (XCR1), cDC2 (CD1c)

  ## ---- Other T Cell Lineages ------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(19)           ~ "T_speicalized", # PTPRC, BCL11B, TOX

  ## ---- Other Lineages -------------------------------------------------------------
  is@meta.data[[cluster_key]] %in% c(24)           ~ "Erythroid_Precursor",
  is@meta.data[[cluster_key]] %in% c(31)           ~ "Megakaryocyte_Platelet",

  ## ---- Default for unassigned -----------------------------------------------------
  TRUE                                            ~ "Unassigned"
)

```
### Subclustering
```{r}
Idents(is)="annotation2_big"
for(cluster in unique(is$annotation2_big)){
    subname=paste0(cluster,"_sub")
    is=FindSubCluster(is, cluster=cluster, graph.name="integrated_snn", subcluster.name=subname)
}

```

# DEG analysis after first annotation
## subsetting
```{r}
tc4=subset(is, annotation2_big=="CD4_T_Cell")
tc8=subset(is, annotation2_big=="CD8_T_Cell")
mo=subset(is,annotation2_big=="Monocyte_Macrophage")
treg=subset(is, annotation2_big=="Treg")
bc=subset(is, annotation2_big=="B_Cell_Lineage")
nk=subset(is, annotation2_big=="NK_Cell")
dc=subset(is, annotation2_big=="Dendritic_Cell")
tcd=subset(is, annotation2_big=="T_Cell_Differentiated")

# day 1만 뽑아
# is1=subset(is, day==1)
# 클러스터 차이
seurat_group_stats(is, grouping_var = "sample_no",categorizing_var = "annotation2_detail",comparative_var="group3")


```
## by default
```{r}
markers_CD4=FindMarkers(tc4,ident.1 = "2", group.by="group3")%>%marker_filter
markers_CD8=FindMarkers(tc8,ident.1 = "2", group.by="group3")%>%marker_filter
markers_mo=FindMarkers(mo,ident.1 = "2", group.by="group3")%>%marker_filter
markers_treg=FindMarkers(treg,ident.1 = "2", group.by="group3")%>%marker_filter
markers_bc=FindMarkers(bc,ident.1 = "2", group.by="group3")%>%marker_filter
markers_nk=FindMarkers(nk,ident.1 = "2", group.by="group3")%>%marker_filter
markers_dc=FindMarkers(dc,ident.1 = "2", group.by="group3")%>%marker_filter
markers_tcd=FindMarkers(tcd,ident.1 = "2", group.by="group3")%>%marker_filter
```

## by AUC
```{r}
is10=downsample_sobj(is,ratio=10)
all_markers_auc=FindAllMarkers(is10,test.use = "roc")

markers_auc_tc4=FindMarkers(tc4, test.use="roc")%>%marker_filter
markers_auc_tc8=FindMarkers(tc8, test.use="roc")%>%marker_filter
markers_auc_mo=FindMarkers(mo, test.use="roc")%>%marker_filter
markers_auc_treg=FindMarkers(treg, test.use="roc")%>%marker_filter
markers_auc_bc=FindMarkers(bc, test.use="roc")%>%marker_filter
markers_auc_nk=FindMarkers(nk, test.use="roc")%>%marker_filter
markers_auc_dc=FindMarkers(dc, test.use="roc")%>%marker_filter
markers_auc_tcd=FindMarkers(tcd, test.use="roc")%>%marker_filter
```

## DEG function by Claude
```{r}
pb_tc4=FindMarkers_pseudobulk(tc4, ident.1="2", group.by="group3", sample.by="exp_sample_no")
pb_tc42=FindMarkers_pseudobulk(tc4, ident.1="2", group.by="group3", sample.by="exp_sample_no", method = "edgeR")
pb_tc43=FindMarkers_pseudobulk(tc4, ident.1="2", group.by="group3", sample.by="exp_sample_no", method = "edgeR", aggregate.by = "annotation2_detail")
```

## use function with gemini
```{r}

# 클러스터의 DEG
pb_is_re=cluster_pseudobulk_deg(is, "exp_sample_no","annotation2_big")

pb_tc4_spe_in_tc4 <- run_pseudobulk_deg(analysis_level = "specific_cluster",target_cluster = "CD4_T_Cell",contrast = c(-1, 1),seurat_obj = is,assay = "SCT", slot = "counts",sample_col = "exp_sample_no", cluster_col = "annotation2_big", group_col = "group3")

pb_tc4_spe_in_tc42=do.call(run_pseudobulk_deg,)

## 하위 cluster를 이용해서.
pb_tc4_overall_in_tc4 <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = tc4,
    assay = "SCT",
    slot = "counts",
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)

# 각 클러스터 별로
# target_cluster는 무시
pb_perc <- run_pseudobulk_deg(analysis_level = "per_cluster",contrast = c(-1, 1),seurat_obj = is,assay = "SCT", slot = "counts",sample_col = "exp_sample_no", cluster_col = "annotation2_big", group_col = "group3")


# 환자 별로

pb_tc4_overall <- run_pseudobulk_deg(analysis_level = "overall",target_cluster = "CD4_T_Cell",contrast = c(-1, 1),seurat_obj = is,assay = "SCT", slot = "counts",sample_col = "exp_sample_no", cluster_col = "annotation2_big", group_col = "group3")


```



### DESeq2


## specificity score
### Tau
```{r}
markers_tau=all_markers_filtered
markers_tau$specificity <- markers_tau %>%
  group_by(cluster) %>%
  mutate(spec = (avg_log2FC - min(avg_log2FC))/sum(avg_log2FC - min(avg_log2FC)))

```



# DEG analysis
## Frequency analysis (plotting)

### visualization and statistics
```{r}

p=plot_cluster_freqs(s, identity="annotation2",group.by="type", add_significance = TRUE)
print(p)
p=test_cluster_association(s,variable_of_interest = "type", covariates=c("age.x","last_normal_dt"))
print(p)
forest_plot=plot_cluster_stats(p,plot_type = "forest")
```

## plotings

### vlnplot with p-value
```{r}
library(Seurat)
library(ggpubr)
library(patchwork)




p=vln_p(is, "TXNIP","annotation2_detail","group3")
p1=vln_p(is_sub, "TXNIP","CD4_T_Cell_sub","group3")
p2=vln_p(is_sub, "TXNIP","CD8_T_Cell_sub","group3")
p3=vln_p(is_sub, "TXNIP","Treg_sub","group3")
p4=vln_p(is_sub, "TXNIP","T_Cell_Differentiated_sub","group3")
p5=vln_p(is_sub, "TXNIP","NK_Cell_sub","group3")
p6=vln_p(is_sub, "TXNIP","Monocyte_Macrophage_sub","group3")
p7=vln_p(is_sub, "TXNIP","Dendritic_Cell_sub","group3")
p8=vln_p(is_sub, "TXNIP","B_Cell_Lineage_sub","group3")

pc1=vln_p(is, cmkr[[1]], group.by="annotation2_big", "group3")
pc2=vln_p(is, cmkr[[2]], group.by="annotation2_big", "group3")
pc3=vln_p(is, cmkr[[3]], group.by="annotation2_big", "group3")
pc4=vln_p(is, cmkr[[4]], group.by="annotation2_big", "group3")
pc5=vln_p(is, cmkr[[5]], group.by="annotation2_big", "group3")
pc6=vln_p(is, cmkr[[6]], group.by="annotation2_big", "group3")
pc7=vln_p(is, cmkr[[7]], group.by="annotation2_big", "group3")
pc8=vln_p(is, cmkr[[8]], group.by="annotation2_big", "group3")

pc9=vln_p(is, unique(unlist(inte_list))[1:10], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc10=vln_p(is, unique(unlist(inte_list))[11:20], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc11=vln_p(is, unique(unlist(inte_list))[21:30], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc12=vln_p(is, unique(unlist(inte_list))[31:40], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc13=vln_p(is, unique(unlist(inte_list))[41:50], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc14=vln_p(is, unique(unlist(inte_list))[51:60], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pc15=vln_p(is, unique(unlist(inte_list))[61:66], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")

pi1=vln_p(is, unlist(immune_cell_functional_gene_sets[[1]][[1]]), group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pi2=vln_p(is, immune_cell_functional_gene_sets[[2]], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pi3=vln_p(is, immune_cell_functional_gene_sets[[3]], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pi4=vln_p(is, immune_cell_functional_gene_sets[[4]], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pi5=vln_p(is, immune_cell_functional_gene_sets[[5]], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")
pi6=vln_p(is, immune_cell_functional_gene_sets[[6]], group.by="annotation2_big", "group3", ncol=3, assay="SCT", layer="data")


cmb(subset(is_sub,annotation2_big=="CD4_T_Cell"), "CD4_T_Cell_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="CD8_T_Cell"), "CD8_T_Cell_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="Treg"), "Treg_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="T_Cell_Differentiated"), "T_Cell_Differentiated_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="NK_Cell"), "NK_Cell_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="Monocyte_Macrophage"), "Monocyte_Macrophage_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="Dendritic_Cell"), "Dendritic_Cell_sub", group.by="group3")
cmb(subset(is_sub,annotation2_big=="B_Cell_Lineage"), "B_Cell_Lineage_sub", group.by="group3")

DimPlot(subset(is_sub,annotation2_big=="CD4_T_Cell"),label=T,group.by="CD4_T_Cell_sub")
DimPlot(subset(is_sub,annotation2_big=="CD8_T_Cell"),label=T,group.by="CD8_T_Cell_sub")
DimPlot(subset(is_sub,annotation2_big=="Treg"),label=T,group.by="Treg_sub")
DimPlot(subset(is_sub,annotation2_big=="T_Cell_Differentiated"),label=T,group.by="T_Cell_Differentiated_sub")
DimPlot(subset(is_sub,annotation2_big=="NK_Cell"),label=T,group.by="NK_Cell_sub")
DimPlot(subset(is_sub,annotation2_big=="Monocyte_Macrophage"),label=T,group.by="Monocyte_Macrophage_sub")
DimPlot(subset(is_sub,annotation2_big=="Dendritic_Cell"),label=T,group.by="Dendritic_Cell_sub")
DimPlot(subset(is_sub,annotation2_big=="B_Cell_Lineage"),label=T,group.by="B_Cell_Lineage_sub")

```
### txnip - day change
```{r}
marker1_3=FindMarkers(is, group.by="ol_time_point",ident.1 = 72,ident.2 = 24)%>%marker_filter() %>% mutate(rank=rank(p_val_daj))
marker1_3_pb=run_pseudobulk_deg(seurat_obj=subset(is,ol_time_point%in%c(24,72)), analysis_level="per_cluster", contrast=c(-1,1),group_col="ol_time_point", cluster_col="annotation2_big",sample_col="exp_sample_no") %>% marker_filter

length(intersect(marker1_3_re[marker1_3_re$avg_log2FC>0, ]$gene, marker1_3_pb[marker1_3_pb$logFC>0, ]$gene))
length(marker1_3_re[marker1_3_re$avg_log2FC>0, ]$gene)
length(marker1_3_pb[marker1_3_pb$logFC>0, ]$gene)

vln_p(subset(is, ol_time_point %in% c(24,72)),"TXNIP", split.by = "group3", group.by="ol_time_point", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72)),"TXNIP", split.by = "ol_time_point", group.by="group3", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==1),"TXNIP", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==2),"TXNIP", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")

vln_p(subset(is, ol_time_point %in% c(24,72)),"HIF1A", split.by = "group3", group.by="ol_time_point", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72)),"HIF1A", split.by = "ol_time_point", group.by="group3", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==1),"HIF1A", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==2),"HIF1A", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")

vln_p(subset(is, ol_time_point %in% c(24,72)),"NFKBIA", split.by = "group3", group.by="ol_time_point", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72)),"NFKBIA", split.by = "ol_time_point", group.by="group3", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==1),"NFKBIA", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")
vln_p(subset(is, ol_time_point %in% c(24,72) & group3==2),"NFKBIA", split.by = "ol_time_point", group.by="annotation2_big", layer="scale.data")
```

# Advanced Freq Analysis

## run by my function
```{r}
seurat_group_stats(is,grouping_var = "exp_sample_no",categorizing_var = "annotation2_big",comparative_var = "group3",test_use = c("t","u"))
```

## run by old function
```{r}
# Run the complete analysis
analysis_results <- analyze_cell_type_frequencies(
  seurat_obj = s,
  cell_type_col = "annotation1",
  sample_col = "sample_no",
  main_var = "type",
  covariates = c("sex", "age.x", "nih1d"),
  methods = c("lm")
)

# Create a dashboard of results
dashboard <- create_cell_type_dashboard(analysis_results)
```


```{r}
cell_freqs <- extract_cell_type_freq(
  seurat_obj = s,
  cell_type_col = "annotation1",  # column with cell type annotations
  sample_col = "sample_no",    # column with patient IDs
  metadata_cols = c("type", "sex", "age.x", "nih1d")
)

# View the results
head(cell_freqs$wide)  # Wide format (each cell type is a column)
head(cell_freqs$long)  # Long format (cell types in rows)

analysis_results <- analyze_cell_type_frequencies(
  seurat_obj = s,
  cell_type_col = "annotation1",
  sample_col = "sample_no",
  main_var = "type",        # Main variable of interest
  covariates = c("sex", "age"),     # Covariates to account for
  metadata_cols = c("nih1d"),    # Additional metadata
  categorical_vars = c("type", "sex"),  # Specify categorical variables
  methods = c("lm")   # Methods to use
)

# Extract results
cell_frequencies <- analysis_results$freq_data
univariate_tests <- analysis_results$univariate_results
multivariable_models <- analysis_results$multivariable_results

# View significant cell types from univariate analysis
sig_cell_types <- univariate_tests[univariate_tests$significant, ]
print(sig_cell_types)

# View plots
print(analysis_results$plots$cell_type_freq)

# For a specific cell type, view variable importance from random forest
top_cell_type <- sig_cell_types$cell_type[1]
print(analysis_results$plots$importance[[top_cell_type]][["random_forest"]])

#-------------------------------------------------
# Example 3: Working with seurat_obj metadata directly
#-------------------------------------------------

# In practice, we often want to examine the metadata first
# Here's how to do that with a Seurat object:

# examine_metadata <- function(seurat_obj) {
#   # Extract metadata
#   meta <- seurat_obj@meta.data
# 
#   # Print column names
#   cat("Metadata columns:", paste(colnames(meta), collapse=", "), "\n\n")
# 
#   # For each column, show basic statistics
#   for (col in colnames(meta)) {
#     cat("Column:", col, "\n")
# 
#     # If numeric, show summary
#     if (is.numeric(meta[[col]])) {
#       print(summary(meta[[col]]))
#     } else {
#       # If categorical, show frequency table
#       freq_table <- table(meta[[col]])
#       print(freq_table)
# 
#       # Also show percentages
#       pct_table <- prop.table(freq_table) * 100
#       print(round(pct_table, 2))
#     }
#     cat("\n")
#   }
# 
#   return(meta)
# }
# 
# metadata <- examine_metadata(stroke_seurat)

#-------------------------------------------------
# Example 4: Custom analysis for specific cell types
#-------------------------------------------------

# If you want to focus on specific cell types of interest:

# cell_types_of_interest <- c("T_cells", "Microglia", "Astrocytes")
#
# # Run univariate analysis for these cell types
# custom_univariate <- univariate_analysis(
#   freq_data = cell_freqs$wide,
#   var_of_interest = "disease_type",
#   cell_types = cell_types_of_interest,
#   is_categorical = TRUE
# )
#
# print(custom_univariate)
#
# # For cell types with significant differences, run multivariable analysis
# sig_cells <- custom_univariate$cell_type[custom_univariate$significant]
#
# for (cell_type in sig_cells) {
#   # Run lasso regression
#   lasso_model <- multivariable_analysis(
#     freq_data = cell_freqs$wide,
#     cell_type = cell_type,
#     main_var = "disease_type",
#     covariates = c("sex", "age", "severity"),
#     method = "lasso"
#   )
#
#   # Plot variable importance
#   importance_plot <- plot_variable_importance(
#     model_result = lasso_model,
#     title = paste("Importance for", cell_type)
#   )
#
#   print(importance_plot)
# }

#-------------------------------------------------
# Example 5: Using a real-world dataset
#-------------------------------------------------

# This example shows how to apply these functions to a real dataset

# 1. Load and preprocess your Seurat object
# stroke_seurat <- readRDS("path/to/your/seurat_object.rds")

# 2. Make sure cell types are annotated
# If not already annotated, you might need to run clustering and annotation
# stroke_seurat <- FindNeighbors(stroke_seurat, dims = 1:20)
# stroke_seurat <- FindClusters(stroke_seurat, resolution = 0.5)
# stroke_seurat <- RenameIdents(stroke_seurat, ...)  # Assign cell type names
# stroke_seurat$cell_type <- Idents(stroke_seurat)

# 3. Extract frequencies and run analysis
# analysis_results <- analyze_cell_type_frequencies(
#   seurat_obj = stroke_seurat,
#   cell_type_col = "cell_type",
#   sample_col = "patient_id",
#   main_var = "disease_type",
#   covariates = c("sex", "age", "severity")
# )

# 4. Save results to files
# save(analysis_results, file = "cell_type_analysis_results.RData")
#
# # Save univariate results to CSV
# write.csv(analysis_results$univariate_results, "univariate_results.csv", row.names = FALSE)
#
# # Save plots to PDF
# pdf("cell_type_plots.pdf", width = 10, height = 8)
# print(analysis_results$plots$cell_type_freq)
# for (cell_type in names(analysis_results$plots$importance)) {
#   for (method in names(analysis_results$plots$importance[[cell_type]])) {
#     print(analysis_results$plots$importance[[cell_type]][[method]])
#   }
# }
# dev.off()
```

# checking all the genes
```{r}

is$nih_change=as.numeric(is$nih_change)
result_lm_df=linear_fit(is, pb_tc4_overall_in_tc4$gene[1:50], "exp_sample_no")
result_lm_df2=linear_fit(is, pb_tc4$gene[1:10])

result3=pseudobulk_linear_fit_legacy(is, pb_tc4_overall_in_tc4$gene[1:50],"exp_sample_no","nih_change")
result4=pseudobulk_linear_fit_legacy2(is, pb_tc4_overall_in_tc4$gene[1:50],"exp_sample_no","nih_change")
result5=pseudobulk_linear_fit_legacy2(is, pb_tc4_overall_in_tc4$gene[1:50],"exp_sample_no","nih_change", "group3")
result6=pseudobulk_linear_fit_legacy2(tc4, pb_tc4_overall_in_tc4$gene,"exp_sample_no","nih_change", "group3")
result7=pseudobulk_linear_fit(tc4, pb_tc4_overall_in_tc4$gene,"exp_sample_no","nih_change", "group3")

result7_post=post_hoc_slope_comparison(result7)
result7_post2=post_hoc_slope_comparison(result7, adjustment_scope = "per_gene")


result8=pseudobulk_linear_fit(is, pb_tc4_overall_in_tc4$gene,"exp_sample_no","nih_change", "group3")
result9=pseudobulk_linear_fit(tc4, pb_tc4_overall_in_tc4$gene,"exp_sample_no","nih_change", "group3")
```


# monocle
## tutorial
```{r}
small_a549_colData_df <- readRDS(system.file("extdata",
                                             "small_a549_dex_pdata.rda",
                                             package = "monocle3"))
small_a549_rowData_df <- readRDS(system.file("extdata",
                                             "small_a549_dex_fdata.rda",
                                             package = "monocle3"))
small_a549_exprs <- readRDS(system.file("extdata",
                                        "small_a549_dex_exprs.rda",
                                        package = "monocle3"))
small_a549_exprs <- small_a549_exprs[,row.names(small_a549_colData_df)]

cds <- new_cell_data_set(expression_data = small_a549_exprs,
                         cell_metadata = small_a549_colData_df,
                         gene_metadata = small_a549_rowData_df)
```

## loading
```{r}
library(monocle3)
# cds <- load_mm_data(mat_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/matrix.mtx.gz", 
#                     feature_anno_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/features.tsv.gz", 
#                     cell_anno_path = "/data/kjc1/projects/#130.stroke/count_matrix/1_IS_72/barcodes.tsv.gz")
sobj=is

# 1. pull out a raw-counts matrix (genes × cells)
counts <- GetAssayData(sobj, assay = "RNA", slot = "counts")
# 2. grab your cell metadata (cells must match the columns of `counts`)
cell_meta <- sobj@meta.data
# 3. build a gene metadata table (genes must match the rows of `counts`)
gene_meta <- data.frame(
  gene_short_name = rownames(counts), 
  row.names        = rownames(counts)
)

# 4. now create your CDS
cds <- new_cell_data_set(
  expression_data = counts,
  cell_metadata   = cell_meta,
  gene_metadata   = gene_meta
)

## Step 1: Normalize and pre-process the data
cds <- preprocess_cds(cds, num_dim = 100)

# auxillary #1
plot_pc_variance_explained(cds)

## (Optional)Step 2: Remove batch effects with cell alignment
# cds <- align_cds(cds, alignment_group = "batch")

## Step 3: Reduce the dimensions using UMAP; used preprocessing default=PCA
cds <- reduce_dimension(cds) # you can choose reduction_method="tSNE"

# auxillary #2
# plot_cells(cds)
# plot_cells(cds, color_cells_by="seurat_clusters", label_cell_groups=T)
# plot_cells(cds, reduction_method="tSNE", color_cells_by="cao_cell_type", label_cell_groups=FALSE)
# plot_cells(cds, genes=c("cpna-2", "egl-21", "ram-2", "inos-1"))


## Step 4: Cluster the cells 
cds <- cluster_cells(cds) #resolution=1e-5

plot_cells(cds, color_cells_by="cluster", label_cell_groups=T, group_label_size =5)
plot_cells(cds, color_cells_by="group3", label_cell_groups=T, group_label_size =5)
# plot_cells_3d(cds, color_cells_by="cluster")


## Step 5: Learn a graph # needed to see trajectory
cds <- learn_graph(cds)


## Step 6: Order cells
cds <- order_cells(cds)
plot_cells(cds,
           color_cells_by = "pseudotime",
           label_cell_groups=FALSE,
           label_leaves=FALSE,
           label_branch_points=FALSE,
           graph_label_size=1.5)

```

## ?? DEG analysis, gene expression batch correction by clinical information, etc.
```{r}

## Auxillary 
marker_test_res <- top_markers(cds, group_cells_by="partition", 
                               reference_cells=1000, cores=8)
## auxillary...
pr_graph_test_res <- graph_test(cds_subset, neighbor_graph="knn", cores=8)
pr_deg_ids <- row.names(subset(pr_graph_test_res, morans_I > 0.01 & q_value < 0.05))
gene_module_df <- find_gene_modules(cds_subset[pr_deg_ids,], resolution=1e-3)
plot_cells(cds_subset, genes=gene_module_df, 
           show_trajectory_graph=FALSE, 
           label_cell_groups=FALSE)

# With regression:
gene_fits <- fit_models(cds, model_formula_str = "~pseudotime")
fit_coefs <- coefficient_table(gene_fits)
emb_time_terms <- fit_coefs %>% filter(term == "embryo.time")
emb_time_terms <- emb_time_terms %>% mutate(q_value = p.adjust(p_value))
sig_genes <- emb_time_terms %>% filter (q_value < 0.05) %>% pull(gene_short_name)

# With graph autocorrelation:
pr_test_res <- graph_test(cds,  neighbor_graph="principal_graph", cores=4)
pr_deg_ids <- row.names(subset(pr_test_res, q_value < 0.05))

```

## subset cells by branch

```{r}
cds_sub <- choose_graph_segments(cds)
```

## 3D trajectory

```{r}
cds_3d <- reduce_dimension(cds, max_components = 3)
cds_3d <- cluster_cells(cds_3d)
cds_3d <- learn_graph(cds_3d)
cds_3d <- order_cells(cds_3d, root_pr_nodes=get_earliest_principal_node(cds))

cds_3d_plot_obj <- plot_cells_3d(cds_3d, color_cells_by="partition")
```
# pseudotime and simple regression
```{r}

```

# pseudo time and general additive model
```{r}
## 0.  사전 준비

# Seurat → Monocle3 CDS(pseudotime) → pseudotime 벡터
pt_cells <- pseudotime(cds)                    # named numeric, 길이 = ncol(cds)

# Seurat object 내 그룹(조건) 정보: 반드시 factor
cond_cells = factor(sobj$group3)
levels(cond_cells)=c("control","treated")
names(cond_cells) <- colnames(sobj)            # 이름 붙이기

# DEG 테이블에서 top-gene 몇 개 추출
top_genes <- pb_tc4 %>% 
  arrange(FDR) %>% 
  slice_head(n=50) %>% 
  pull(gene)

# counts matrix 가져오기 (genes × cells)
cnt_mat <- counts(cds)[ top_genes, ]           # dgCMatrix
cnt_mat=counts(cds)

# 공통으로 사용할 “하나의 pseudotime lineage” 용 cellWeights
# (한 줄기로 보기 위해 모든 셀 가중치 = 1)
cw_cells <- matrix(1,
                   nrow = length(pt_cells),
                   ncol = 1,
                   dimnames = list(names(pt_cells),"Lineage1"))


```

## tradeSeq fitGAM
1. tradeSeq fitGAM() 예시
```{r}
library(tradeSeq)
mean(pt_cells)    # Inf
var(pt_cells)     # NaN

# Inf/NaN 제거
valid <- names(pt_cells)[is.finite(pt_cells)]
cnt_mat   <- cnt_mat[, valid]
pt_cells  <- pt_cells[valid]
cond_cells<- cond_cells[valid]
cw_cells  <- cw_cells[valid,,drop=FALSE]

# [0,1]로 정규화해도 spline 안정화에 도움
pt_cells <- (pt_cells - min(pt_cells)) / diff(range(pt_cells))


```

## GAM
```{r}
library(mgcv) 
# 예시: 첫 번째 top gene
gene <- top_genes[3]
gene="TXNIP"
gene="IL32"

# 1) 데이터프레임 구성: cell ordering, NA/Inf 제거
cells <- intersect(colnames(cnt_mat), names(pt_cells))
dat <- tibble(
  expr       = as.numeric(cnt_mat[gene, cells]),
  pseudotime = pt_cells[cells],
  cond       = cond_cells[cells]
) %>%
  filter(is.finite(expr), is.finite(pseudotime))

# 2) GAM 모델링: 공통 smooth + 조건별 smooth(interaction)
#    cond는 factor, family는 음이항(UMI) 또는 Gaussian(log1p expr) 선택
fit <- gam(expr ~ 
             s(pseudotime, k=6, bs="cr") + 
             cond + 
             s(pseudotime, by=cond, k=6, bs="cr"),
           family = nb(link="log"),
           data   = dat,
           method = "REML")

# 3) 요약 & 통계
summary(fit)                    # p-value·edf 등
# 두 모델 비교(Interaction 유무)
fit0 <- update(fit, . ~ . - s(pseudotime, by=cond, k=6))
anova(fit0, fit, test="Chisq") # H0: 곡선 shape 차이 없음

# 4) 예측 곡선 & Total Variation
newd <- expand.grid(
  pseudotime = seq(min(dat$pseudotime), max(dat$pseudotime), length=200),
  cond       = levels(dat$cond)
)
newd$fit <- predict(fit, newdata=newd, type="response")

tv <- newd %>%
  group_by(cond) %>%
  summarize(TV = sum(abs(diff(fit))), .groups="drop")

# 5) 시각화
ggplot(newd, aes(pseudotime, fit, color=cond)) +
  geom_line(linewidth=1) +
  geom_point(size=1) +
  ggtitle(paste0(gene, " pseudotime fit"))
```

### residual 추가
```{r}
# 1) residuals 계산
dat$resid <- residuals(fit, type = "pearson")  

# 2) 예측곡선(newd)에 이미fit 컬럼이 들어 있음
p <- ggplot() +
  # (a) 원본 데이터 포인트: 실제 expr
  geom_point(data = dat,
             aes(x = pseudotime, y = expr, color = cond),
             alpha = 0.2, size = 0.8) +
  # (b) residuals 산점도: pseudotime vs residual
  geom_point(data = dat,
             aes(x = pseudotime, y = resid),
             color = "grey50", alpha = 0.3, size = 0.5) +
  # (c) 예측된 smooth 곡선
  geom_line(data = newd,
            aes(x = pseudotime, y = fit, color = cond),
            size = 1) +
  labs(y = "Expression / Residual",
       title = paste(gene, "pseudotime GAM fit + residuals")) +
  theme_classic()
print(p)
```

### metrics 계산, plot 저장
```{r}
calc_metrics <- function(dat, newd){
  TV    <- newd %>% group_by(cond) %>% summarize(TV = sum(abs(diff(fit))), .groups="drop")
  DR    <- newd %>% group_by(cond) %>% summarize(DR = max(fit)-min(fit), .groups="drop")
  R2    <- 1 - sum((dat$expr - predict(fit, type="response")[match(dat$pseudotime, newd$pseudotime)])^2) /
                sum((dat$expr - mean(dat$expr))^2)
  list(TV=TV, DR=DR, R2=R2)
}

# 2) 단일 gene 분석 함수
analyze_gene <- function(gene){
  # (a) 데이터 준비
  cells <- intersect(colnames(cnt_mat), names(pt_cells))
  dat   <- tibble(expr       = as.numeric(cnt_mat[gene, cells]),
                  pseudotime = pt_cells[cells],
                  cond       = cond_cells[cells]) %>%
           filter(is.finite(expr), is.finite(pseudotime))
  if(nrow(dat) < 50) return(NULL)  # 너무 셀이 적으면 skip

  # (b) GAM 적합
  fit <- gam(expr ~
               s(pseudotime, k=6, bs="cr") +
               cond +
               s(pseudotime, by=cond, k=6, bs="cr"),
             family = nb(link="log"),
             data   = dat,
             method = "REML")

  # (c) 예측 곡선, residual
  newd <- expand.grid(pseudotime = seq(min(dat$pseudotime),
                                       max(dat$pseudotime), length=200),
                      cond       = levels(dat$cond))
  newd$fit <- predict(fit, newdata=newd, type="response")
  dat$resid <- residuals(fit, type="pearson")

  # (d) 지표 계산
  mets <- calc_metrics(dat, newd)

  # (e) 시각화
  p <- ggplot() +
       geom_point(data=dat,
                  aes(x=pseudotime, y=expr, color=cond),
                  alpha=0.2, size=0.6) +
       geom_point(data=dat,
                  aes(x=pseudotime, y=resid),
                  color="grey50", alpha=0.3, size=0.4) +
       geom_line(data=newd,
                 aes(x=pseudotime, y=fit, color=cond),
                 size=1) +
       theme_classic() +
       labs(title=gene, y="expr / resid")

  # (f) 파일로 저장
  ggsave(filename = paste0("/data/kjc1/mylit/myR/plots", gene, ".png"),
         plot     = p, width=4, height=3, dpi=300, create.dir = T)

  list(gene=gene, metrics=mets, plot=p)
}

# 3) 전체 분석: top_genes에 대해
results <- lapply(top_genes, analyze_gene)
# NULL 체크
results <- compact(results)

# 4) 결과 예시 확인
results[[1]]$metrics$TV
results[[1]]$metrics$DR
results[[1]]$metrics$R2
```

#### 병렬화 처리 로직을 포함, 함수 내재화
```{r}
library(mgcv); library(ggplot2); library(dplyr); library(purrr)

analyze_gene <- function(gene){
  # 1) 데이터 준비
  cells <- intersect(colnames(cnt_mat), names(pt_cells))
  dat <- tibble(
    expr       = as.numeric(cnt_mat[gene, cells]),
    pseudotime = pt_cells[cells],
    cond       = cond_cells[cells]
  ) %>% filter(is.finite(expr), is.finite(pseudotime))
  if(nrow(dat)<50) return(NULL)

  # 2) GAM 적합
  fit <- gam(expr ~
               s(pseudotime, k=6, bs="cr") +
               cond +
               s(pseudotime, by=cond, k=6, bs="cr"),
             family="nb", data=dat, method="REML")

  # 3) 예측 곡선 & residuals
  newd <- expand.grid(
    pseudotime=seq(min(dat$pseudotime), max(dat$pseudotime), length=200),
    cond=levels(dat$cond)
  )
  newd$fit <- predict(fit, newdata=newd, type="response")
  dat$resid <- residuals(fit, type="pearson")

  # 4) 지표 계산
  TV <- newd %>% group_by(cond) %>% summarize(TV=sum(abs(diff(fit))), .groups="drop")
  DR <- newd %>% group_by(cond) %>% summarize(DR=max(fit)-min(fit), .groups="drop")
  R2 <- 1 - sum((dat$expr - predict(fit, type="response"))^2) /
            sum((dat$expr - mean(dat$expr))^2)
  
  expr_range <- range(dat$expr, na.rm=TRUE)
  fit_range <- range(newd$fit, na.rm=TRUE)
  scale_factor <- diff(expr_range) / diff(fit_range)
  # 5) 플롯
  p <- ggplot() +
         geom_point(data=dat, aes(pseudotime, expr / scale_factor, color=cond),
                    alpha=0.2, size=0.6) +
         geom_line(data=newd, aes(pseudotime, fit, color=cond), size=1) +
          scale_y_continuous(
            name = "Fit Expression",
            sec.axis = sec_axis(~ . * scale_factor,
                                name = "Raw Expression")
          )+
         theme_classic() +
         labs(title=gene,
              subtitle=paste0("TV:",round(TV$TV,1),
                              " DR:",round(DR$DR,1),
                              " R2:",round(R2,2)))

  # 6) 파일 저장
  ggsave(paste0("/data/kjc1/mylit/plots/",gene,".png"), p, width=4, height=3, dpi=300)
  
  list(gene=gene, TV=TV, DR=DR, R2=R2, plot=p)
}

# 병렬(ex: 4코어) 적용
core_to_use=50

library(parallel)

if(detectCores()>core_to_use){}else{core_to_use=detectCores()-1}
if(length(top_genes)%/%core_to_use<10){
  results <- lapply(top_genes, analyze_gene)
}else{
  results <- mclapply(top_genes, analyze_gene, mc.cores=core_to_use)
}

results <- compact(results)




```


```{r}
# 1) 숫자 부분만 뽑아서 데이터프레임으로 합치기
numeric_df <- do.call(rbind,
  lapply(results, function(res_i) {
    # 1:4번 추출 → 벡터를 행벡터로 바꿔서 데이터프레임 생성
    row <- unlist(res_i[1:4])
    df  <- as.data.frame(t(row))
    # 컬럼명 지정 (원하는 이름으로 바꿔주세요)
    colnames(df) <- paste0("X", 1:4)
    df
  })
)
rownames(numeric_df) <- names(results)  # 리스트 이름이 있으면 행 이름으로 사용
colnames(numeric_df) = c("gene","condition1","condition2","TV1","TV2","condition1","condition2","DR1","DR2","R^2")


# 2) 플롯 부분만 따로 추출
plot_list <- lapply(results, `[[`, 5)

# 예: 첫 번째 플롯 그리기
print(plot_list[[1]])
```




```{r}
sce_with_sling1=run_slingshot_from_seurat(is,
                                          cluster_col="integrated_1.1",
                                          reduced_dim_name = "umap",
                                          start_cluster = "0",
                                          count_assay_name="SCT")
```
# NicheNet

```{r}

NN_analysis_tc4=run_nichenet_analysis_legacy(is,
                                 species = c("human"),
                                 sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"
                                                    ),
                                 receiver_celltype="CD4_T_Cell",
                                 assay_name = "SCT",
                                 cluster_col="annotation2_big",
                                 receiver_DE_ident1="2",
                                 receiver_DE_ident2 = NULL,
                                 receiver_DE_group_by="group3",
                                 min_pct_expressed = 0.10,
                                 p_val_adj_cutoff = 0.05,
                                 logfc_cutoff = 0.25,
                                 top_n_ligands = 20,
                                 top_n_targets_per_ligand = 200,
                                 ligand_target_cutoff = 0.33,
                                 nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                 nichenet_data_name= "NicheNetData",
                                 output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                 run_circos = TRUE,
                                 run_signaling_path_inference = TRUE,
                                 verbose = TRUE)

NN_analysis_tc8=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="CD8_T_Cell",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)


NN_analysis_mo=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="Monocyte_Macrophage",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

NN_analysis_nk=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="NK_Cell",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

NN_analysis_dc=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="Dendritic_Cell",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

NN_analysis_bc=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="B_Cell_Lineage",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

NN_analysis_treg=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="Treg",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

NN_analysis_tcd=run_nichenet_analysis_legacy(is,
                                      species = c("human"),
                                      sender_celltypes=c("CD4_T_Cell",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="T_Cell_Differentiated",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      run_signaling_path_inference = TRUE,
                                      verbose = TRUE)

saveRDS(NN_analysis_tc4, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_tc4.rds")
saveRDS(NN_analysis_tc8, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_tc8.rds")
saveRDS(NN_analysis_mo, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_mo.rds")
saveRDS(NN_analysis_nk, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_nk.rds")
saveRDS(NN_analysis_dc, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_dc.rds")
saveRDS(NN_analysis_bc, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_bc.rds")
saveRDS(NN_analysis_treg, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_treg.rds")
saveRDS(NN_analysis_tcd, "/data/kjc1/projects/#130.stroke/sobj/nn/NN_analysis_tcd.rds")


NNre_bc=run_nichenet_analysis_new(is,
                                      species = c("human"),
                                      sender_celltypes=c("B_Cell_Lineage",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="T_Cell_Differentiated",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                                      verbose = TRUE)

NNre_bc2=run_nichenet_analysis(is,
                                      species = c("human"),
                                      sender_celltypes=c("B_Cell_Lineage",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="T_Cell_Differentiated",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                              circos_cex_text=2,
                                      verbose = TRUE)

NNre_bc3=run_nichenet_analysis_test(is,
                                      species = c("human"),
                                      sender_celltypes=c("B_Cell_Lineage",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                      receiver_celltype="T_Cell_Differentiated",
                                      assay_name = "SCT",
                                      cluster_col="annotation2_big",
                                      receiver_DE_ident1="2",
                                      receiver_DE_ident2 = NULL,
                                      receiver_DE_group_by="group3",
                                      nichenet_data_dir ="/data/kjc1/projects/NicheNet",
                                      nichenet_data_name= "NicheNetData",
                                      output_dir ="/data/kjc1/mylit/plots/NicheNet/",
                                      run_circos = TRUE,
                              circos_cex_text=2,
                                      verbose = TRUE)

NN_prepare=prepare_nichenet_circos_data(lr_network_top_df_large=NN_analysis_bc$ligand_receptor_network_df,
                                         best_upstream_ligands=NN_analysis_bc$best_upstream_ligands,
                                         seurat_obj = is,
                                         sender_celltypes = c("B_Cell_Lineage",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                         assay_name = "SCT", # Default, ensure it matches your usage
                                         min_pct_expressed = 0.10,
                                         ligand_sender_map = NULL,
                                         # circos_args = list(sender_palette_name = ,
                                         #                    receptor_color_name = ,
                                         #                    receptor_color_idx = ,)
                                        )

NN_circos=draw_nichenet_circos_plot(NN_prepare,
                                    cex_text = 0.8,
                                    link_transparency = 0.25,
                                    plot_title = NULL,
                                    show_legend = TRUE,
                                    sender_palette_legend = NULL, # From circos_data
                                    receptor_color_legend = NULL, # From circos_data
                                    legend_size = 0.9,
                                    legend_inset = c(-0.15,-0.1)
)

circos_prepare_list=list()
circos_list=list()
for(cell in unique(is$annotation2_big)){
  NN_prepare=prepare_nichenet_circos_data(lr_network_top_df_large=NN_analysis_bc$ligand_receptor_network_df,
                                         best_upstream_ligands=NN_analysis_bc$best_upstream_ligands,
                                         seurat_obj = is,
                                         sender_celltypes = c("B_Cell_Lineage",
                                                    "Monocyte_Macrophage","B_Cell_Lineage" , "NK_Cell", "Dendritic_Cell", "Treg",
                                                    "CD8_T_Cell", "T_Cell_Differentiated"),
                                         assay_name = "SCT", # Default, ensure it matches your usage
                                         min_pct_expressed = 0.10,
                                         ligand_sender_map = NULL,
                                         # circos_args = list(sender_palette_name = ,
                                         #                    receptor_color_name = ,
                                         #                    receptor_color_idx = ,)
                                        )
  NN_circos=draw_nichenet_circos_plot(NN_prepare,
                                    cex_text = 0.8,
                                    link_transparency = 0.25,
                                    plot_title = NULL,
                                    show_legend = TRUE,
                                    sender_palette_legend = NULL, # From circos_data
                                    receptor_color_legend = NULL, # From circos_data
                                    legend_size = 0.9,
                                    legend_inset = c(-0.15,-0.1)
)
}

```

## NN_ligands, target gene lists
```{r}

```


```{r}

```



# ScatterPlot

## patient-static metric and Features
```{r}
receiver_genes=c("ICAM1","DDIT4","TXNIP","NFKBIA","FTH1","BCL3","RELB","SOD2","WTAP","TGFBR2","SFXN1","CXCR4","IL7R","CD3E","IFI44L")
sender_genes=c("ITGAL","PSAP","ICAM1","RETN","ANXA1","S100A12","NAMPT","HMGB1","CD40","IL15","ITGAL","CD40LG","ADAM17","TNF","TNFSF12")

result8=pseudobulk_linear_fit(is, receiver_genes,"exp_sample_no","nih_change", "group3")
result9=pseudobulk_linear_fit(is, sender_genes,"exp_sample_no","nih_change", "group3")
result10=pseudobulk_linear_fit(tc4, receiver_genes,"exp_sample_no","nih_change", "group3")
result11=pseudobulk_linear_fit(tc4, sender_genes,"exp_sample_no","nih_change", "group3")


result8=pseudobulk_linear_fit(is, receiver_genes,"exp_sample_no","nih_change")
result9=pseudobulk_linear_fit(is, sender_genes,"exp_sample_no","nih_change")
result10=pseudobulk_linear_fit(tc4, receiver_genes,"exp_sample_no","nih_change")
result11=pseudobulk_linear_fit(tc4, sender_genes,"exp_sample_no","nih_change")

scatter_smooth(is, "CD40")
scatter_smooth(is, "ITGAL")
scatter_smooth(is, "CD40LG")
scatter_smooth(is, "RETN")
scatter_smooth(is, "IL15")
scatter_smooth(is, "DDIT4")
scatter_smooth(is, "BCL3")
scatter_smooth(is, "FTH1")
scatter_smooth(is, "CXCR4")
scatter_smooth(is, "IFI44L")
scatter_smooth(is, "TXNIP")

scatter_smooth(tc4, "CD40")
scatter_smooth(tc4, "ITGAL")
scatter_smooth(tc4, "CD40LG")
scatter_smooth(tc4, "HMGB1")
scatter_smooth(tc4, "IL15")
scatter_smooth(tc4, "DDIT4")
scatter_smooth(tc4, "CD3E")
scatter_smooth(tc4, "NFKBIA")
scatter_smooth(tc4, "CXCR4")
scatter_smooth(tc4, "IFI44L")
scatter_smooth(tc4, "TXNIP")

scatter_smooth(treg, "CD40")
scatter_smooth(treg, "ITGAL")
scatter_smooth(treg, "CD40LG")
scatter_smooth(treg, "HMGB1")
scatter_smooth(treg, "IL15")
scatter_smooth(treg, "DDIT4")
scatter_smooth(treg, "CD3E")
scatter_smooth(treg, "NFKBIA")
scatter_smooth(treg, "CXCR4")
scatter_smooth(treg, "IFI44L")
scatter_smooth(treg, "TXNIP")

```

## time and features
```{r}
tc4_to_scatter_time=subset(is, onset_to_sample>0&annotation2_big=="CD4_T_Cell")

scatter_smooth_colored(tc4_to_scatter_time, "TXNIP", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(tc4_to_scatter_time, "HMGB1", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")

scatter_smooth_colored(tc4_to_scatter_time, "STAT3", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(tc4_to_scatter_time, "STAT1", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(tc4_to_scatter_time, "STAT6", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(tc4_to_scatter_time, "IL15", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")

scatter_smooth_colored(tc4_to_scatter_time, "HMGB1", group.by="sample_no", x_var="onset_to_sample", color_by="group3")
scatter_smooth_colored(tc4_to_scatter_time, "IL15", group.by="sample_no", x_var="onset_to_sample", color_by="group3")
scatter_smooth_colored(tc4_to_scatter_time, "STAT3", group.by="sample_no", x_var="onset_to_sample", color_by="group3")
scatter_smooth_colored(tc4_to_scatter_time, "STAT1", group.by="sample_no", x_var="onset_to_sample", color_by="group3")
scatter_smooth_colored(tc4_to_scatter_time, "STAT6", group.by="sample_no", x_var="onset_to_sample", color_by="group3")
scatter_smooth_colored(tc4_to_scatter_time, "IL15", group.by="sample_no", x_var="onset_to_sample", color_by="group3")

scatter_smooth_colored(subset(tc4_to_scatter_time,group3==2), "TXNIP", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(subset(tc4_to_scatter_time,group3==1), "TXNIP", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")

tc4_to_scatter_time$TXNIP=FetchData(tc4_to_scatter_time,"TXNIP")$TXNIP

tc4_to_scatter_time$NFKBIA=FetchData(tc4_to_scatter_time,"NFKBIA")$NFKBIA

scatter_smooth_colored(subset(tc4_to_scatter_time,group3==2), "NFKBIA", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
scatter_smooth_colored(subset(tc4_to_scatter_time,group3==1), "NFKBIA", group.by="sample_no", x_var="onset_to_sample", color_by="nih_change")
```

# corr
```{r}

markers_bootstrapped_tc4=intersect(intersect(intersect(sum_detail_tc4_4[sum_detail_tc4_4$n_sig==10,]$gene,sum_detail_tc4_2[sum_detail_tc4_2$n_sig==10,]$gene),sum_detail_tc4_1[sum_detail_tc4_1$n_sig==10,]$gene),rownames(tc4@assays$SCT$scale.data))

corr_TXNIP1=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="pearson", assay="SCT", slot="scale.data")

corr_TXNIP2=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="pearson", assay="SCT", slot="scale.data", group.by = "sample_no") #not working
# Error in (function (cond)  : 
#   error in evaluating the argument 'x' in selecting a method for function 'as.data.frame': subscript out of bounds

corr_TXNIP3=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="pearson", assay="SCT", slot="data", group.by = "sample_no")
# Error in (function (cond)  : 
#   error in evaluating the argument 'x' in selecting a method for function 'as.data.frame': subscript out of bounds

corr_TXNIP4=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="pearson", assay="SCT", slot="scale.data", split.by = "group3") #not working
# Error in numeric(nrowz) : invalid 'length' argument

corr_TXNIP5=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="pearson", assay="SCT", slot="scale.data", group.by = "annotation2_detail") #not working
# Error in (function (cond)  : 
#   error in evaluating the argument 'x' in selecting a method for function 'as.data.frame': subscript out of bounds


corr_TXNIP6=corr_with_major(tc4, "TXNIP", markers_bootstrapped_tc4, method="spearman", assay="SCT", slot="scale.data")

corr_TXNIP7=corr_with_major(subset(tc4,group3==2), "TXNIP", markers_bootstrapped_tc4, method="spearman", assay="SCT", slot="scale.data")

corr_TXNIP8=corr_with_major(subset(tc4,group3==1), "TXNIP", markers_bootstrapped_tc4, method="spearman", assay="SCT", slot="scale.data")

# 1) 세포 산점도 (선형 회귀)
scatter_smooth_cells(tc4, "TXNIP", "IL7R",
                     regression = "lm",
                     assay_x = "SCT",
                     assay_y="SCT",
                     color_by = "annotation2_detail")

scatter_plot_cells(tc4, "TXNIP", "IL7R",
                     regression = "linear",
                     assay_x = "SCT",
                     assay_y="SCT",
                     feature_color = "annotation2_detail")

# 2) 세포 산점도 (LASSO, λ 자동)
scatter_plot_cells(pbmc, "nCount_RNA", "percent.mt",
                   regression = "lasso")

# 3) 유전자 메트릭 산점도
scatter_plot_genes(gene_df, "avg_log2FC", "pct_1",
                   feature_col = "p_val_adj",
                   regression = "loess")
```

# pseudotime
```{r}

gene_list <- c("TXNIP", "IL32")
condition_column <- "group3"
output_destination_dir <- "/data/kjc1/mylit/plots/gam_analysis_v3"
# # # (만약 cds 객체에 조건 정보가 없다면, 먼저 추가해야 합니다)
# # # 예: cell_conditions <- factor(sobj$group3)
# # # names(cell_conditions) <- colnames(sobj)
# # # common_cells <- intersect(colnames(cds), names(cell_conditions))
# # # cds_subset <- cds[, common_cells]
# # # colData(cds_subset)$condition_name <- cell_conditions[common_cells]
# # # condition_column <- "condition_name"

# total
pseudo1=process_gene_list_dynamics(cds_obj=cds,
                              gene_list="TXNIP",
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )

pseudo2=process_gene_list_dynamics(cds_obj=cds,
                              gene_list="IL15",
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )


# CD4
pseudo3=analyze_gene_dynamics(cds_obj=cds_tc4,
                              gene_id="TXNIP",
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )


pseudo4=analyze_gene_dynamics(cds_obj=cds_tc4,
                              gene_id="IL15",
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )



easyfunc4=function(gene){
  analyze_gene_dynamics(cds_obj=cds_tc4,
                              gene_id=gene,
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )
}
easyfunc=function(gene){
  analyze_gene_dynamics(cds_obj=cds,
                              gene_id=gene,
                              condition_col_name=condition_column,
                              output_dir=output_destination_dir
                              )
}

# DDIT4, NFKB1A
p5= easyfunc4("DDIT4")
p6=easyfunc("DDIT4")

p7= easyfunc4("NFKBIA")
p8=easyfunc("NFKBIA")

p7= easyfunc4("CD40")
p8=easyfunc("CD40")

p7= easyfunc4("CD40LG")
p8=easyfunc("CD40LG")

p7= easyfunc4("ITGAL")
p8=easyfunc("ITGAL")

```



# python section

## python을 쓰기 위한 설정
```{r}
# knitr 설정  
knitr::opts_chunk$set(echo = TRUE)

# reticulate 로딩 및 Python 환경 지정
library(reticulate)
# conda env 를 쓰신다면
use_condaenv("scenvi", required = TRUE)

# Seurat → h5Seurat/H5AD 변환에 필요한 패키지
library(Seurat)
library(SeuratDisk)


```

## scanpy로 sc파일 읽기
```{python}

```

# re

```{r}

# markers
markers_re=FindMarkers(is1, ident.1 = "2",group.by="group3")%>%marker_filter
markers_CD4_re=FindMarkers(tc4r,ident.1 = "2", group.by="group3")%>%marker_filter
markers_CD8_re=FindMarkers(tc8r,ident.1 = "2", group.by="group3")%>%marker_filter
markers_mo_re=FindMarkers(mor,ident.1 = "2", group.by="group3")%>%marker_filter
markers_treg_re=FindMarkers(tregr,ident.1 = "2", group.by="group3")%>%marker_filter
markers_bc_re=FindMarkers(bcr,ident.1 = "2", group.by="group3")%>%marker_filter
markers_nk_re=FindMarkers(nkr,ident.1 = "2", group.by="group3")%>%marker_filter
markers_dc_re=FindMarkers(dcr,ident.1 = "2", group.by="group3")%>%marker_filter
markers_tcd_re=FindMarkers(tcdr,ident.1 = "2", group.by="group3")%>%marker_filter

pb_re = run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = is1,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE)%>%marker_filter()
pb_tc4_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = tc4r,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_tc8_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = tc8r,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_mo_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = mor,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_treg_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = tregr,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_bc_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = bcr,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_nk_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = nkr,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_dc_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = dcr,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()
pb_tcd_re <- run_pseudobulk_deg(
    analysis_level = "overall",
    seurat_obj = tcdr,
    assay = "SCT",
    slot = "counts", #edgeR이 counts 기반으로 만들어진 툴
    sample_col = "exp_sample_no",       # 환자 정보 컬럼
    cluster_col = "annotation2_detail", # 하위 클러스터 정보 컬럼 (aggregation에 사용됨)
    group_col = "group3",               # 비교할 그룹 정보 컬럼
    contrast = c(-1, 1),                # group3의 두 번째 레벨 vs 첫 번째 레벨 비교
    min_count = 10,                     # 이전과 동일한 min_count 사용
    verbose = TRUE
)%>%marker_filter()

# pb_tc4_re=pb_tc4_re%>%marker_filter()
# pb_tc8_re=pb_tc8_re%>%marker_filter()
# pb_treg_re=pb_treg_re%>%marker_filter()
# pb_tcd_re=pb_tcd_re%>%marker_filter()
# pb_mo_re=pb_mo_re%>%marker_filter()
# pb_dc_re=pb_dc_re%>%marker_filter()
# pb_nk_re=pb_nk_re%>%marker_filter()
# pb_bc_re=pb_bc_re%>%marker_filter()

markers_list=list(
  markers_CD4_re=markers_CD4_re$gene,
  markers_CD8_re=markers_CD8_re$gene,
  markers_mo_re=markers_mo_re$gene,
  markers_treg_re=markers_treg_re$gene,
  markers_bc_re=markers_bc_re$gene,
  markers_nk_re=markers_nk_re$gene,
  markers_dc_re=markers_dc_re$gene,
  markers_tcd_re=markers_tcd_re$gene
)

markers_list=list(
  markers_T_re=union(union(union(markers_CD4_re$gene,markers_CD8_re$gene),markers_treg_re$gene),markers_tcd_re$gene),
  markers_mo_re=markers_mo_re$gene,
  markers_bc_re=markers_bc_re$gene,
  markers_nk_re=markers_nk_re$gene,
  markers_dc_re=markers_dc_re$gene
)

markers_list=list(
  markers_re=markers_re$gene,
  markers_T_re=union(union(union(markers_CD4_re$gene,markers_CD8_re$gene),markers_treg_re$gene),markers_tcd_re$gene),
  markers_mo_re=markers_mo_re$gene,
  markers_bc_re=markers_bc_re$gene,
  markers_nk_re=markers_nk_re$gene,
  markers_dc_re=markers_dc_re$gene
)

markers_list=list(
  pb_tc4_re=pb_tc4_re$gene,
  pb_tc8_re=pb_tc8_re$gene,
  pb_treg_re=pb_treg_re$gene,
  pb_tcd_re=pb_tcd_re$gene,
  pb_bc_re=pb_bc_re$gene,
  pb_dc_re=pb_dc_re$gene,
  pb_nk_re=pb_nk_re$gene,
  pb_mo_re=pb_mo_re$gene
)

markers_list=list(
  pb_re=pb_re$gene,
  pb_T_re=union(union(union(pb_tc4_re$gene,pb_tc8_re$gene),pb_treg_re$gene),pb_tcd_re$gene),
  pb_bc_re=pb_bc_re$gene,
  pb_dc_re=pb_dc_re$gene,
  pb_nk_re=pb_nk_re$gene,
  pb_mo_re=pb_mo_re$gene
)

p= upset_gene_lists(markers_list)
p

markers_list=list(
  pb_tc4_re=pb_tc4_re,
  pb_tc8_re=pb_tc8_re,
  pb_treg_re=pb_treg_re,
  pb_tcd_re=pb_tcd_re,
  pb_bc_re=pb_bc_re,
  pb_dc_re=pb_dc_re,
  pb_nk_re=pb_nk_re,
  pb_mo_re=pb_mo_re
)

is1t=subset(is1,onset_to_sample>0)
is1t1=subset(is1t, group3==1)
is1t2=subset(is1t, group3==2)

tc4rt=subset(tc4r,onset_to_sample>0)
tc4r1=subset(tc4rt, group3==1)
tc4r2=subset(tc4rt, group3==2)

bcrt=subset(bcr,onset_to_sample>0)
bcr1=subset(bcrt, group3==1)
bcr2=subset(bcrt, group3==2)

fit1=pseudobulk_linear_fit(is1,genes=pb_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit2=pseudobulk_linear_fit(is1,genes=pb_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change",group_col = "group3")
fit3=pseudobulk_linear_fit(is1t1,genes=pb_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit4=pseudobulk_linear_fit(is1t2,genes=pb_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")

fit5=pseudobulk_linear_fit(tc4rt,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit6=pseudobulk_linear_fit(tc4rt,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change",group_col = "group3")
fit7=pseudobulk_linear_fit(tc4r1,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit8=pseudobulk_linear_fit(tc4r2,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")

fit9=pseudobulk_linear_fit(bcrt,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit10=pseudobulk_linear_fit(bcrt,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change",group_col = "group3")
fit11=pseudobulk_linear_fit(bcr1,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")
fit12=pseudobulk_linear_fit(bcr2,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="nih_change")

fita=pseudobulk_linear_fit(tc4rt,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")
fitb=pseudobulk_linear_fit(tc4rt,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample",group_col = "group3")
fitc=pseudobulk_linear_fit(tc4r1,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")
fitd=pseudobulk_linear_fit(tc4r2,genes=pb_tc4_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")

fite=pseudobulk_linear_fit(bcrt,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")
fitf=pseudobulk_linear_fit(bcrt,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample",group_col = "group3")
fitg=pseudobulk_linear_fit(bcr1,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")
fith=pseudobulk_linear_fit(bcr2,genes=pb_bc_re$gene ,sample_col="exp_sample_no", numeric_predictor="onset_to_sample")

# slope
# -
scatter_smooth_colored(is1t, "HLA-DQA1",color_by="onset_to_sample")
scatter_smooth_colored(is1t, "IL16",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "CYBA",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "CYBA",color_by="onset_to_sample")
# +
scatter_smooth_colored(is1t2, "MTRNR2L12",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "MTRNR2L12",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "TNFAIP3",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "TNFAIP3",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "IL1B",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "IL1B",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "CD69",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "CD69",color_by="onset_to_sample")

# p-value
# small
scatter_smooth_colored(is1t2, "FCMR",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "FCMR",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "LBH",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "LBH",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "TAX1BP1",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "TAX1BP1",color_by="onset_to_sample")
# big

scatter_smooth_colored(is1t2, "CAPG",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "CAPG",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "EIF4B",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "EIF4B",color_by="onset_to_sample")
scatter_smooth_colored(is1t2, "EEF2",color_by="onset_to_sample")
scatter_smooth_colored(is1t1, "EEF2",color_by="onset_to_sample")

# Tc
scatter_smooth_colored(tc4r1, "CD40LG",color_by="onset_to_sample")
scatter_smooth_colored(tc4r2, "CD40LG",color_by="onset_to_sample")
scatter_smooth_colored(tc4rt, "TXNIP",color_by="onset_to_sample")
scatter_smooth_colored(tc4r1, "TXNIP",color_by="onset_to_sample")
scatter_smooth_colored(tc4r2, "TXNIP",color_by="onset_to_sample")
scatter_smooth_colored(tc4r1, "CXCR4",color_by="onset_to_sample")
scatter_smooth_colored(tc4r2, "CXCR4",color_by="onset_to_sample")

scatter_smooth_colored(tc4r1, "FCMR",color_by="onset_to_sample")
scatter_smooth_colored(tc4r2, "FCMR",color_by="onset_to_sample")

# by time
scatter_smooth_colored(tc4r1, "TXNIP",color_by="nih_change", x_var = "onset_to_sample")
scatter_smooth_colored(tc4r2, "TXNIP",color_by="nih_change", x_var = "onset_to_sample")
scatter_smooth_colored(tc4r1, "FKBP5",color_by="nih_change", x_var = "onset_to_sample")
scatter_smooth_colored(tc4r2, "FKBP5",color_by="nih_change", x_var = "onset_to_sample")
```



# bootstrapping
```{r}
obj_char_names <- c("is", "tc4", "tc8", "tcd", "treg", "bc", "mo", "dc", "nk")
matching=c("CD4_T_Cell","CD4_T_Cell","CD8_T_Cell","T_Cell_Differentiated","Treg","B_Cell_Lineage","Monocyte_Macrophage","Dendritic_Cell","NK_Cell")
matching_list=list()
for(i in 1:9){matching_list[[obj_char_names[[i]]]]=matching[[i]]}
# 실제 객체들을 리스트로 가져오기
# 만약 객체들이 다른 이름 규칙을 따른다면 이 부분을 수정하세요.
tryCatch({
  all_sobjects <- mget(obj_char_names, ifnotfound = list(NULL))
  if(any(sapply(all_sobjects, is.null))) {
    stop("일부 Seurat 객체를 찾을 수 없습니다: ", paste(obj_char_names[sapply(all_sobjects, is.null)], collapse=", "))
  }
}, error = function(e) {
  stop("객체 로딩 중 오류 발생: ", e$message, 
       "\n'is', 'tc4', ..., 'nk' 객체들이 현재 R 환경에 로드되어 있는지 확인해주세요.")
})
# 결과에 사용될 객체 이름 (좀 더 설명적으로)
# obj_list_names <- c("full_dataset", "TC4", "TC8", "TCD", "Treg", "BC", "Monocytes", "DC", "NK")
# names(all_sobjects) <- obj_list_names
# 또는 기존 이름 사용
names(all_sobjects) <- obj_char_names


# 다운샘플링 비율
ratios_pseudobulk <- c(4/3, 4/2, 4/1) # 즉, c(4/3, 2, 4)
ratio_roc <- 10
n_iterations <- 10 # 반복 횟수

# --- run_pseudobulk_deg 및 FindMarkers 공통 파라미터 ---
# 이 부분은 사용자의 실제 데이터 구조에 맞게 *반드시* 수정해야 합니다.
ASSAY_NAME <- "SCT" # 또는 "RNA" 등 분석에 사용할 assay
SLOT_PSEUDOBULK <- "counts" # run_pseudobulk_deg에 사용할 slot
SLOT_FINDMARKERS <- "data"  # FindMarkers에 사용할 slot (일반적으로 'data' 또는 'scale.data')

SAMPLE_COL <- "exp_sample_no" # 샘플 ID가 저장된 메타데이터 컬럼명
GROUP_COL <- "group3"  # 비교할 그룹("Control", "Treatment" 등) 정보가 있는 메타데이터 컬럼명

# 대비(contrast) 설정: group_col의 factor 레벨 순서에 따라 결정됩니다.
# 예: GROUP_COL에 "Control"이 첫 번째 레벨, "Treatment"가 두 번째 레벨일 때,
# Treatment vs Control 비교는 c(-1, 1) 입니다.
# 이는 모든 객체에 걸쳐 일관되어야 하거나, 객체별로 동적으로 설정해야 합니다.
# 여기서는 모든 객체에 동일한 대비를 적용한다고 가정합니다.
# **실제 데이터의 group_col 레벨을 반드시 확인하고 설정하세요!**
# 예시: levels(factor(all_sobjects[["is"]][[GROUP_COL, drop=TRUE]])) 등을 통해 확인
CONTRAST_VECTOR <- c(-1, 1) # 예: 두 번째 그룹 vs 첫 번째 그룹

# FindMarkers를 위한 그룹명 (GROUP_COL 내의 실제 값)
# 이 값들도 사용자의 데이터에 맞게 수정해야 합니다.
IDENT1_NAME <- "2" # ident.1에 해당 (예: 질병군, 처리군)
IDENT2_NAME <- "1"   # ident.2에 해당 (예: 정상군, 대조군)

# 결과를 저장할 리스트 초기화
all_deg_results <- list()
result_idx <- 1

# 2. 부트스트래핑 DEG 분석 루프

cat("부트스트래핑 DEG 분석을 시작합니다...\n")

# 2.1 Pseudobulk DEG 분석
cat("\n--- Pseudobulk DEG 분석 중 ---\n")
for (obj_key_name in names(all_sobjects)) {
  original_sobj <- all_sobjects[[obj_key_name]]
  cat(paste0("객체 처리 중: ", obj_key_name, "\n"))
  seedplus=0
  for (ratio_val in ratios_pseudobulk) {
    cat(paste0("  비율: ", round(ratio_val, 3), "\n"))
    seedplus=seedplus+100
    for (iter_n in 1:n_iterations) {
      cat(paste0("    반복: ", iter_n, "\n"))
      
      # 결과 저장을 위한 정보
      run_info <- list(
        object_name = obj_key_name,
        method = "pseudobulk",
        ratio = ratio_val,
        iteration = iter_n
      )

      tryCatch({
        # 2.1.1 다운샘플링
        if (is.null(body(downsample_sobj))) stop("downsample_sobj 함수가 정의되지 않았습니다.")
        downsampled_obj <- downsample_sobj(original_sobj, ratio = ratio_val, seed=1234+iter_n+seedplus)

        # 다운샘플링 후 셀 수 확인 (너무 적으면 건너뛰기)
        if (ncol(downsampled_obj) < 10) { # 최소 셀 수 기준 (예시)
          cat("      다운샘플링 후 셀 수가 너무 적어 건너<U+375C>니다 (", ncol(downsampled_obj), " cells).\n")
          next
        }
        
        # run_pseudobulk_deg 실행 전 그룹별 샘플 수 확인 (선택적이지만 권장)
        # 이 함수는 내부적으로 min_samples_per_group_cluster (기본값 2)를 사용합니다.
        # analysis_level = "overall" 이므로, 전체 객체에서 group_col별 sample_col의 유니크한 개수를 확인.
        sample_group_counts <- table(downsampled_obj[[SAMPLE_COL, drop=TRUE]], 
                                     downsampled_obj[[GROUP_COL, drop=TRUE]])
        if (any(apply(sample_group_counts > 0, 2, sum) < 2 )) {
             cat("      그룹당 최소 샘플 수를 만족하지 못하여 건너<U+375C>니다.\n")
             next
        }


        # 2.1.2 Pseudobulk DEG 실행
        # `cluster_col` 인자: `analysis_level = "overall"`일 때는 모든 셀을 하나의 큰 그룹으로 간주하여
        # `group_col`을 기준으로 비교합니다. `run_pseudobulk_deg` 함수가 `cluster_col`을 어떻게
        # 처리하는지 확인이 필요합니다. 만약 형식적으로라도 컬럼이 필요하다면, 모든 셀에 동일한 값을 가진
        # 임시 컬럼을 추가하거나 (예: `downsampled_obj$temp_cluster <- "all_cells"`),
        # 또는 이미 `obj_key_name`으로 subset된 경우, 해당 객체의 모든 cell_type 메타데이터가 `obj_key_name`이라면
        # `cell_type` 컬럼을 그대로 사용할 수 있습니다. 여기서는 `obj_key_name`을 사용한다고 가정.
        # 더 안전한 방법은 analysis_level="overall"일 때 cluster_col이 무시되거나,
        # 모든 셀이 단일 클러스터에 속함을 명시하는 것입니다.
        # 예시에서는 `cluster_col`에 임시로 객체 이름을 사용 (모든 cell이 해당 cell type이라는 가정)
        # downsampled_obj$analysis_cluster_id <- obj_key_name 
        # cluster_col_to_use <- "analysis_cluster_id"
        # 또는, 만약 객체 내 cell_type 메타데이터가 이미 obj_key_name으로 통일되어 있다면,
        cluster_col_to_use <- if ("cell_type" %in% names(downsampled_obj@meta.data)) "cell_type" else GROUP_COL # 임시 방편, 함수 요구사항 확인 필요

        deg_res_pb <- run_pseudobulk_deg(
          analysis_level = "overall",
          contrast = CONTRAST_VECTOR,
          seurat_obj = downsampled_obj,
          assay = ASSAY_NAME,
          slot = SLOT_PSEUDOBULK,
          sample_col = SAMPLE_COL,
          # cluster_col = cluster_col_to_use, # 함수가 "overall"에서 이 인자를 어떻게 쓰는지 확인!
                                             # 만약 "overall"에서 무시한다면 NULL 또는 생략 가능
                                             # 여기서는 예제대로 cell_type을 넣어봅니다.
                                             # 단, 이 경우 해당 객체 내 모든 cell의 cell_type이 동일하거나,
                                             # 함수가 이를 적절히 처리해야 합니다.
          cluster_col = if ("cell_type" %in% names(downsampled_obj@meta.data)) "cell_type" else GROUP_COL, # 주의: 이 부분은 함수의 정확한 요구사항에 따라야 함
          group_col = GROUP_COL,
          min_samples_per_group_cluster = 2, # 기본값
          verbose = FALSE
        )

        if (nrow(deg_res_pb) > 0) {
          # 결과에 실행 정보 추가
          deg_res_pb_annotated <- deg_res_pb %>%
            mutate(
              object = obj_key_name,
              method = "pseudobulk",
              ratio = ratio_val,
              iteration = iter_n,
              .before = 1 # 정보 컬럼들을 맨 앞에 추가
            )
          all_deg_results[[result_idx]] <- deg_res_pb_annotated
          result_idx <- result_idx + 1
        } else {
          cat("      DEG 결과가 없습니다.\n")
        }
        
          deg_res_pb2 <- run_pseudobulk_deg(
          analysis_level = "specific_cluster",
          target_cluster = matching_list[[obj_key_name]],
          contrast = CONTRAST_VECTOR,
          seurat_obj = downsample_sobj(is,ratio_val,1234+iter_n+seedplus),
          assay = ASSAY_NAME,
          slot = SLOT_PSEUDOBULK,
          sample_col = SAMPLE_COL,
          cluster_col = "annotation2_big", # 함수가 "overall"에서 이 인자를 어떻게 쓰는지 확인!
                                             # 만약 "overall"에서 무시한다면 NULL 또는 생략 가능
                                             # 여기서는 예제대로 cell_type을 넣어봅니다.
                                             # 단, 이 경우 해당 객체 내 모든 cell의 cell_type이 동일하거나,
                                             # 함수가 이를 적절히 처리해야 합니다.
          # cluster_col = if ("cell_type" %in% names(downsampled_obj@meta.data)) "cell_type" else GROUP_COL, # 주의: 이 부분은 함수의 정확한 요구사항에 따라야 함
          group_col = GROUP_COL,
          min_samples_per_group_cluster = 2, # 기본값
          verbose = FALSE
        )

        if (nrow(deg_res_pb) > 0) {
          # 결과에 실행 정보 추가
          deg_res_pb2_annotated <- deg_res_pb2 %>%
            mutate(
              object = obj_key_name,
              method = "detail",
              ratio = ratio_val,
              iteration = iter_n,
              .before = 1 # 정보 컬럼들을 맨 앞에 추가
            )
          all_deg_results[[result_idx]] <- deg_res_pb2_annotated
          result_idx <- result_idx + 1
        } else {
          cat("      DEG 결과가 없습니다.\n")
        }

      }, error = function(e) {
        cat(paste0("      오류 발생 (Pseudobulk): ", obj_key_name, ", 비율 ", round(ratio_val,3), ", 반복 ", iter_n, "\n"))
        cat(paste0("      오류 메시지: ", e$message, "\n"))
        # 오류 발생 시에도 정보 기록 (선택적)
        # error_df <- tibble(!!!run_info, gene="ERROR", PValue=NA, FDR=NA, logFC=NA, error_message=e$message)
        # all_deg_results[[result_idx]] <- error_df
        # result_idx <- result_idx + 1
      })
      gc() # 메모리 정리
    }
  }
}

# 2.2 FindMarkers (ROC) 분석
cat("\n--- FindMarkers (ROC) 분석 중 ---\n")
for (obj_key_name in names(all_sobjects)) {
  original_sobj <- all_sobjects[[obj_key_name]]
  cat(paste0("객체 처리 중: ", obj_key_name, "\n"))

  # ROC는 고정된 ratio 사용
  ratio_val_roc <- ratio_roc
  cat(paste0("  비율: ", ratio_val_roc, "\n"))
  seedplus=seedplus+100
  for (iter_n in 1:n_iterations) {
    cat(paste0("    반복: ", iter_n, "\n"))
    
    run_info <- list(
        object_name = obj_key_name,
        method = "FindMarkers_ROC",
        ratio = ratio_val_roc,
        iteration = iter_n
      )

    tryCatch({
      # 2.2.1 다운샘플링
      if (is.null(body(downsample_sobj))) stop("downsample_sobj 함수가 정의되지 않았습니다.")
      downsampled_obj <- downsample_sobj(original_sobj, ratio = ratio_val_roc, seed=1234+iter_n+seedplus)

      if (ncol(downsampled_obj) < 10) {
        cat("      다운샘플링 후 셀 수가 너무 적어 건너<U+375C>니다 (", ncol(downsampled_obj), " cells).\n")
        next
      }
      
      # FindMarkers 실행 전 그룹별 셀 수 확인
      # group.by 인자에 지정된 컬럼(GROUP_COL)을 기준으로 각 그룹(IDENT1_NAME, IDENT2_NAME)에 셀이 있는지 확인
      # min.cells.group 기본값이 3이므로, 그 이상 있는지 확인하면 좋음
      group_counts_fm <- table(downsampled_obj[[GROUP_COL, drop=TRUE]])
      if (!IDENT1_NAME %in% names(group_counts_fm) || group_counts_fm[IDENT1_NAME] < 3 ||
          !IDENT2_NAME %in% names(group_counts_fm) || group_counts_fm[IDENT2_NAME] < 3) {
          cat("      FindMarkers에 필요한 그룹별 최소 셀 수를 만족하지 못하여 건너<U+375C>니다.\n")
          next
      }

      # 2.2.2 FindMarkers (ROC) 실행
      deg_res_roc <- FindMarkers(
        downsampled_obj,
        ident.1 = IDENT1_NAME,
        ident.2 = IDENT2_NAME,
        group.by = GROUP_COL, # GROUP_COL을 기준으로 그룹핑
        test.use = "roc",
        assay = ASSAY_NAME,
        slot = SLOT_FINDMARKERS,
        verbose = FALSE,
        min.cells.group = 3 # 기본값, 필요시 조정 (너무 작으면 AUC 불안정)
      )

      if (nrow(deg_res_roc) > 0) {
        deg_res_roc_annotated <- deg_res_roc %>%
          rownames_to_column(var = "gene") %>% # gene 이름을 컬럼으로
          mutate(
            object = obj_key_name,
            method = "FindMarkers_ROC",
            ratio = ratio_val_roc,
            iteration = iter_n,
            .before = 1
          )
        all_deg_results[[result_idx]] <- deg_res_roc_annotated
        result_idx <- result_idx + 1
      } else {
        cat("      DEG 결과가 없습니다.\n")
      }

    }, error = function(e) {
      cat(paste0("      오류 발생 (FindMarkers_ROC): ", obj_key_name, ", 비율 ", ratio_val_roc, ", 반복 ", iter_n, "\n"))
      cat(paste0("      오류 메시지: ", e$message, "\n"))
      # error_df <- tibble(!!!run_info, gene="ERROR", avg_log2FC=NA, myAUC=NA, p_val_adj=NA, error_message=e$message) # 컬럼명은 ROC 결과에 맞게
      # all_deg_results[[result_idx]] <- error_df
      # result_idx <- result_idx + 1
    })
    gc() # 메모리 정리
  }
}

# 3. 모든 결과 종합
cat("\n--- 모든 결과 종합 중 ---\n")
if (length(all_deg_results) > 0) {
  # purrr::compact를 사용하여 NULL 요소(오류 등으로 결과가 생성되지 않은 경우) 제거
  # final_combined_degs <- bind_rows(compact(all_deg_results))
  # 또는 NULL이 없다고 가정하거나, 위에서 오류 시에도 tibble을 넣었다면 compact 불필요
  final_combined_degs <- bind_rows(all_deg_results)

  # 결과 요약 확인
  cat("\n종합된 DEG 결과 요약:\n")
  print(head(final_combined_degs))
  cat("\n객체 및 방법별 결과 수:\n")
  print(table(final_combined_degs$object, final_combined_degs$method))

  # 결과 파일로 저장 (예: CSV)
  # output_filename <- paste0("bootstrapped_deg_results_", format(Sys.Date(), "%Y%m%d"), ".csv")
  # write.csv(final_combined_degs, output_filename, row.names = FALSE)
  # cat(paste0("\n결과가 ", output_filename, " 파일로 저장되었습니다.\n"))
  
  # RDS로 저장하면 R에서 다시 불러오기 편함
  output_filename_rds <- paste0("bootstrapped_deg_results_", format(Sys.Date(), "%Y%m%d"), ".rds")
  saveRDS(final_combined_degs, file = output_filename_rds)
  cat(paste0("\n결과가 ", output_filename_rds, " 파일로 저장되었습니다.\n"))

} else {
  cat("처리된 DEG 결과가 없습니다.\n")
}

cat("\n부트스트래핑 DEG 분석이 완료되었습니다.\n")

```

#### meta-analysis for boot
```{r}
# 0. 필요 라이브러리 로드
library(dplyr)
library(tidyr)
# library(metap) # p-value 결합을 원할 경우 설치 및 주석 해제 (install.packages("metap"))

# 1. 데이터 로드 (이전에 생성된 final_combined_degs 사용)
if (!exists("final_combined_degs")) {
  stop("먼저 'final_combined_degs' 데이터프레임을 로드해주세요.")
  # 예시: final_combined_degs <- readRDS("bootstrapped_deg_results_YYYYMMDD.rds")
}

# 2. 분석 방법별 컬럼명 표준화 및 전처리
cat("데이터 전처리 및 컬럼 표준화 중...\n")
processed_degs <- final_combined_degs %>%
  mutate(
    # Effect size (logFC) 표준화
    standard_logFC = case_when(
      method %in% c("pseudobulk", "detail") & "logFC" %in% names(.) ~ logFC,
      method == "FindMarkers_ROC" & "avg_log2FC" %in% names(.) ~ avg_log2FC,
      TRUE ~ NA_real_
    ),
    # P-value 표준화 (FindMarkers_ROC는 p-value가 없다고 하심)
    standard_p_value = case_when(
      method %in% c("pseudobulk", "detail") & "PValue" %in% names(.) ~ PValue,
      # FindMarkers_ROC는 p_val 컬럼이 없으므로, 해당 라인 불필요. NA로 처리됨.
      TRUE ~ NA_real_
    ),
    # FDR 표준화 (FindMarkers_ROC는 p_val_adj가 FDR 역할. 만약 이마저 없다면 NA)
    standard_fdr = case_when(
      method %in% c("pseudobulk", "detail") & "FDR" %in% names(.) ~ FDR,
      #method == "FindMarkers_ROC" & "p_val_adj" %in% names(.) ~ p_val_adj, # FindMarkers_ROC에 FDR 컬럼이 있다면
      TRUE ~ NA_real_ # FindMarkers_ROC에 FDR에 해당하는 컬럼이 없다면 NA
    ),
    # AUC 표준화
    standard_auc = case_when(
      method == "FindMarkers_ROC" & "myAUC" %in% names(.) ~ myAUC,
      #method == "FindMarkers_ROC" & "AUC" %in% names(.) ~ AUC, # 다른 이름의 AUC 컬럼 가능성
      TRUE ~ NA_real_
    ),
    # avg_diff 표준화 (FindMarkers_ROC 전용)
    standard_avg_diff = case_when(
      method == "FindMarkers_ROC" & "avg_diff" %in% names(.) ~ avg_diff,
      TRUE ~ NA_real_
    )
  ) %>%
  # 필요한 컬럼 선택 (matches 함수로 유연하게 선택)
  select(
    gene, object, method, ratio, iteration, # 기본 정보 컬럼
    standard_logFC, standard_p_value, standard_fdr, standard_auc, standard_avg_diff, # 표준화된 핵심 컬럼
    matches("pct\\.1"), matches("pct\\.2"), matches("power") # 기타 보조 지표 컬럼
  )

# 3. 유의성 기준 설정
SIGNIFICANCE_THRESHOLD_FDR <- 0.05

cat("메타 분석 요약 중...\n")
# 4. 그룹별 요약 통계 계산
meta_summary <- processed_degs %>%
  group_by(object, method, ratio, gene) %>%
  summarise(
    n_iterations_run = n(),

    # 1) 검출 빈도 (FDR 기반)
    # standard_fdr이 NA가 아닌 경우에만 계산 (FindMarkers_ROC는 FDR이 없을 수 있음)
    n_significant_fdr = if(any(!is.na(standard_fdr))) sum(standard_fdr < SIGNIFICANCE_THRESHOLD_FDR, na.rm = TRUE) else 0,
    detection_frequency_fdr = if(any(!is.na(standard_fdr))) n_significant_fdr / n_iterations_run else 0,

    # 2) Effect size (logFC) 종합
    mean_logFC = mean(standard_logFC, na.rm = TRUE),
    median_logFC = median(standard_logFC, na.rm = TRUE),
    sd_logFC = sd(standard_logFC, na.rm = TRUE),
    mean_logFC_if_sig = if(any(!is.na(standard_fdr))) mean(standard_logFC[standard_fdr < SIGNIFICANCE_THRESHOLD_FDR], na.rm = TRUE) else NA_real_,

    # 3) P-value 종합 (Fisher's method 예시 - metap 패키지 필요)
    #    FindMarkers_ROC는 standard_p_value가 NA이므로, 이 부분은 pseudobulk/detail에 주로 적용됨.
    combined_p_fisher = if (requireNamespace("metap", quietly = TRUE) && sum(!is.na(standard_p_value)) > 1) {
        p_vals_to_combine <- na.omit(standard_p_value)
        p_vals_to_combine[p_vals_to_combine == 0] <- .Machine$double.eps
        p_vals_to_combine[p_vals_to_combine == 1] <- 1 - .Machine$double.eps
        if(length(p_vals_to_combine) > 1) {
           tryCatch(metap::sumlog(p_vals_to_combine)$p, error = function(e) NA_real_)
        } else { NA_real_ }
      } else { NA_real_ },
    combined_fdr_fisher = if(!is.na(combined_p_fisher)) p.adjust(combined_p_fisher, method="BH") else NA_real_,

    # 4) 기타 지표 종합 (주로 FindMarkers_ROC 결과)
    mean_auc = if(any(!is.na(standard_auc))) mean(standard_auc, na.rm = TRUE) else NA_real_,
    median_auc = if(any(!is.na(standard_auc))) median(standard_auc, na.rm = TRUE) else NA_real_,
    
    mean_avg_diff = if(any(!is.na(standard_avg_diff))) mean(standard_avg_diff, na.rm = TRUE) else NA_real_,
    median_avg_diff = if(any(!is.na(standard_avg_diff))) median(standard_avg_diff, na.rm = TRUE) else NA_real_,

    mean_pct1 = if("pct.1" %in% names(.)) mean(get("pct.1"), na.rm = TRUE) else NA_real_,
    mean_pct2 = if("pct.2" %in% names(.)) mean(get("pct.2"), na.rm = TRUE) else NA_real_,
    mean_power = if("power" %in% names(.)) mean(get("power"), na.rm = TRUE) else NA_real_,
    
    n_na_logfc = sum(is.na(standard_logFC)),
    n_na_fdr = sum(is.na(standard_fdr)),

    .groups = 'drop'
  ) %>%
  arrange(object, method, ratio, desc(detection_frequency_fdr), gene)

cat("메타 분석 요약 완료.\n")

# 5. 결과 확인
print(head(meta_summary))
cat("\n'meta_summary' 데이터프레임 구조:\n")
print(str(meta_summary))


# 6. FindMarkers_ROC 결과에 대한 주석
cat("\n[FindMarkers_ROC 결과 참고]\n")
cat(" - FindMarkers_ROC 방법은 p-value/FDR을 직접 제공하지 않을 수 있습니다.\n")
cat("   이 경우 'n_significant_fdr' 및 'detection_frequency_fdr'은 0 또는 NA로 표시될 수 있습니다.\n")
cat("   AUC ('mean_auc', 'median_auc') 및 'power'가 주요 판별 지표로 활용됩니다.\n")
cat(" - 'avg_diff'의 의미를 확인하고 해석에 참고하세요 (예: 발현 비율의 차이 또는 평균 발현량 차이).\n")
cat(" - 'myAUC' (standard_auc) 값이 0.5에 가깝다면 그룹 간 구별 능력이 낮음을 의미할 수 있습니다.\n")

# (선택) 결과 저장
# current_date_str <- format(Sys.Date(), "%Y%m%d")
# output_meta_filename_rds <- paste0("meta_summary_results_", current_date_str, ".rds")
# saveRDS(meta_summary, file = output_meta_filename_rds)
# cat(paste0("\n종합 결과가 RDS 파일로 저장되었습니다: ", output_meta_filename_rds, "\n"))

# output_meta_filename_csv <- paste0("meta_summary_results_", current_date_str, ".csv")
# write.csv(meta_summary, output_meta_filename_csv, row.names = FALSE)
# cat(paste0("종합 결과가 CSV 파일로 저장되었습니다: ", output_meta_filename_csv, "\n"))
```

#### meta by O3
```{r}
final_filtered=final_combined_degs%>%marker_filter()
cutoff_for_roc_power=0.4

degs_flagged <- final_filtered %>% 
  mutate(signif = case_when(
    !is.na(FDR) & FDR < 0.05 ~ TRUE,
    !is.na(power) &  power < cutoff_for_roc_power ~ TRUE,
    TRUE ~ FALSE))
#A. Method only (easiest to read)
#lvl <- c("method")
# B. Method + ratio (distinguishes subsampling depth)
# lvl <- c("method", "ratio")
# C. Method + ratio + object (full detail)
lvl <- c("method", "ratio", "object")
summary_tbl <- degs_flagged %>% 
  group_by(gene, !!!syms(lvl)) %>%                # !!! splices the level vector
  summarise(
    n_iter        = n(),                          # total tests for this gene-level combo
    n_sig         = sum(signif),                  # how many times FDR < 0.05
    prop_sig      = n_sig / n_iter,               # convenience column (0-1)
    
    # --- EFFECT-SIZE METRICS --------------------
    mean_logFC    = mean(logFC,    na.rm = TRUE),
    mean_logCPM   = mean(logCPM,   na.rm = TRUE),
    mean_myAUC    = mean(myAUC,    na.rm = TRUE),
    mean_avgDiff  = mean(avg_diff, na.rm = TRUE),
    mean_power    = mean(power,    na.rm = TRUE),
    mean_avgLog2  = mean(avg_log2FC, na.rm = TRUE),
    mean_pct1     = mean(pct.1,    na.rm = TRUE),
    mean_pct2     = mean(pct.2,    na.rm = TRUE),
    #stde_logFC=stderr(logFC),
        se_logFC = sqrt(var(logFC, na.rm=T)/n_sig),
        se_logCPM = sqrt(var(logCPM, na.rm=T)/n_sig),
        se_myAUC = sqrt(var(myAUC, na.rm=T)/n_sig),
        se_avg_diff = sqrt(var(avg_diff, na.rm=T)/n_sig),
        se_power= sqrt(var(power, na.rm=T)/n_sig),
        se_avg_log2FC = sqrt(var(avg_log2FC, na.rm=T)/n_sig),
        se_pct.1 = sqrt(var(pct.1, na.rm=T)/n_sig),
        se_pct.2 = sqrt(var(pct.2, na.rm=T)/n_sig),
    
    # --- P-VALUE META-ANALYSIS (optional) -------
    # Fisher’s combined p (needs ≥ 2 non-NA p-values)
    fisher_p      = if (sum(!is.na(PValue)) > 1) {
                      metap::sumlog(PValue)$p
                    } else { NA_real_ }
  ) %>% 
  ungroup()

sum_detail=summary_tbl[summary_tbl$method=="detail", ]
sum_pb=summary_tbl[summary_tbl$method=="pseudobulk", ]
sum_roc=summary_tbl[summary_tbl$method=="FindMarkers_ROC", ]

sum_detail_tc4=sum_detail[sum_detail$object=="tc4",]
sum_roc_tc4=sum_roc[sum_roc$object=="tc4", ]

mybar(sum_detail_tc4, n_sig, bins=10)
mybar(sum_roc_tc4, n_sig, bins=10)

sum_detail_tc4_4=sum_detail_tc4[as.integer(sum_detail_tc4$ratio)==4,]
sum_detail_tc4_2=sum_detail_tc4[as.integer(sum_detail_tc4$ratio)==2,]
sum_detail_tc4_1=sum_detail_tc4[as.integer(sum_detail_tc4$ratio)==1,]
mybar(sum_detail_tc4_4, n_sig, bins=10)
mybar(sum_detail_tc4_2, n_sig, bins=10)
mybar(sum_detail_tc4_1, n_sig, bins=10)


sum_detail_tc4_1=sum_detail_tc4_1%>%mutate(logfisherp=-log(fisher_p))
sum_detail_tc4_2=sum_detail_tc4_2%>%mutate(logfisherp=-log(fisher_p))
sum_detail_tc4_4=sum_detail_tc4_4%>%mutate(logfisherp=-log(fisher_p))

scatter_smooth_colored(sum_detail_tc4_1,feature="logfisherp", x_var="mean_logFC",group.by="gene", color_by = "se_logFC")
scatter_smooth_colored()
summarizer=function(degs_flagged,lvl=c("method")){
  summary_tbl <- degs_flagged %>% 
  group_by(gene, !!!syms(lvl)) %>%                # !!! splices the level vector
  summarise(
    n_iter        = n(),                          # total tests for this gene-level combo
    n_sig         = sum(signif),                  # how many times FDR < 0.05
    prop_sig      = n_sig / n_iter,               # convenience column (0-1)
    
    # --- EFFECT-SIZE METRICS --------------------
    mean_logFC    = mean(logFC,    na.rm = TRUE),
    mean_logCPM   = mean(logCPM,   na.rm = TRUE),
    mean_myAUC    = mean(myAUC,    na.rm = TRUE),
    mean_avgDiff  = mean(avg_diff, na.rm = TRUE),
    mean_power    = mean(power,    na.rm = TRUE),
    mean_avgLog2  = mean(avg_log2FC, na.rm = TRUE),
    mean_pct1     = mean(pct.1,    na.rm = TRUE),
    mean_pct2     = mean(pct.2,    na.rm = TRUE),
    
    # --- P-VALUE META-ANALYSIS (optional) -------
    # Fisher’s combined p (needs ≥ 2 non-NA p-values)
    fisher_p      = if (sum(!is.na(PValue)) > 1) {
                      metap::sumlog(PValue)$p
                    } else { NA_real_ }
  ) %>% 
  ungroup()
  
  return(summary_tbl)
}

subsetted_objects=c("tc4","tc8","tcd","treg","bc","dc","nk","mo")
summary_list=list()
for(object in subsetted_objects){
  deg=degs_flagged[degs_flagged$object==object,]
  summary_list[[object]][["total"]]=summarizer(deg)
  summary_list[[object]][["roc"]]=summary_list[[object]][["total"]][summary_list[[object]][["total"]]$method=="FindMarkers_ROC"& summary_list[[object]][["total"]]$mean_power>=0.05,]
  #summary_list[[object]][["pb"]]=summary_list[[object]][["total"]][summary_list[[object]][["total"]]$method%in%c("pseudobulk","detail"),]
  summary_list[[object]][["detail"]]=summary_list[[object]][["total"]][summary_list[[object]][["total"]]$method%in%c("detail"),]
  summary_list[[object]][["pseudobulk"]]=summary_list[[object]][["total"]][summary_list[[object]][["total"]]$method%in%c("pseudobulk"),]
}


```

#### upset plot
```{r}
library(ComplexHeatmap)
library(RColorBrewer)
# --- User Input: Your actual summary_list should be defined here ---
# Example: summary_list <- your_actual_data_object

# For demonstration, creating a dummy summary_list based on your description:
cell_type_names_from_user <- c("tc4", "tc8", "tcd", "treg", "bc", "dc", "nk", "mo")
deg_method_names_from_user <- c("pseudobulk", "roc", "detail") # "pb" for pseudobulk

set.seed(456) # for reproducibility
# --- End of dummy data. Use your actual summary_list ---

# Extract cell type names and method names from your summary_list
cell_type_names <- names(summary_list)
if (length(cell_type_names) == 0) {
  stop("summary_list is empty or has no named cell types.")
}
# Assuming all cell types have the same set of methods
deg_method_names <- deg_method_names_from_user
if (length(deg_method_names) == 0) {
  stop("Methods are not defined for the first cell type in summary_list.")
}

# Helper function to safely get gene lists
get_genes_from_summary <- function(ct_name, method_name) {
  # Check if cell type exists
  if (!ct_name %in% names(summary_list)) return(character(0))
  cell_data <- summary_list[[ct_name]]

  # Check if method exists for that cell type
  if (!method_name %in% names(cell_data)) return(character(0))
  method_df <- cell_data[[method_name]]

  # Check if data frame and 'gene' column exist and are not NULL
  if (!is.null(method_df) && "gene" %in% names(method_df) && !is.null(method_df$gene)) {
    return(as.character(method_df$gene)) # Ensure it's a character vector
  }
  return(character(0)) # Return empty character vector if genes are not found
}

list_for_comb_mat <- list()
for (method in deg_method_names) {
  genes_for_method_agg <- c()
  for (ct in cell_type_names) {
    current_genes_for_ct_method <- get_genes_from_summary(ct, method)
    if (length(current_genes_for_ct_method) > 0) {
      genes_for_method_agg <- union(genes_for_method_agg, current_genes_for_ct_method)
    }
  }
  list_for_comb_mat[[method]] <- unique(genes_for_method_agg)
}

# Create the combination matrix object
comb_matrix <- make_comb_mat(list_for_comb_mat)

combination_ids <- comb_name(comb_matrix)
n_combinations <- length(combination_ids)

stacked_barplot_data <- matrix(0,
                               nrow = length(cell_type_names),
                               ncol = n_combinations,
                               dimnames = list(cell_type_names, combination_ids))

for (comb_id_str in combination_ids) {
  active_methods_logical <- as.logical(as.integer(strsplit(comb_id_str, "")[[1]]))

  for (ct in cell_type_names) {
    genes_matching_comb_for_ct <- NULL # Initialize

    # Identify genes that are DEGs for *all* active methods in this combination for this cell type
    current_active_method_names <- deg_method_names[active_methods_logical]
    if (length(current_active_method_names) > 0) {
      # Start with genes from the first active method for this cell type
      genes_matching_comb_for_ct <- get_genes_from_summary(ct, current_active_method_names[1])

      if (length(current_active_method_names) > 1 && length(genes_matching_comb_for_ct) > 0) {
        for (m_name in current_active_method_names[-1]) {
          method_degs_for_ct <- get_genes_from_summary(ct, m_name)
          genes_matching_comb_for_ct <- intersect(genes_matching_comb_for_ct, method_degs_for_ct)
          if (length(genes_matching_comb_for_ct) == 0) break
        }
      }
    } else {
      genes_matching_comb_for_ct <- character(0) # No active methods
    }
    if (is.null(genes_matching_comb_for_ct)) genes_matching_comb_for_ct <- character(0) # Ensure it's not NULL

    # Exclude genes that are DEGs for *any* of the inactive methods for this cell type
    if (length(genes_matching_comb_for_ct) > 0) {
      current_inactive_method_names <- deg_method_names[!active_methods_logical]
      if (length(current_inactive_method_names) > 0) {
        for (m_name in current_inactive_method_names) {
          degs_from_inactive_method <- get_genes_from_summary(ct, m_name)
          if (length(degs_from_inactive_method) > 0) {
            genes_matching_comb_for_ct <- setdiff(genes_matching_comb_for_ct, degs_from_inactive_method)
          }
          if (length(genes_matching_comb_for_ct) == 0) break
        }
      }
    }
    stacked_barplot_data[ct, comb_id_str] <- length(genes_matching_comb_for_ct)
  }
}

n_cell_types <- length(cell_type_names)
if (n_cell_types <= 12 && n_cell_types > 0) { # brewer.pal needs n >= 3 for some palettes
    pal_name <- if (n_cell_types >=3) "Paired" else "Set2" # Choose appropriate palette
    cell_type_colors <- RColorBrewer::brewer.pal(n = max(3, n_cell_types), name = pal_name)
    if (n_cell_types < 3) cell_type_colors <- cell_type_colors[1:n_cell_types]
} else if (n_cell_types > 0) {
    qual_col_pals <- RColorBrewer::brewer.pal.info[RColorBrewer::brewer.pal.info$category == 'qual',]
    col_vector <- unlist(mapply(RColorBrewer::brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
    # Ensure enough unique colors if n_cell_types is very large
    if (n_cell_types > length(unique(col_vector))) {
        col_vector <- rep(col_vector, ceiling(n_cell_types / length(unique(col_vector))))
    }
    cell_type_colors <- sample(unique(col_vector), n_cell_types) # Sample to get diverse colors
    # Or use colorRampPalette for smoother gradients if preferred, though distinct colors are better here
    # cell_type_colors <- colorRampPalette(RColorBrewer::brewer.pal(8, "Set2"))(n_cell_types)
} else {
    cell_type_colors <- character(0) # No cell types
}
if (length(cell_type_colors) > 0) names(cell_type_colors) <- cell_type_names

# Ensure cell_type_colors has names corresponding to rownames of stacked_barplot_data
# and that stacked_barplot_data is not empty
if (nrow(stacked_barplot_data) > 0 && ncol(stacked_barplot_data) > 0) {
    top_annotation <- HeatmapAnnotation(
      "Intersection DEGs by Cell Type" = anno_barplot(
        stacked_barplot_data,
        gp = gpar(fill = cell_type_colors[rownames(stacked_barplot_data)]),
        border = FALSE,
        height = unit(6, "cm"),
        axis_param = list(side = "left", labels_rot = 0, gp = gpar(fontsize = 8))
      ),
      annotation_name_side = "left",
      annotation_name_rot = 0,
      annotation_name_gp = gpar(fontsize = 10)
    )
} else {
    top_annotation <- NULL # No data to plot
}

if (length(cell_type_colors) > 0 && !is.null(names(cell_type_colors))) {
    cell_type_legend <- Legend(
      labels = names(cell_type_colors),
      title = "Cell Type Contributions",
      legend_gp = gpar(fill = cell_type_colors[names(cell_type_colors)]) # Ensure correct order
    )
} else {
    cell_type_legend <- NULL
}

# (Previous steps and definitions for comb_matrix, set_order, combination_order,
# top_annotation, left_annotation, cell_type_legend are assumed to be the same
# and correct as in the last version)

# Check if comb_matrix is valid before plotting
if (nrow(comb_matrix) > 0 && ncol(comb_matrix) > 0) {
    upset_plot_final <- UpSet(
        comb_matrix,
        set_order = set_order,
        comb_order = combination_order,
        top_annotation = top_annotation,
        left_annotation = left_annotation,
        right_annotation = NULL,
        row_names_gp = gpar(fontsize = 10),
        column_title = "DEG Set Overlap by Method, Stacked by Cell Type Contribution",
        column_title_gp = gpar(fontsize = 14, fontface = "bold")
        # REMOVED: show_heatmap_legend = FALSE
    )

    # Draw the plot
    # Ensure plot device is open and sufficiently large
    # e.g., by running quartz() or windows() or X11() beforehand if not in RStudio
    if (!is.null(upset_plot_final)) {
        draw_args <- list(upset_plot_final, padding = unit(c(5, 5, 10, 25), "mm")) # Increased right padding for legend
        if (!is.null(cell_type_legend)) {
            draw_args$heatmap_legend_list <- list(cell_type_legend)
        }
        do.call(draw, draw_args)
    } else {
        message("Upset plot object could not be generated, likely due to empty data or an issue within UpSet function.")
    }

} else {
    message("Combination matrix is empty. Cannot generate UpSet plot.")
    message("This might be due to no DEGs found or an issue with input data processing.")
}

```
#### o4 mini high
##### simplest
```{r}
# install.packages("ComplexHeatmap")
library(ComplexHeatmap)

# ⬥── 1. Upset of the three DEG methods (roc, detail, pseudobulk) aggregated across all subsets
# -----------------------------------------------------------------------------
# pull out the union of genes called by each method across your 8 cell subsets:
method_gene_list <- list(
  ROC        = unique(unlist(lapply(summary_list, function(res) res[["roc"]]$gene))),
  Detail     = unique(unlist(lapply(summary_list, function(res) res[["detail"]]$gene))),
  Pseudobulk = unique(unlist(lapply(summary_list, function(res) res[["pseudobulk"]]$gene)))
)

# build the combination matrix and draw
comb_mat_methods <- make_comb_mat(method_gene_list)
UpSet(comb_mat_methods)
```